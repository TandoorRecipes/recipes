{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Tandoor Recipes The recipe manager that allows you to manage your ever growing collection of digital recipes. Website \u2022 Installation \u2022 Docs \u2022 Demo \u2022 Discord Core Features \ud83e\udd57 Manage your recipes with a fast and intuitive editor \ud83d\udcc6 Plan multiple meals for each day \ud83d\uded2 Shopping lists via the meal plan or straight from recipes \ud83d\udcda Cookbooks collect recipes into books \ud83d\udc6a Share and collaborate on recipes with friends and family Made by and for power users \ud83d\udd0d Powerful & customizable search with fulltext support and TrigramSimilarity \ud83c\udff7\ufe0f Create and search for tags , assign them in batch to all files matching certain filters \u2194\ufe0f Quickly merge and rename ingredients, tags and units \ud83d\udce5\ufe0f Import recipes from thousands of websites supporting ld+json or microdata \u2797 Support for fractions or decimals \ud83d\udc33 Easy setup with Docker and included examples for Kubernetes , Unraid and Synology \ud83c\udfa8 Customize your interface with themes \ud83d\udce6 Sync files with Dropbox and Nextcloud All the must haves \ud83d\udcf1Optimized for use on mobile devices \ud83c\udf0d localized in many languages thanks to the awesome community \ud83d\udce5\ufe0f Import your collection from many other recipe managers \u2795 Many more like recipe scaling, image compression, printing views and supermarkets This application is meant for people with a collection of recipes they want to share with family and friends or simply store them in a nicely organized way. A basic permission system exists but this application is not meant to be run as a public page. Your Feedback Share some information on how you use Tandoor to help me improve the application Google Survey Get in touch Discord We have a public Discord server that anyone can join. This is where all our developers and contributors hang out and where we make announcements Twitter You can follow our Twitter account to get updates on new features or releases Roadmap This application has been under rapid development over the last year. During this time I have learnt a lot and added tons of features, I have also moved to some new technologies like Vue.js. This has led to some great features but has left the Quality unsatisfactory in regard to the details and technical implementation. So in addition to the new Features and Ideas which can always be found in the Issues & Milestones there are some greater overall goals for the future (in no particular order) Improve the UI! The Design is inconsistent and many pages work but don't look great. This needs to change. I strongly believe in Open Data and Systems. Thus adding importers and exporters for all relevant other recipe management systems is something i really want to do. Move all Javascript Libraries to a packet manger and clean up some of the mess I made in the early days Improve Test coverage and also the individual tests themselves Improve the documentation for all features and aspects of this project and add some application integrated help About This application has originally been developed to index, tag and search my collection of digital (PDF) recipes. Over the time tons of features have been added making this the most comprehensive recipe management system. I am just a single developer with many other interests and obligations so development and support might be slow at times, but I try my best to constantly improve this application. If you have any wishes, feature requests, problems or ideas feel free to open an issue on GitHub.","title":"Home"},{"location":"#core-features","text":"\ud83e\udd57 Manage your recipes with a fast and intuitive editor \ud83d\udcc6 Plan multiple meals for each day \ud83d\uded2 Shopping lists via the meal plan or straight from recipes \ud83d\udcda Cookbooks collect recipes into books \ud83d\udc6a Share and collaborate on recipes with friends and family","title":"Core Features"},{"location":"#made-by-and-for-power-users","text":"\ud83d\udd0d Powerful & customizable search with fulltext support and TrigramSimilarity \ud83c\udff7\ufe0f Create and search for tags , assign them in batch to all files matching certain filters \u2194\ufe0f Quickly merge and rename ingredients, tags and units \ud83d\udce5\ufe0f Import recipes from thousands of websites supporting ld+json or microdata \u2797 Support for fractions or decimals \ud83d\udc33 Easy setup with Docker and included examples for Kubernetes , Unraid and Synology \ud83c\udfa8 Customize your interface with themes \ud83d\udce6 Sync files with Dropbox and Nextcloud","title":"Made by and for power users"},{"location":"#all-the-must-haves","text":"\ud83d\udcf1Optimized for use on mobile devices \ud83c\udf0d localized in many languages thanks to the awesome community \ud83d\udce5\ufe0f Import your collection from many other recipe managers \u2795 Many more like recipe scaling, image compression, printing views and supermarkets This application is meant for people with a collection of recipes they want to share with family and friends or simply store them in a nicely organized way. A basic permission system exists but this application is not meant to be run as a public page.","title":"All the must haves"},{"location":"#your-feedback","text":"Share some information on how you use Tandoor to help me improve the application Google Survey","title":"Your Feedback"},{"location":"#get-in-touch","text":"Discord We have a public Discord server that anyone can join. This is where all our developers and contributors hang out and where we make announcements Twitter You can follow our Twitter account to get updates on new features or releases","title":"Get in touch"},{"location":"#roadmap","text":"This application has been under rapid development over the last year. During this time I have learnt a lot and added tons of features, I have also moved to some new technologies like Vue.js. This has led to some great features but has left the Quality unsatisfactory in regard to the details and technical implementation. So in addition to the new Features and Ideas which can always be found in the Issues & Milestones there are some greater overall goals for the future (in no particular order) Improve the UI! The Design is inconsistent and many pages work but don't look great. This needs to change. I strongly believe in Open Data and Systems. Thus adding importers and exporters for all relevant other recipe management systems is something i really want to do. Move all Javascript Libraries to a packet manger and clean up some of the mess I made in the early days Improve Test coverage and also the individual tests themselves Improve the documentation for all features and aspects of this project and add some application integrated help","title":"Roadmap"},{"location":"#about","text":"This application has originally been developed to index, tag and search my collection of digital (PDF) recipes. Over the time tons of features have been added making this the most comprehensive recipe management system. I am just a single developer with many other interests and obligations so development and support might be slow at times, but I try my best to constantly improve this application. If you have any wishes, feature requests, problems or ideas feel free to open an issue on GitHub.","title":"About"},{"location":"contribute/","text":"If you like this application and want it to improve, feel free to contribute to its development. Contribution List If you help bring this project forward you deserve to be credited for it. Feel free to add yourself to CONTRIBUTERS.md or message me to add you if you have contributed anything. Issues The most basic but also very important way of contributing is reporting issues and commenting on ideas and feature requests over on the GitHub issues . Without Feedback improvement can't happen, so don't hesitate to say what you want to say. Contributing Code Code contributions are always welcome. There is no special rules for what you need to do, just do your best and we will work together to get your idea and code merged into the project. Info The dev setup is a little messy as this application combines the best (at least in my opinion) of django and Vue.js. Django This application is developed using the Django framework for Python. They have excellent documentation on how to get started, so I will only give you the basics here. Clone this repository wherever you like and install the Python language for your OS (at least version 3.8) Open it in your favorite editor/IDE (e.g. PyCharm) If you want, create a virtual environment for all your packages. Install all required packages: pip install -r requirements.txt Run the migrations: python manage.py migrate Start the development server: python manage.py runserver There is no need to set any environment variables. By default, a simple sqlite database is used and all settings are populated from default values. Vue.js Some of the more complex pages use Vue.js to enhance the frontend. In order to work on these pages you will have to install a Javascript package manager of your choice. The following examples use yarn. Run yarn install to install the dependencies. After that you can use yarn serve to start the development server and go ahead and test your changes. Before committing please make sure to pack the source using yarn build . API Client The API Client is generated automatically from the openapi interface provided by the django rest framework. For this openapi-generator is used. Install it using your desired setup method (for example using npm install @openapitools/openapi-generator-cli -g ). Navigate to vue/src/utils/openapi . Generate the schema using openapi-generator-cli generate -g typescript-axios -i http://127.0.0.1:8000/openapi/ (replace your dev server url if required) Contribute Documentation The documentation is build from the markdown files in the docs folder of the GitHub repository. Deployment Branch The documentation is currently build from the develop branch of the GitHub repository as it is evolving rapidly. This will likely change in the future to prevent issues with documentation being released before the features. In order to contribute to the documentation you can fork the repository and edit the markdown files in the browser. If you want to test the documentation locally run mkdocs serve from the project root. Contribute Translations If you know any foreign languages that is not yet translated feel free to contribute translations. Translations are managed on translate.tandoor.dev , a self hosted instance of Weblate . Weblate functionality Translations have only recently been migrated to weblate so I do not 100% understand each feature. Please feel free to contact me if you need any help getting started. You can simply register an account and then follow these steps to add translations: After registering you are asked to select your languages. This is optional but allows weblate to only show you relevant translations In the navigation click on Projects and then Browse all projects Select Tandoor and on the top right hand corner select Watch project Tandoor (click on Not watching ) Go back to the dashboard. It now shows you the relevant translations for your languages. Click the pencil icon to get started. !!!! info \"Creating a new languagte\" To create a new language you must first select Tandoor (the project) and then a component. Here you will have the option to add the language. Afterwards you can also simply add it to the other components as well. There is also a lot of documentation available from Weblate directly. It is also possible to provide the translations directly by creating a new language using manage.py makemessages -l <language_code> -i venv . Once finished, simply open a PR with the changed files.","title":"Contributing"},{"location":"contribute/#issues","text":"The most basic but also very important way of contributing is reporting issues and commenting on ideas and feature requests over on the GitHub issues . Without Feedback improvement can't happen, so don't hesitate to say what you want to say.","title":"Issues"},{"location":"contribute/#contributing-code","text":"Code contributions are always welcome. There is no special rules for what you need to do, just do your best and we will work together to get your idea and code merged into the project. Info The dev setup is a little messy as this application combines the best (at least in my opinion) of django and Vue.js.","title":"Contributing Code"},{"location":"contribute/#django","text":"This application is developed using the Django framework for Python. They have excellent documentation on how to get started, so I will only give you the basics here. Clone this repository wherever you like and install the Python language for your OS (at least version 3.8) Open it in your favorite editor/IDE (e.g. PyCharm) If you want, create a virtual environment for all your packages. Install all required packages: pip install -r requirements.txt Run the migrations: python manage.py migrate Start the development server: python manage.py runserver There is no need to set any environment variables. By default, a simple sqlite database is used and all settings are populated from default values.","title":"Django"},{"location":"contribute/#vuejs","text":"Some of the more complex pages use Vue.js to enhance the frontend. In order to work on these pages you will have to install a Javascript package manager of your choice. The following examples use yarn. Run yarn install to install the dependencies. After that you can use yarn serve to start the development server and go ahead and test your changes. Before committing please make sure to pack the source using yarn build .","title":"Vue.js"},{"location":"contribute/#api-client","text":"The API Client is generated automatically from the openapi interface provided by the django rest framework. For this openapi-generator is used. Install it using your desired setup method (for example using npm install @openapitools/openapi-generator-cli -g ). Navigate to vue/src/utils/openapi . Generate the schema using openapi-generator-cli generate -g typescript-axios -i http://127.0.0.1:8000/openapi/ (replace your dev server url if required)","title":"API Client"},{"location":"contribute/#contribute-documentation","text":"The documentation is build from the markdown files in the docs folder of the GitHub repository. Deployment Branch The documentation is currently build from the develop branch of the GitHub repository as it is evolving rapidly. This will likely change in the future to prevent issues with documentation being released before the features. In order to contribute to the documentation you can fork the repository and edit the markdown files in the browser. If you want to test the documentation locally run mkdocs serve from the project root.","title":"Contribute Documentation"},{"location":"contribute/#contribute-translations","text":"If you know any foreign languages that is not yet translated feel free to contribute translations. Translations are managed on translate.tandoor.dev , a self hosted instance of Weblate . Weblate functionality Translations have only recently been migrated to weblate so I do not 100% understand each feature. Please feel free to contact me if you need any help getting started. You can simply register an account and then follow these steps to add translations: After registering you are asked to select your languages. This is optional but allows weblate to only show you relevant translations In the navigation click on Projects and then Browse all projects Select Tandoor and on the top right hand corner select Watch project Tandoor (click on Not watching ) Go back to the dashboard. It now shows you the relevant translations for your languages. Click the pencil icon to get started. !!!! info \"Creating a new languagte\" To create a new language you must first select Tandoor (the project) and then a component. Here you will have the option to add the language. Afterwards you can also simply add it to the other components as well. There is also a lot of documentation available from Weblate directly. It is also possible to provide the translations directly by creating a new language using manage.py makemessages -l <language_code> -i venv . Once finished, simply open a PR with the changed files.","title":"Contribute Translations"},{"location":"faq/","text":"There are several questions and issues that come up from time to time. Here are some answers. Please note that the existence of some questions is due the application not being perfect in some parts. Many of those shortcomings are planned to be fixed in future release but simply could not be addressed yet due to time limits. CSRF Errors If you are getting CSRF Errors this is most likely due to a reverse proxy not passing the correct headers. If you are using swag by linuxserver you might need proxy_set_header X-Forwarded-Proto $scheme; in your nginx config. If you are using a plain ngix you might need proxy_set_header Host $http_host; . Further discussions can be found in this Issue #518 Images not loading If images are not loading this might be related to the same issue as the CSRF Errors. A discussion about that can be found Issue #452 The other common issue is that the recommended nginx container is removed from the deployment stack. If removed, the nginx webserver needs to be replaced by something else that servers the /mediafiles/ directory or GUNICORN_MEDIA needs to be enabled to allow media serving by the application container itself. User Creation To create a new user click on your name (top right corner) and select system. There click on invite links and create a new invite link. It is not possible to create users through the admin because users must be assigned a default group and space. To change a users space you need to go to the admin and select User Infos. If you use an external auth provider or proxy authentication make sure to specify a default group and space in the environment configuration. Spaces Spaces are a feature used to separate one installation of Tandoor into several parts. In technical terms it is a multi tenant system. You can compare a space to something like google drive or dropbox. There is only one installation of the Dropbox system, but it handles multiple users without them noticing each other. For Tandoor that means all people that work together on one recipe collection can be in one space. If you want to host the collection of your friends family or your neighbor you can create a separate space for them (trough the admin interface). Sharing between spaces is currently not possible but is planned for future releases.","title":"FAQ"},{"location":"faq/#csrf-errors","text":"If you are getting CSRF Errors this is most likely due to a reverse proxy not passing the correct headers. If you are using swag by linuxserver you might need proxy_set_header X-Forwarded-Proto $scheme; in your nginx config. If you are using a plain ngix you might need proxy_set_header Host $http_host; . Further discussions can be found in this Issue #518","title":"CSRF Errors"},{"location":"faq/#images-not-loading","text":"If images are not loading this might be related to the same issue as the CSRF Errors. A discussion about that can be found Issue #452 The other common issue is that the recommended nginx container is removed from the deployment stack. If removed, the nginx webserver needs to be replaced by something else that servers the /mediafiles/ directory or GUNICORN_MEDIA needs to be enabled to allow media serving by the application container itself.","title":"Images not loading"},{"location":"faq/#user-creation","text":"To create a new user click on your name (top right corner) and select system. There click on invite links and create a new invite link. It is not possible to create users through the admin because users must be assigned a default group and space. To change a users space you need to go to the admin and select User Infos. If you use an external auth provider or proxy authentication make sure to specify a default group and space in the environment configuration.","title":"User Creation"},{"location":"faq/#spaces","text":"Spaces are a feature used to separate one installation of Tandoor into several parts. In technical terms it is a multi tenant system. You can compare a space to something like google drive or dropbox. There is only one installation of the Dropbox system, but it handles multiple users without them noticing each other. For Tandoor that means all people that work together on one recipe collection can be in one space. If you want to host the collection of your friends family or your neighbor you can create a separate space for them (trough the admin interface). Sharing between spaces is currently not possible but is planned for future releases.","title":"Spaces"},{"location":"features/authentication/","text":"Besides the normal django username and password authentication this application supports multiple methods of central account management and authentication. Allauth Django Allauth is an awesome project that allows you to use a huge number of different authentication providers. They basically explain everything in their documentation, but the following is a short overview on how to get started. Public Providers If you choose Google, Github or any other publicly available service as your authentication provider anyone with an account on that site can create an account on your installation. A new account does not have any permission but it is still not recommended to give public access to your installation. Choose a provider from the list and install it using the environment variable SOCIAL_PROVIDERS as shown in the example below. SOCIAL_PROVIDERS = allauth.socialaccount.providers.github,allauth.socialaccount.providers.nextcloud Formatting The exact formatting is important so make sure to follow the steps explained here! Depending on your authentication provider you might need to configure it. This needs to be done trough the settings system. To make the system flexible (allow multiple providers) and to not require another file to be mounted into the container the configuration ins done trough a single environment variable. The downside of this approach is that the configuration needs to be put into a single line as environment files loaded by docker compose don't support multiple lines for a single variable. Take the example configuration from the allauth docs, fill in your settings and then inline the whole object (you can use a service like www.freeformatter.com for formatting). Assign it to the SOCIALACCOUNT_PROVIDERS variable. SOCIALACCOUNT_PROVIDERS = {\"nextcloud\":{\"SERVER\":\"https://nextcloud.example.org\"}} Improvements ? There are most likely ways to achieve the same goal but with a cleaner or simpler system. If you know such a way feel free to let me know. After that, use your superuser account to configure your authentication backend. Open the admin page and do the following Select Sites and edit the default site with the URL of your installation (or create a new). Create a new Social Application with the required information as stated in the provider documentation of allauth. Make sure to add your site to the list of available sites Now the provider is configured and you should be able to sign up and sign in using the provider. Use the superuser account to grant permissions to the newly created users. WIP I do not have a ton of experience with using various single signon providers and also cannot test all of them. If you have any Feedback or issues let me know. Linking accounts To link an account to an already existing normal user go to the settings page of the user and link it. Here you can also unlink your account if you no longer want to use a social login method. LDAP LDAP authentication can be enabled in the .env file by setting LDAP_AUTH=1 . If set, users listed in the LDAP instance will be able to sign in without signing up. These variables must be set to configure the connection to the LDAP instance: AUTH_LDAP_SERVER_URI=ldap://ldap.example.org:389 AUTH_LDAP_BIND_DN=uid=admin,ou=users,dc=example,dc=org AUTH_LDAP_BIND_PASSWORD=adminpassword AUTH_LDAP_USER_SEARCH_BASE_DN=ou=users,dc=example,dc=org Additional optional variables: AUTH_LDAP_USER_SEARCH_FILTER_STR=(uid=%(user)s) AUTH_LDAP_USER_ATTR_MAP={'first_name': 'givenName', 'last_name': 'sn', 'email': 'mail'} AUTH_LDAP_ALWAYS_UPDATE_USER=1 AUTH_LDAP_CACHE_TIMEOUT=3600 Reverse Proxy Authentication Community Contributed Tutorial This tutorial was provided by a community member. Since I do not use reverse proxy authentication, I cannot provide any assistance should you choose to use this authentication method. In order use proxy authentication you will need to: Set REVERSE_PROXY_AUTH=1 in the .env file Update your nginx configuration file Using any of the examples above will automatically generate a configuration file inside a docker volume. Use docker volume inspect recipes_nginx to find out where your volume is stored. Configuration File Volume The nginx config volume is generated when the container is first run. You can change the volume to a bind mount in the warning docker-compose.yml , but then you will need to manually create it. See section Volumes vs Bind Mounts below for more information. The following example shows a configuration for Authelia: server { listen 80; server_name localhost; client_max_body_size 16M; # serve static files location /static/ { alias /static/; } # serve media files location /media/ { alias /media/; } # Authelia endpoint for authentication requests include /config/nginx/auth.conf; # pass requests for dynamic content to gunicorn location / { proxy_set_header Host $host; proxy_pass http://web_recipes:8080; # Ensure Authelia is specifically required for this endpoint # This line is important as it will return a 401 error if the user doesn't have access include /config/nginx/authelia.conf; auth_request_set $user $upstream_http_remote_user; proxy_set_header REMOTE-USER $user; } # Required to allow user to logout of authentication from within Recipes # Ensure the <auth_endpoint> below is changed to actual the authentication url location /accounts/logout/ { return 301 http://<auth_endpoint>/logout; } } Please refer to the appropriate documentation on how to setup the reverse proxy, authentication, and networks. Ensure users have been configured for Authelia, and that the endpoint recipes is pointed to is protected but available. There is a good guide to the other additional files that need to be added to your nginx set up at the Authelia Docs . Remember to add the appropriate environment variables to .env file (example for nginx proxy): VIRTUAL_HOST= LETSENCRYPT_HOST= LETSENCRYPT_EMAIL= PROXY_HEADER=","title":"Authentication"},{"location":"features/authentication/#allauth","text":"Django Allauth is an awesome project that allows you to use a huge number of different authentication providers. They basically explain everything in their documentation, but the following is a short overview on how to get started. Public Providers If you choose Google, Github or any other publicly available service as your authentication provider anyone with an account on that site can create an account on your installation. A new account does not have any permission but it is still not recommended to give public access to your installation. Choose a provider from the list and install it using the environment variable SOCIAL_PROVIDERS as shown in the example below. SOCIAL_PROVIDERS = allauth.socialaccount.providers.github,allauth.socialaccount.providers.nextcloud Formatting The exact formatting is important so make sure to follow the steps explained here! Depending on your authentication provider you might need to configure it. This needs to be done trough the settings system. To make the system flexible (allow multiple providers) and to not require another file to be mounted into the container the configuration ins done trough a single environment variable. The downside of this approach is that the configuration needs to be put into a single line as environment files loaded by docker compose don't support multiple lines for a single variable. Take the example configuration from the allauth docs, fill in your settings and then inline the whole object (you can use a service like www.freeformatter.com for formatting). Assign it to the SOCIALACCOUNT_PROVIDERS variable. SOCIALACCOUNT_PROVIDERS = {\"nextcloud\":{\"SERVER\":\"https://nextcloud.example.org\"}} Improvements ? There are most likely ways to achieve the same goal but with a cleaner or simpler system. If you know such a way feel free to let me know. After that, use your superuser account to configure your authentication backend. Open the admin page and do the following Select Sites and edit the default site with the URL of your installation (or create a new). Create a new Social Application with the required information as stated in the provider documentation of allauth. Make sure to add your site to the list of available sites Now the provider is configured and you should be able to sign up and sign in using the provider. Use the superuser account to grant permissions to the newly created users. WIP I do not have a ton of experience with using various single signon providers and also cannot test all of them. If you have any Feedback or issues let me know.","title":"Allauth"},{"location":"features/authentication/#linking-accounts","text":"To link an account to an already existing normal user go to the settings page of the user and link it. Here you can also unlink your account if you no longer want to use a social login method.","title":"Linking accounts"},{"location":"features/authentication/#ldap","text":"LDAP authentication can be enabled in the .env file by setting LDAP_AUTH=1 . If set, users listed in the LDAP instance will be able to sign in without signing up. These variables must be set to configure the connection to the LDAP instance: AUTH_LDAP_SERVER_URI=ldap://ldap.example.org:389 AUTH_LDAP_BIND_DN=uid=admin,ou=users,dc=example,dc=org AUTH_LDAP_BIND_PASSWORD=adminpassword AUTH_LDAP_USER_SEARCH_BASE_DN=ou=users,dc=example,dc=org Additional optional variables: AUTH_LDAP_USER_SEARCH_FILTER_STR=(uid=%(user)s) AUTH_LDAP_USER_ATTR_MAP={'first_name': 'givenName', 'last_name': 'sn', 'email': 'mail'} AUTH_LDAP_ALWAYS_UPDATE_USER=1 AUTH_LDAP_CACHE_TIMEOUT=3600","title":"LDAP"},{"location":"features/authentication/#reverse-proxy-authentication","text":"Community Contributed Tutorial This tutorial was provided by a community member. Since I do not use reverse proxy authentication, I cannot provide any assistance should you choose to use this authentication method. In order use proxy authentication you will need to: Set REVERSE_PROXY_AUTH=1 in the .env file Update your nginx configuration file Using any of the examples above will automatically generate a configuration file inside a docker volume. Use docker volume inspect recipes_nginx to find out where your volume is stored. Configuration File Volume The nginx config volume is generated when the container is first run. You can change the volume to a bind mount in the warning docker-compose.yml , but then you will need to manually create it. See section Volumes vs Bind Mounts below for more information. The following example shows a configuration for Authelia: server { listen 80; server_name localhost; client_max_body_size 16M; # serve static files location /static/ { alias /static/; } # serve media files location /media/ { alias /media/; } # Authelia endpoint for authentication requests include /config/nginx/auth.conf; # pass requests for dynamic content to gunicorn location / { proxy_set_header Host $host; proxy_pass http://web_recipes:8080; # Ensure Authelia is specifically required for this endpoint # This line is important as it will return a 401 error if the user doesn't have access include /config/nginx/authelia.conf; auth_request_set $user $upstream_http_remote_user; proxy_set_header REMOTE-USER $user; } # Required to allow user to logout of authentication from within Recipes # Ensure the <auth_endpoint> below is changed to actual the authentication url location /accounts/logout/ { return 301 http://<auth_endpoint>/logout; } } Please refer to the appropriate documentation on how to setup the reverse proxy, authentication, and networks. Ensure users have been configured for Authelia, and that the endpoint recipes is pointed to is protected but available. There is a good guide to the other additional files that need to be added to your nginx set up at the Authelia Docs . Remember to add the appropriate environment variables to .env file (example for nginx proxy): VIRTUAL_HOST= LETSENCRYPT_HOST= LETSENCRYPT_EMAIL= PROXY_HEADER=","title":"Reverse Proxy Authentication"},{"location":"features/external_recipes/","text":"The original intend of this application was to provide a search interface to my large collection of PDF scans of recipes. This feature is now called External recipes. Info Internal recipes are stored in a structured manner inside the database. They can be displayed using the standardized interface and support features like shopping lists, scaling and steps. External recipes are basically files that are displayed within the interface. The benefit is that you can quickly import all your old recipes and convert them one by one. To use external recipes you will first need to configure a storage source. After that a synced path can be created. Lastly you will need to sync with the external path and import recipes you desire. Storage Danger In order for this application to retrieve data from external providers it needs to store authentication information. Please use read only/separate accounts or app passwords wherever possible. There are better ways to do this but they are currently not implemented A Storage Backend is a remote storage location where files are read from. To add a new backend click on Storage Data and then on Storage Backends . There click the plus button. The basic configuration is the same for all providers. Field Value Name Your identifier for this storage source, can be everything you want. Method The desired method. Success Only the providers listed below are currently implemented. If you need anything else feel free to open an issue or pull request. Local Info There is currently no way to upload files trough the webinterface. This is a feature that might be added later. The local provider does not need any configuration. For the monitor you will need to define a valid path on your host system. The Path depends on your setup and can be both relative and absolute. If you use docker the default directory is /opt/recipes/ . Volume By default no data other than the mediafiles and the database is persisted. If you use the local provider make sure to mount the path you choose to monitor to your host system in order to keep it persistent. Dropbox Field Value Username Dropbox username Token Dropbox API Token. Can be found here Nextcloud Path It appears that the correct webdav path varies from installation to installation (for whatever reason). In the Nextcloud webinterface click the Settings button in the bottom left corner, there your WebDav Url will be displayed. Field Value Username Nextcloud username Password Nextcloud app password Url Nextcloud Server URL (e.g. https://cloud.mydomain.com ) Path (optional) webdav path (e.g. /remote.php/dav/files/vabene1111 ). If no path is supplied /remote.php/dav/files/ plus your username will be used. Adding Synced Paths To add a new path from your Storage backend to the sync list, go to Storage Data >> Configure Sync and select the storage backend you want to use. Then enter the path you want to monitor starting at the storage root (e.g. /Folder/RecipesFolder ) and save it. Syncing Data To sync the recipes app with the storage backends press Sync now under Storage Data >> Configure Sync . Discovered Recipes All files found by the sync can be found under Manage Data >> Discovered recipes . There you can either import all at once without modifying them or import one by one, adding tags while importing.","title":"Storages and Sync"},{"location":"features/external_recipes/#storage","text":"Danger In order for this application to retrieve data from external providers it needs to store authentication information. Please use read only/separate accounts or app passwords wherever possible. There are better ways to do this but they are currently not implemented A Storage Backend is a remote storage location where files are read from. To add a new backend click on Storage Data and then on Storage Backends . There click the plus button. The basic configuration is the same for all providers. Field Value Name Your identifier for this storage source, can be everything you want. Method The desired method. Success Only the providers listed below are currently implemented. If you need anything else feel free to open an issue or pull request.","title":"Storage"},{"location":"features/external_recipes/#local","text":"Info There is currently no way to upload files trough the webinterface. This is a feature that might be added later. The local provider does not need any configuration. For the monitor you will need to define a valid path on your host system. The Path depends on your setup and can be both relative and absolute. If you use docker the default directory is /opt/recipes/ . Volume By default no data other than the mediafiles and the database is persisted. If you use the local provider make sure to mount the path you choose to monitor to your host system in order to keep it persistent.","title":"Local"},{"location":"features/external_recipes/#dropbox","text":"Field Value Username Dropbox username Token Dropbox API Token. Can be found here","title":"Dropbox"},{"location":"features/external_recipes/#nextcloud","text":"Path It appears that the correct webdav path varies from installation to installation (for whatever reason). In the Nextcloud webinterface click the Settings button in the bottom left corner, there your WebDav Url will be displayed. Field Value Username Nextcloud username Password Nextcloud app password Url Nextcloud Server URL (e.g. https://cloud.mydomain.com ) Path (optional) webdav path (e.g. /remote.php/dav/files/vabene1111 ). If no path is supplied /remote.php/dav/files/ plus your username will be used.","title":"Nextcloud"},{"location":"features/external_recipes/#adding-synced-paths","text":"To add a new path from your Storage backend to the sync list, go to Storage Data >> Configure Sync and select the storage backend you want to use. Then enter the path you want to monitor starting at the storage root (e.g. /Folder/RecipesFolder ) and save it.","title":"Adding Synced Paths"},{"location":"features/external_recipes/#syncing-data","text":"To sync the recipes app with the storage backends press Sync now under Storage Data >> Configure Sync .","title":"Syncing Data"},{"location":"features/external_recipes/#discovered-recipes","text":"All files found by the sync can be found under Manage Data >> Discovered recipes . There you can either import all at once without modifying them or import one by one, adding tags while importing.","title":"Discovered Recipes"},{"location":"features/import_export/","text":"This application features a very versatile import and export feature in order to offer the best experience possible and allow you to freely choose where your data goes. WIP The Module is relatively new. There is a know issue with Timeouts on large exports. A fix is being developed and will likely be released with the next version. The Module is build with maximum flexibility and expandability in mind and allows to easily add new integrations to allow you to both import and export your recipes into whatever format you desire. Feel like there is an important integration missing ? Just take a look at the integration issues or open a new one if your favorite one is missing. Export I strongly believe in everyone's right to use their data as they please and therefore want to give you the most possible flexibility with your recipes. That said for most of the people getting this application running with their recipes is the biggest priority. Because of this importing as many formats as possible is prioritized over exporting. Exporter for the different formats will follow over time. Overview of the capabilities of the different integrations. Integration Import Export Images Default \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Nextcloud \u2714\ufe0f \u231a \u2714\ufe0f Mealie \u2714\ufe0f \u231a \u2714\ufe0f Chowdown \u2714\ufe0f \u231a \u2714\ufe0f Safron \u2714\ufe0f \u231a \u274c Paprika \u2714\ufe0f \u231a \u2714\ufe0f ChefTap \u2714\ufe0f \u274c \u274c Pepperplate \u2714\ufe0f \u231a \u274c RecipeSage \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Domestica \u2714\ufe0f \u231a \u2714\ufe0f MealMaster \u2714\ufe0f \u274c \u274c RezKonv \u2714\ufe0f \u274c \u274c OpenEats \u2714\ufe0f \u274c \u231a Plantoeat \u2714\ufe0f \u274c \u2714 CookBookApp \u2714\ufe0f \u231a \u2714\ufe0f \u2714 = implemented, \u274c = not implemented and not possible/planned, \u231a = not yet implemented Default The default integration is the build in (and preferred) way to import and export recipes. It is maintained with new fields added and contains all data to transfer your recipes from one installation to another. It is also one of the few recipe formats that is actually structured in a way that allows for easy machine readability if you want to use the data for any other purpose. RecipeSage Go to Settings > Export Recipe Data and select EXPORT AS JSON-LD (BEST) . Then simply upload the exported file to Tandoor. The RecipeSage integration also allows exporting. To migrate from Tandoor to RecipeSage simply export with Recipe Sage selected and import the json file in RecipeSage. Images are currently not supported for exporting. Domestica Go to Import/Export and select Export Recipes . Then simply upload the exported file to Tandoor. Nextcloud Importing recipes from Nextcloud cookbook is very easy and since Nextcloud Cookbook provides nice, standardized and structured information most of your recipe is going to be intact. Follow these steps to import your recipes Go to your Nextcloud Webinterface Open the Recipes folder where your recipes are stored Select the recipes you want to export or use the checkbox at the top of the list to select all of them Click on the three dot Actions and press Download You will get a Recipes.zip file. Simply upload the file and choose the Nextcloud Cookbook type. Folder Structure Importing only works if the folder structure is correct. If you do not use the standard path or create the zip file in any other way make sure the structure is as follows Recipes.zip/ \u2514\u2500\u2500 Recipes/ \u251c\u2500\u2500 Recipe1/ \u2502 \u251c\u2500\u2500 recipe.json \u2502 \u2514\u2500\u2500 full.jpg \u2514\u2500\u2500 Recipe2/ \u251c\u2500\u2500 recipe.json \u2514\u2500\u2500 full.jpg Mealie Mealie provides structured data similar to nextcloud. To migrate your recipes Go to you Mealie settings and create a new Backup Download the backup by clicking on it and pressing download (this wasn't working for me, so I had to manually pull it from the server) Upload the entire .zip file to the importer page and import everything Chowdown Chowdown stores all your recipes in plain text markdown files in a directory called _recipes . Images are saved in a directory called images . In order to import your Chowdown recipes simply create a .zip file from those two folders and import them. The folder structure should look as follows _recipes For some reason chowdown uses _ before the recipes folder. To avoid confusion the import supports both _recipes and recipes Recipes.zip/ \u251c\u2500\u2500 _recipes/ \u2502 \u251c\u2500\u2500 recipe one.md \u2502 \u251c\u2500\u2500 recipe two.md \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 images/ \u251c\u2500\u2500 image-name.jpg \u251c\u2500\u2500 second-image-name.jpg \u2514\u2500\u2500 ... Safron Go to you safron settings page and export your recipes. Then simply upload the entire .zip file to the importer. Images Safron exports do not contain any images. They will be lost during import. Paprika A Paprika export contains a folder with a html representation of your recipes and a .paprikarecipes file. The .paprikarecipes file is basically just a zip with gzipped contents. Simply upload the whole file and import all your recipes. Pepperplate Pepperplate provides a .zip files contain all your recipes as .txt files. These files are well-structured and allow the import of all data without loosing anything. Simply export the recipes from Pepperplate and upload the zip to Tandoor. Images are not included in the export and thus cannot be imported. ChefTap ChefTaps allows you to export your recipes from the app (I think). The export is a zip file containing a folder called cheftap_export which in turn contains .txt files with your recipes. This format is basically completely unstructured and every export looks different. This makes importing it very hard and leads to suboptimal results. Images are also not supported as they are not included in the export (at least the tests I had). Usually the import should recognize all ingredients and put everything else into the instructions. If you import fails or is worse than this feel free to provide me with more example data and I can try to improve the importer. As ChefTap cannot import these files anyway there won't be an exporter implemented in Tandoor. MealMaster Meal master can be imported by uploading one or more meal master files. The files should either be .txt , .MMF or .MM files. The MealMaster spec allow for many variations. Currently, only the on column format for ingredients is supported. Second line notes to ingredients are currently also not imported as a note but simply put into the instructions. If you have MealMaster recipes that cannot be imported feel free to raise an issue. RezKonv The RezKonv format is primarily used in the german recipe manager RezKonv Suite. To migrate from RezKonv Suite to Tandoor select Export > Gesamtes Kochbuch exportieren (the last option in the export menu). The generated file can simply be imported into Tandoor. As I only had limited sample data feel free to open an issue if your RezKonv export cannot be imported. Recipekeeper Recipe keeper allows to export a zip file containing recipes and images using its apps. This zip file can simply be imported into Tandoor. OpenEats OpenEats does not provide any way to export the data using the interface. Luckily it is relatively easy to export it from the command line. You need to run the command python manage.py dumpdata recipe ingredient inside of the application api container. If you followed the default installation method you can use the following command docker-compose -f docker-prod.yml run --rm --entrypoint 'sh' api ./manage.py dumpdata recipe ingredient . This command might also work docker exec -it openeats_api_1 ./manage.py dumpdata recipe ingredient > recipe_ingredients.json Store the outputted json string in a .json file and simply import it using the importer. The file should look something like this [ { \"model\" : \"recipe.recipe\" , \"pk\" : 1 , \"fields\" :{ \"title\" : \"Tasty Chili\" , ... } }, ... { \"model\" : \"ingredient.ingredientgroup\" , \"pk\" : 1 , \"fields\" :{ \"title\" : \"Veges\" , \"recipe\" : 1 } }, ... { \"model\" : \"ingredient.ingredient\" , \"pk\" : 1 , \"fields\" :{ \"title\" : \"black pepper\" , \"numerator\" : 1.0 , \"denominator\" : 1.0 , \"measurement\" : \"dash\" , \"ingredient_group\" : 1 } } ] Plantoeat Plan to eat allow to export a text file containing all your recipes. Simply upload that text file to Tandoor to import all recipes CookBookApp CookBookApp can export .zip files containing .html files. Upload the entire ZIP to Tandoor to import all included recipes.","title":"Import/Export"},{"location":"features/import_export/#default","text":"The default integration is the build in (and preferred) way to import and export recipes. It is maintained with new fields added and contains all data to transfer your recipes from one installation to another. It is also one of the few recipe formats that is actually structured in a way that allows for easy machine readability if you want to use the data for any other purpose.","title":"Default"},{"location":"features/import_export/#recipesage","text":"Go to Settings > Export Recipe Data and select EXPORT AS JSON-LD (BEST) . Then simply upload the exported file to Tandoor. The RecipeSage integration also allows exporting. To migrate from Tandoor to RecipeSage simply export with Recipe Sage selected and import the json file in RecipeSage. Images are currently not supported for exporting.","title":"RecipeSage"},{"location":"features/import_export/#domestica","text":"Go to Import/Export and select Export Recipes . Then simply upload the exported file to Tandoor.","title":"Domestica"},{"location":"features/import_export/#nextcloud","text":"Importing recipes from Nextcloud cookbook is very easy and since Nextcloud Cookbook provides nice, standardized and structured information most of your recipe is going to be intact. Follow these steps to import your recipes Go to your Nextcloud Webinterface Open the Recipes folder where your recipes are stored Select the recipes you want to export or use the checkbox at the top of the list to select all of them Click on the three dot Actions and press Download You will get a Recipes.zip file. Simply upload the file and choose the Nextcloud Cookbook type. Folder Structure Importing only works if the folder structure is correct. If you do not use the standard path or create the zip file in any other way make sure the structure is as follows Recipes.zip/ \u2514\u2500\u2500 Recipes/ \u251c\u2500\u2500 Recipe1/ \u2502 \u251c\u2500\u2500 recipe.json \u2502 \u2514\u2500\u2500 full.jpg \u2514\u2500\u2500 Recipe2/ \u251c\u2500\u2500 recipe.json \u2514\u2500\u2500 full.jpg","title":"Nextcloud"},{"location":"features/import_export/#mealie","text":"Mealie provides structured data similar to nextcloud. To migrate your recipes Go to you Mealie settings and create a new Backup Download the backup by clicking on it and pressing download (this wasn't working for me, so I had to manually pull it from the server) Upload the entire .zip file to the importer page and import everything","title":"Mealie"},{"location":"features/import_export/#chowdown","text":"Chowdown stores all your recipes in plain text markdown files in a directory called _recipes . Images are saved in a directory called images . In order to import your Chowdown recipes simply create a .zip file from those two folders and import them. The folder structure should look as follows _recipes For some reason chowdown uses _ before the recipes folder. To avoid confusion the import supports both _recipes and recipes Recipes.zip/ \u251c\u2500\u2500 _recipes/ \u2502 \u251c\u2500\u2500 recipe one.md \u2502 \u251c\u2500\u2500 recipe two.md \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 images/ \u251c\u2500\u2500 image-name.jpg \u251c\u2500\u2500 second-image-name.jpg \u2514\u2500\u2500 ...","title":"Chowdown"},{"location":"features/import_export/#safron","text":"Go to you safron settings page and export your recipes. Then simply upload the entire .zip file to the importer. Images Safron exports do not contain any images. They will be lost during import.","title":"Safron"},{"location":"features/import_export/#paprika","text":"A Paprika export contains a folder with a html representation of your recipes and a .paprikarecipes file. The .paprikarecipes file is basically just a zip with gzipped contents. Simply upload the whole file and import all your recipes.","title":"Paprika"},{"location":"features/import_export/#pepperplate","text":"Pepperplate provides a .zip files contain all your recipes as .txt files. These files are well-structured and allow the import of all data without loosing anything. Simply export the recipes from Pepperplate and upload the zip to Tandoor. Images are not included in the export and thus cannot be imported.","title":"Pepperplate"},{"location":"features/import_export/#cheftap","text":"ChefTaps allows you to export your recipes from the app (I think). The export is a zip file containing a folder called cheftap_export which in turn contains .txt files with your recipes. This format is basically completely unstructured and every export looks different. This makes importing it very hard and leads to suboptimal results. Images are also not supported as they are not included in the export (at least the tests I had). Usually the import should recognize all ingredients and put everything else into the instructions. If you import fails or is worse than this feel free to provide me with more example data and I can try to improve the importer. As ChefTap cannot import these files anyway there won't be an exporter implemented in Tandoor.","title":"ChefTap"},{"location":"features/import_export/#mealmaster","text":"Meal master can be imported by uploading one or more meal master files. The files should either be .txt , .MMF or .MM files. The MealMaster spec allow for many variations. Currently, only the on column format for ingredients is supported. Second line notes to ingredients are currently also not imported as a note but simply put into the instructions. If you have MealMaster recipes that cannot be imported feel free to raise an issue.","title":"MealMaster"},{"location":"features/import_export/#rezkonv","text":"The RezKonv format is primarily used in the german recipe manager RezKonv Suite. To migrate from RezKonv Suite to Tandoor select Export > Gesamtes Kochbuch exportieren (the last option in the export menu). The generated file can simply be imported into Tandoor. As I only had limited sample data feel free to open an issue if your RezKonv export cannot be imported.","title":"RezKonv"},{"location":"features/import_export/#recipekeeper","text":"Recipe keeper allows to export a zip file containing recipes and images using its apps. This zip file can simply be imported into Tandoor.","title":"Recipekeeper"},{"location":"features/import_export/#openeats","text":"OpenEats does not provide any way to export the data using the interface. Luckily it is relatively easy to export it from the command line. You need to run the command python manage.py dumpdata recipe ingredient inside of the application api container. If you followed the default installation method you can use the following command docker-compose -f docker-prod.yml run --rm --entrypoint 'sh' api ./manage.py dumpdata recipe ingredient . This command might also work docker exec -it openeats_api_1 ./manage.py dumpdata recipe ingredient > recipe_ingredients.json Store the outputted json string in a .json file and simply import it using the importer. The file should look something like this [ { \"model\" : \"recipe.recipe\" , \"pk\" : 1 , \"fields\" :{ \"title\" : \"Tasty Chili\" , ... } }, ... { \"model\" : \"ingredient.ingredientgroup\" , \"pk\" : 1 , \"fields\" :{ \"title\" : \"Veges\" , \"recipe\" : 1 } }, ... { \"model\" : \"ingredient.ingredient\" , \"pk\" : 1 , \"fields\" :{ \"title\" : \"black pepper\" , \"numerator\" : 1.0 , \"denominator\" : 1.0 , \"measurement\" : \"dash\" , \"ingredient_group\" : 1 } } ]","title":"OpenEats"},{"location":"features/import_export/#plantoeat","text":"Plan to eat allow to export a text file containing all your recipes. Simply upload that text file to Tandoor to import all recipes","title":"Plantoeat"},{"location":"features/import_export/#cookbookapp","text":"CookBookApp can export .zip files containing .html files. Upload the entire ZIP to Tandoor to import all included recipes.","title":"CookBookApp"},{"location":"features/shopping/","text":"WIP While being around for a while there are still a lot of features that i plan on adding to the shopping list. You can see an overview of what is still planned on this issue. Shopping lists allow you to easily convert a recipe or even a whole meal plan into a shopping list. From there you can either use it on the site or export it to your shopping list of choice. It also includes automatic supermarket specific ordering. Create Shopping Lists You have three options to create a shopping list Open a recipe of your choice. From the context menu choose Add to Shoppinglist and create a new list with the recipe already added. After adding recipes to the meal plan you can click the little shopping cart icon to add the recipes to the shopping list. They will be shown below the plan, from there you can open a new shopping list with them. The last option is to open the shopping list page and click the little plus icon to create a new list. Supermarket Ordering WIP This feature is relatively new and I did not have the time to completely polished it yet, that said it already works quite well. You can create Supermarket Categories and Supermarkets in the admin interface. After setting this up you can choose a supermarket for each shopping list. This will automatically show the categories configured for this supermarket in the order specified. All Foods that are not yet categorized can be dragged into their category, this will save the categories for the future. Sharing & Autosync If you want to collaborate on the creation and usage of the shopping list you can add a user to the list of shared users. Each user now has access to the list and can edit it. When checking items in viewing mode the change is synced to all other clients that currently have the same list open. You can set the syncing interval in your user settings. Other Features There are a few more features worth pointing out You can export recipes for use in other applications (Google Keep, etc.) by using the export button In the export popup you can define a prefix to be put before each row in case an external app requires that Marking a shopping list as finished will hide it from the shopping list page","title":"Shopping"},{"location":"features/shopping/#create-shopping-lists","text":"You have three options to create a shopping list Open a recipe of your choice. From the context menu choose Add to Shoppinglist and create a new list with the recipe already added. After adding recipes to the meal plan you can click the little shopping cart icon to add the recipes to the shopping list. They will be shown below the plan, from there you can open a new shopping list with them. The last option is to open the shopping list page and click the little plus icon to create a new list.","title":"Create Shopping Lists"},{"location":"features/shopping/#supermarket-ordering","text":"WIP This feature is relatively new and I did not have the time to completely polished it yet, that said it already works quite well. You can create Supermarket Categories and Supermarkets in the admin interface. After setting this up you can choose a supermarket for each shopping list. This will automatically show the categories configured for this supermarket in the order specified. All Foods that are not yet categorized can be dragged into their category, this will save the categories for the future.","title":"Supermarket Ordering"},{"location":"features/shopping/#sharing-autosync","text":"If you want to collaborate on the creation and usage of the shopping list you can add a user to the list of shared users. Each user now has access to the list and can edit it. When checking items in viewing mode the change is synced to all other clients that currently have the same list open. You can set the syncing interval in your user settings.","title":"Sharing &amp; Autosync"},{"location":"features/shopping/#other-features","text":"There are a few more features worth pointing out You can export recipes for use in other applications (Google Keep, etc.) by using the export button In the export popup you can define a prefix to be put before each row in case an external app requires that Marking a shopping list as finished will hide it from the shopping list page","title":"Other Features"},{"location":"features/telegram_bot/","text":"The telegram bot is meant to simplify certain interactions with Tandoor. It is currently very basic but might be expanded in the future. Experimental This feature is considered experimental. You can use it and it should not break anything but you might be required to update your configuration in the future. The setup is also definitely not user-friendly, this will likely improve if the feature is well-received/expanded. Public IP/Domain To use the Telegram Bot you will need an installation that is accessible from the outside, otherwise telegram can't send messages. This could be circumvented using the polling API but this is currently not implemented. Shopping Bot The shopping bot will add any message you send it to your latest open shopping list. To get a shopping bot follow these steps Create a new Telegram Bot using the BotFather If you want to use the bot with multiple persons add the bot to a group and grant it admin privileges Open the Admin Page (click your username, then admin) and select Telegram Bots Create a new Bot token: the token obtained in step one space: your space (usually Default) user: to the user the bot is meant for (determines the shopping list used) chat id: if you know where messages will be sent from enter the chat ID, otherwise it is set to the first chat the bot received a message from Visit your installation at recipes.mydomin.tld/telegram/setup/<botid> with botid being the ID of the bot you just created You should see the following message: { \"hook_url\": \"https://recipes.mydomin.tld/telegram/hook/c0c08de9-5e1e-4480-8312-3e256af61340/\", \"create_response\": { \"ok\": true, \"result\": true, \"description\": \"Webhook was set\" }, \"info_response\": { \"ok\": true, \"result\": { \"url\": \"recipes.mydomin.tld/telegram/hook/<webhook_token>\", \"has_custom_certificate\": false, \"pending_update_count\": 0, \"max_connections\": 40, \"ip_address\": \"46.4.105.116\" } } } You should now be able to send messages to the bot and have the entries appear in your latest shopping list. Resetting To reset a bot open recipes.mydomin.tld/telegram/remove/<botid>","title":"Telegram bot"},{"location":"features/telegram_bot/#shopping-bot","text":"The shopping bot will add any message you send it to your latest open shopping list. To get a shopping bot follow these steps Create a new Telegram Bot using the BotFather If you want to use the bot with multiple persons add the bot to a group and grant it admin privileges Open the Admin Page (click your username, then admin) and select Telegram Bots Create a new Bot token: the token obtained in step one space: your space (usually Default) user: to the user the bot is meant for (determines the shopping list used) chat id: if you know where messages will be sent from enter the chat ID, otherwise it is set to the first chat the bot received a message from Visit your installation at recipes.mydomin.tld/telegram/setup/<botid> with botid being the ID of the bot you just created You should see the following message: { \"hook_url\": \"https://recipes.mydomin.tld/telegram/hook/c0c08de9-5e1e-4480-8312-3e256af61340/\", \"create_response\": { \"ok\": true, \"result\": true, \"description\": \"Webhook was set\" }, \"info_response\": { \"ok\": true, \"result\": { \"url\": \"recipes.mydomin.tld/telegram/hook/<webhook_token>\", \"has_custom_certificate\": false, \"pending_update_count\": 0, \"max_connections\": 40, \"ip_address\": \"46.4.105.116\" } } } You should now be able to send messages to the bot and have the entries appear in your latest shopping list.","title":"Shopping Bot"},{"location":"features/telegram_bot/#resetting","text":"To reset a bot open recipes.mydomin.tld/telegram/remove/<botid>","title":"Resetting"},{"location":"features/templating/","text":"Danger The version containing Templating is not yet released! This documentation is only to illustrate the pending changes facilitate the discussion. With the Version 0.14.0 support for using a custom Jinja2 Template in recipe step instructions has been added. This allows you to write ingredients with their corresponding amount directly inside the text while still profiting from recipe scaling. Info Templating is a very new feature and still WIP. Feel free to open an issue to provide feedback and ideas. Please also refer to Issue #218 where this feature has been discussed. Using Templating Currently the only available variable in the Templating context is ingredients . ingredients is an array that contains all ingredients of the current recipe step. You can access an ingredient by using {{ ingredient[<index in list>] }} where the index refers to the position in the list of ingredients starting with zero. You can also use the interaction menu of the ingredient to copy its reference. Warning Please note that changing the order of the ingredients will break the reference (or at least make it useless). See the technical reasoning for more information on why it is this way. You can also access only the amount, unit, note or food inside your instruction text using {{ instructions[0].amount }} {{ instructions[0].unit }} {{ instructions[0].food }} {{ instructions[0].note }} Technical Reasoning There are several options how the ingredients in the list can be related to the Template Context in the Text. The template could access them by ID, the food name or the position in the list. All options have their benefits and disadvantages. ID : ugly to write and read when not rendered and also more complex from a technical standpoint Name : very nice to read and easy but does not work when a food occurs twice in a step. Could have workaround but would then be inconsistent. Position : easy to write and understand but breaks when ordering is changed and not really nice to read when instructions are not rendered. I decided to go for the position based system. If you know of any better way feel free to open an issue or PR.","title":"Templating"},{"location":"features/templating/#using-templating","text":"Currently the only available variable in the Templating context is ingredients . ingredients is an array that contains all ingredients of the current recipe step. You can access an ingredient by using {{ ingredient[<index in list>] }} where the index refers to the position in the list of ingredients starting with zero. You can also use the interaction menu of the ingredient to copy its reference. Warning Please note that changing the order of the ingredients will break the reference (or at least make it useless). See the technical reasoning for more information on why it is this way. You can also access only the amount, unit, note or food inside your instruction text using {{ instructions[0].amount }} {{ instructions[0].unit }} {{ instructions[0].food }} {{ instructions[0].note }}","title":"Using Templating"},{"location":"features/templating/#technical-reasoning","text":"There are several options how the ingredients in the list can be related to the Template Context in the Text. The template could access them by ID, the food name or the position in the list. All options have their benefits and disadvantages. ID : ugly to write and read when not rendered and also more complex from a technical standpoint Name : very nice to read and easy but does not work when a food occurs twice in a step. Could have workaround but would then be inconsistent. Position : easy to write and understand but breaks when ordering is changed and not really nice to read when instructions are not rendered. I decided to go for the position based system. If you know of any better way feel free to open an issue or PR.","title":"Technical Reasoning"},{"location":"install/docker/","text":"Recommended Installation Setting up this application using Docker is recommended. This does not mean that other options are bad, just that support is much easier for this setup. It is possible to install this application using many Docker configurations. Please read the instructions/notes on each example carefully and decide if this is the way for you. Docker The docker image ( vabene1111/recipes ) simply exposes the application on the container's port 8080 . It can be run and accessed on port 80 using: docker run -d \\ -v ./staticfiles:/opt/recipes/staticfiles \\ -v ./mediafiles:/opt/recipes/mediafiles \\ -p 80 :8080 \\ -e SECRET_KEY = YOUR_SECRET_KEY \\ -e DB_ENGINE = django.db.backends.postgresql \\ -e POSTGRES_HOST = db_recipes \\ -e POSTGRES_PORT = 5432 \\ -e POSTGRES_USER = djangodb \\ -e POSTGRES_PASSWORD = YOUR_POSTGRES_SECRET_KEY \\ -e POSTGRES_DB = djangodb \\ --name recipes_1 \\ vabene1111/recipes Please make sure, if you run your image this way, to consult the .env.template file in the GitHub repository to verify if additional environment variables are required for your setup. Versions There are different versions (tags) released on docker hub. latest Default image. The one you should use if you don't know that you need anything else. beta Partially stable version that gets updated every now and then. Expect to have some problems. develop If you want the most bleeding edge version with potentially many breaking changes feel free to use this version (I don't recommend it!). X.Y.Z each released version has its own image. If you need to revert to an old version or want to make sure you stay on one specific use these tags. No Downgrading There is currently no way to migrate back to an older version as there is no mechanism to downgrade the database. You could probably do it but I cannot help you with that. Choose wisely if you want to use the unstable images. That said beta should usually be working if you like frequent updates and new stuff. Docker Compose The main, and also recommended, installation option is to install this application using Docker Compose. Choose your docker-compose.yml from the examples below. Download the .env configuration file with wget , then edit it accordingly . wget https://raw.githubusercontent.com/vabene1111/recipes/develop/.env.template -O .env Start your container using docker-compose up -d . Plain This configuration exposes the application through an nginx web server on port 80 of your machine. wget https://raw.githubusercontent.com/vabene1111/recipes/develop/docs/install/docker/plain/docker-compose.yml version : \"3\" services : db_recipes : restart : always image : postgres:11-alpine volumes : - ./postgresql:/var/lib/postgresql/data env_file : - ./.env web_recipes : image : vabene1111/recipes restart : always env_file : - ./.env volumes : - staticfiles:/opt/recipes/staticfiles - nginx_config:/opt/recipes/nginx/conf.d - ./mediafiles:/opt/recipes/mediafiles depends_on : - db_recipes nginx_recipes : image : nginx:mainline-alpine restart : always ports : - 80:80 env_file : - ./.env depends_on : - web_recipes volumes : - nginx_config:/etc/nginx/conf.d:ro - staticfiles:/static - ./mediafiles:/media volumes : nginx_config : staticfiles : Reverse Proxy Most deployments will likely use a reverse proxy. Traefik If you use traefik, this configuration is the one for you. Info Traefik can be a little confusing to setup. Please refer to their excellent documentation . If that does not help, this little example might be for you. wget https://raw.githubusercontent.com/vabene1111/recipes/develop/docs/install/docker/traefik-nginx/docker-compose.yml version : \"3\" services : db_recipes : restart : always image : postgres:11-alpine volumes : - ./postgresql:/var/lib/postgresql/data env_file : - ./.env networks : - default web_recipes : image : vabene1111/recipes restart : always env_file : - ./.env volumes : - staticfiles:/opt/recipes/staticfiles - nginx_config:/opt/recipes/nginx/conf.d - ./mediafiles:/opt/recipes/mediafiles depends_on : - db_recipes networks : - default nginx_recipes : image : nginx:mainline-alpine restart : always env_file : - ./.env volumes : - nginx_config:/etc/nginx/conf.d:ro - staticfiles:/static - ./mediafiles:/media labels : # traefik example labels - \"traefik.enable=true\" - \"traefik.http.routers.recipes.rule=Host(`recipes.mydomain.com`, `recipes.myotherdomain.com`)\" - \"traefik.http.routers.recipes.entrypoints=web_secure\" # your https endpoint - \"traefik.http.routers.recipes.tls.certresolver=le_resolver\" # your cert resolver depends_on : - web_recipes networks : - default - traefik networks : default : traefik : # This is you external traefik network external : true volumes : nginx_config : staticfiles : nginx-proxy This is a docker compose example using jwilder's nginx reverse proxy in combination with jrcs's letsencrypt companion . Please refer to the appropriate documentation on how to setup the reverse proxy and networks. Remember to add the appropriate environment variables to .env file: VIRTUAL_HOST= LETSENCRYPT_HOST= LETSENCRYPT_EMAIL= wget https://raw.githubusercontent.com/vabene1111/recipes/develop/docs/install/docker/nginx-proxy/docker-compose.yml version : \"3\" services : db_recipes : restart : always image : postgres:11-alpine volumes : - ./postgresql:/var/lib/postgresql/data env_file : - ./.env networks : - default web_recipes : image : vabene1111/recipes restart : always env_file : - ./.env volumes : - staticfiles:/opt/recipes/staticfiles - nginx_config:/opt/recipes/nginx/conf.d - ./mediafiles:/opt/recipes/mediafiles depends_on : - db_recipes networks : - default nginx_recipes : image : nginx:mainline-alpine restart : always env_file : - ./.env depends_on : - web_recipes volumes : - nginx_config:/etc/nginx/conf.d:ro - staticfiles:/static - ./mediafiles:/media networks : - default - nginx-proxy networks : default : nginx-proxy : external : name : nginx-proxy volumes : nginx_config : staticfiles : Additional Information Nginx vs Gunicorn All examples use an additional nginx container to serve mediafiles and act as the forward facing webserver. This is technically not required but very much recommended . I do not 100% understand the deep technical details but the developers of gunicorn , the WSGi server that handles the Python execution, explicitly state that it is not recommended to deploy without nginx. You will also likely not see any decrease in performance or a lot of space used as nginx is a very light container. Info Even if you run behind a reverse proxy as described above, using an additional nginx container is the recommended option. If you run a small private deployment and don't care about performance, security and whatever else feel free to run without a ngix container. Warning When running without nginx make sure to enable GUNICORN_MEDIA in the .env . Without it, media files will be uploaded but not shown on the page. For additional information please refer to the 0.9.0 Release and Issue 201 where these topics have been discussed. See also refer to the official gunicorn docs . Nginx Config In order to give the user (you) the greatest amount of freedom when choosing how to deploy this application the webserver is not directly bundled with the Docker image. This has the downside that it is difficult to supply the configuration to the webserver (e.g. nginx). Up until version 0.13.0 , this had to be done manually by downloading the nginx config file and placing it in a directory that was then mounted into the nginx container. From version 0.13.0 , the config file is supplied using the application image ( vabene1111/recipes ). It is then mounted to the host system and from there into the nginx container. This is not really a clean solution, but I could not find any better alternative that provided the same amount of usability. If you know of any better way, feel free to open an issue. Volumes vs Bind Mounts Since I personally prefer to have my data where my docker-compose.yml resides, bind mounts are used in the example configuration files for all user generated data (e.g. Postgresql and media files). Please note that there is a difference in functionality between the two and you cannot always simply interchange them. You can move everything to volumes if you prefer it this way, but you cannot convert the nginx config file to a bind mount. If you do so you will have to manually create the nginx config file and restart the container once after creating it.","title":"Docker"},{"location":"install/docker/#docker","text":"The docker image ( vabene1111/recipes ) simply exposes the application on the container's port 8080 . It can be run and accessed on port 80 using: docker run -d \\ -v ./staticfiles:/opt/recipes/staticfiles \\ -v ./mediafiles:/opt/recipes/mediafiles \\ -p 80 :8080 \\ -e SECRET_KEY = YOUR_SECRET_KEY \\ -e DB_ENGINE = django.db.backends.postgresql \\ -e POSTGRES_HOST = db_recipes \\ -e POSTGRES_PORT = 5432 \\ -e POSTGRES_USER = djangodb \\ -e POSTGRES_PASSWORD = YOUR_POSTGRES_SECRET_KEY \\ -e POSTGRES_DB = djangodb \\ --name recipes_1 \\ vabene1111/recipes Please make sure, if you run your image this way, to consult the .env.template file in the GitHub repository to verify if additional environment variables are required for your setup.","title":"Docker"},{"location":"install/docker/#versions","text":"There are different versions (tags) released on docker hub. latest Default image. The one you should use if you don't know that you need anything else. beta Partially stable version that gets updated every now and then. Expect to have some problems. develop If you want the most bleeding edge version with potentially many breaking changes feel free to use this version (I don't recommend it!). X.Y.Z each released version has its own image. If you need to revert to an old version or want to make sure you stay on one specific use these tags. No Downgrading There is currently no way to migrate back to an older version as there is no mechanism to downgrade the database. You could probably do it but I cannot help you with that. Choose wisely if you want to use the unstable images. That said beta should usually be working if you like frequent updates and new stuff.","title":"Versions"},{"location":"install/docker/#docker-compose","text":"The main, and also recommended, installation option is to install this application using Docker Compose. Choose your docker-compose.yml from the examples below. Download the .env configuration file with wget , then edit it accordingly . wget https://raw.githubusercontent.com/vabene1111/recipes/develop/.env.template -O .env Start your container using docker-compose up -d .","title":"Docker Compose"},{"location":"install/docker/#plain","text":"This configuration exposes the application through an nginx web server on port 80 of your machine. wget https://raw.githubusercontent.com/vabene1111/recipes/develop/docs/install/docker/plain/docker-compose.yml version : \"3\" services : db_recipes : restart : always image : postgres:11-alpine volumes : - ./postgresql:/var/lib/postgresql/data env_file : - ./.env web_recipes : image : vabene1111/recipes restart : always env_file : - ./.env volumes : - staticfiles:/opt/recipes/staticfiles - nginx_config:/opt/recipes/nginx/conf.d - ./mediafiles:/opt/recipes/mediafiles depends_on : - db_recipes nginx_recipes : image : nginx:mainline-alpine restart : always ports : - 80:80 env_file : - ./.env depends_on : - web_recipes volumes : - nginx_config:/etc/nginx/conf.d:ro - staticfiles:/static - ./mediafiles:/media volumes : nginx_config : staticfiles :","title":"Plain"},{"location":"install/docker/#reverse-proxy","text":"Most deployments will likely use a reverse proxy.","title":"Reverse Proxy"},{"location":"install/docker/#traefik","text":"If you use traefik, this configuration is the one for you. Info Traefik can be a little confusing to setup. Please refer to their excellent documentation . If that does not help, this little example might be for you. wget https://raw.githubusercontent.com/vabene1111/recipes/develop/docs/install/docker/traefik-nginx/docker-compose.yml version : \"3\" services : db_recipes : restart : always image : postgres:11-alpine volumes : - ./postgresql:/var/lib/postgresql/data env_file : - ./.env networks : - default web_recipes : image : vabene1111/recipes restart : always env_file : - ./.env volumes : - staticfiles:/opt/recipes/staticfiles - nginx_config:/opt/recipes/nginx/conf.d - ./mediafiles:/opt/recipes/mediafiles depends_on : - db_recipes networks : - default nginx_recipes : image : nginx:mainline-alpine restart : always env_file : - ./.env volumes : - nginx_config:/etc/nginx/conf.d:ro - staticfiles:/static - ./mediafiles:/media labels : # traefik example labels - \"traefik.enable=true\" - \"traefik.http.routers.recipes.rule=Host(`recipes.mydomain.com`, `recipes.myotherdomain.com`)\" - \"traefik.http.routers.recipes.entrypoints=web_secure\" # your https endpoint - \"traefik.http.routers.recipes.tls.certresolver=le_resolver\" # your cert resolver depends_on : - web_recipes networks : - default - traefik networks : default : traefik : # This is you external traefik network external : true volumes : nginx_config : staticfiles :","title":"Traefik"},{"location":"install/docker/#nginx-proxy","text":"This is a docker compose example using jwilder's nginx reverse proxy in combination with jrcs's letsencrypt companion . Please refer to the appropriate documentation on how to setup the reverse proxy and networks. Remember to add the appropriate environment variables to .env file: VIRTUAL_HOST= LETSENCRYPT_HOST= LETSENCRYPT_EMAIL= wget https://raw.githubusercontent.com/vabene1111/recipes/develop/docs/install/docker/nginx-proxy/docker-compose.yml version : \"3\" services : db_recipes : restart : always image : postgres:11-alpine volumes : - ./postgresql:/var/lib/postgresql/data env_file : - ./.env networks : - default web_recipes : image : vabene1111/recipes restart : always env_file : - ./.env volumes : - staticfiles:/opt/recipes/staticfiles - nginx_config:/opt/recipes/nginx/conf.d - ./mediafiles:/opt/recipes/mediafiles depends_on : - db_recipes networks : - default nginx_recipes : image : nginx:mainline-alpine restart : always env_file : - ./.env depends_on : - web_recipes volumes : - nginx_config:/etc/nginx/conf.d:ro - staticfiles:/static - ./mediafiles:/media networks : - default - nginx-proxy networks : default : nginx-proxy : external : name : nginx-proxy volumes : nginx_config : staticfiles :","title":"nginx-proxy"},{"location":"install/docker/#additional-information","text":"","title":"Additional Information"},{"location":"install/docker/#nginx-vs-gunicorn","text":"All examples use an additional nginx container to serve mediafiles and act as the forward facing webserver. This is technically not required but very much recommended . I do not 100% understand the deep technical details but the developers of gunicorn , the WSGi server that handles the Python execution, explicitly state that it is not recommended to deploy without nginx. You will also likely not see any decrease in performance or a lot of space used as nginx is a very light container. Info Even if you run behind a reverse proxy as described above, using an additional nginx container is the recommended option. If you run a small private deployment and don't care about performance, security and whatever else feel free to run without a ngix container. Warning When running without nginx make sure to enable GUNICORN_MEDIA in the .env . Without it, media files will be uploaded but not shown on the page. For additional information please refer to the 0.9.0 Release and Issue 201 where these topics have been discussed. See also refer to the official gunicorn docs .","title":"Nginx vs Gunicorn"},{"location":"install/docker/#nginx-config","text":"In order to give the user (you) the greatest amount of freedom when choosing how to deploy this application the webserver is not directly bundled with the Docker image. This has the downside that it is difficult to supply the configuration to the webserver (e.g. nginx). Up until version 0.13.0 , this had to be done manually by downloading the nginx config file and placing it in a directory that was then mounted into the nginx container. From version 0.13.0 , the config file is supplied using the application image ( vabene1111/recipes ). It is then mounted to the host system and from there into the nginx container. This is not really a clean solution, but I could not find any better alternative that provided the same amount of usability. If you know of any better way, feel free to open an issue.","title":"Nginx Config"},{"location":"install/docker/#volumes-vs-bind-mounts","text":"Since I personally prefer to have my data where my docker-compose.yml resides, bind mounts are used in the example configuration files for all user generated data (e.g. Postgresql and media files). Please note that there is a difference in functionality between the two and you cannot always simply interchange them. You can move everything to volumes if you prefer it this way, but you cannot convert the nginx config file to a bind mount. If you do so you will have to manually create the nginx config file and restart the container once after creating it.","title":"Volumes vs Bind Mounts"},{"location":"install/kubernetes/","text":"Community Contributed This guide was contributed by the community and is neither officially supported, nor updated or tested. This is a basic kubernetes setup. Please note that this does not necessarily follow Kubernetes best practices and should only used as a basis to build your own setup from! All files con be found here in the Github Repo: docs/install/k8s Important notes State (database, static files and media files) is handled via PersistentVolumes . Note that you will most likely have to change the PersistentVolumes in 30-pv.yaml . The current setup is only usable for a single-node cluster because it uses local storage on the kubernetes worker nodes under /data/recipes/ . It should just serve as an example. Currently, the deployment in 50-deployment.yaml just pulls the latest tag of all containers. In a production setup, you should set this to a fixed version! See env variables tagged with CHANGEME in 50-deployment.yaml and make sure to change those! A better setup would use kubernetes secrets but this is not implemented yet. Updates These manifests are not tested against new versions. Apply the manifets To apply the manifest with kubectl , use the following command: kubectl apply -f ./docs/k8s/","title":"Kubernetes"},{"location":"install/kubernetes/#important-notes","text":"State (database, static files and media files) is handled via PersistentVolumes . Note that you will most likely have to change the PersistentVolumes in 30-pv.yaml . The current setup is only usable for a single-node cluster because it uses local storage on the kubernetes worker nodes under /data/recipes/ . It should just serve as an example. Currently, the deployment in 50-deployment.yaml just pulls the latest tag of all containers. In a production setup, you should set this to a fixed version! See env variables tagged with CHANGEME in 50-deployment.yaml and make sure to change those! A better setup would use kubernetes secrets but this is not implemented yet.","title":"Important notes"},{"location":"install/kubernetes/#updates","text":"These manifests are not tested against new versions.","title":"Updates"},{"location":"install/kubernetes/#apply-the-manifets","text":"To apply the manifest with kubectl , use the following command: kubectl apply -f ./docs/k8s/","title":"Apply the manifets"},{"location":"install/manual/","text":"Manual installation instructions These intructions are inspired from a standard django/gunicorn/postgresql instructions ( for example ) Warning Be sure to use python 3.9 and pip related to python 3.9. Depending on your distribution calling python or pip will use python2 instead of python 3.9. Prerequisites Setup user: sudo useradd recipes Get the last version from the repository: git clone https://github.com/vabene1111/recipes.git -b master Move it to the /var/www directory: mv recipes /var/www Change to the directory: cd /var/www/recipes Give the user permissions: chown -R recipes:www-data /var/www/recipes Create virtual env: python3.9 -m venv /var/www/recipes Install Javascript Tools apt install nodejs npm install --global yarn Install postgresql requirements sudo apt install libpq-dev postgresql Install project requirements Update Dependencies change with most updates so the following steps need to be re-run with every update or else the application might stop working. See section Updating below Using binaries from the virtual env: /var/www/recipes/bin/pip3.9 install -r requirements.txt You will also need to install front end requirements and build them. For this navigate to the ./vue folder and run yarn install yarn build Setup postgresql sudo -u postgres psql In the psql console: CREATE DATABASE djangodb ; CREATE USER djangouser WITH PASSWORD 'password' ; GRANT ALL PRIVILEGES ON DATABASE djangodb TO djangouser ; ALTER DATABASE djangodb OWNER TO djangouser ; --Maybe not necessary, but should be faster: ALTER ROLE djangouser SET client_encoding TO 'utf8' ; ALTER ROLE djangouser SET default_transaction_isolation TO 'read committed' ; ALTER ROLE djangouser SET timezone TO 'UTC' ; --Grant superuser right to your new user, it will be removed later ALTER USER djangouser WITH SUPERUSER ; Download the .env configuration file and edit it accordingly . wget https://raw.githubusercontent.com/vabene1111/recipes/develop/.env.template -O /var/www/recipes/.env Things to edit: - SECRET_KEY : use something secure. - POSTGRES_HOST : probably 127.0.0.1. - POSTGRES_PASSWORD : the password we set earlier when setting up djangodb. - STATIC_URL , MEDIA_URL : these will be in /var/www/recipes , under /staticfiles/ and /mediafiles/ respectively. Initialize the application Execute export $(cat /var/www/recipes/.env |grep \"^[^#]\" | xargs) to load variables from /var/www/recipes/.env Execute bin/python3.9 manage.py migrate and revert superuser from postgres: sudo -u postgres psql and ALTER USER djangouser WITH NOSUPERUSER; Generate static files: bin/python3.9 manage.py collectstatic and bin/python3.9 manage.py collectstatic_js_reverse and remember the folder where files have been copied. Setup web services gunicorn Create a service that will start gunicorn at boot: sudo nano /etc/systemd/system/gunicorn_recipes.service And enter these lines: [Unit] Description=gunicorn daemon for recipes After=network.target [Service] Type=simple Restart=always RestartSec=3 User=recipes Group=www-data WorkingDirectory=/var/www/recipes EnvironmentFile=/var/www/recipes/.env ExecStart=/var/www/recipes/bin/gunicorn --error-logfile /tmp/gunicorn_err.log --log-level debug --capture-output --bind unix:/var/www/recipes/recipes.sock recipes.wsgi:application [Install] WantedBy=multi-user.target Note : -error-logfile /tmp/gunicorn_err.log --log-level debug --capture-output are usefull for debugging and can be removed later Note2 : Fix the path in the ExecStart line to where you gunicorn and recipes are Finally, run sudo systemctl enable gunicorn_recipes and sudo systemctl start gunicorn_recipes . You can check that the service is correctly started with systemctl status gunicorn_recipes nginx Now we tell nginx to listen to a new port and forward that to gunicorn. sudo nano /etc/nginx/conf.d/recipes.conf And enter these lines: server { listen 8002 ; #access_log /var/log/nginx/access.log; #error_log /var/log/nginx/error.log; # serve media files location /staticfiles { alias /var/www/recipes/staticfiles ; } location /mediafiles { alias /var/www/recipes/mediafiles ; } location / { proxy_set_header Host $http_host ; proxy_pass http://unix:/var/www/recipes/recipes.sock ; proxy_set_header X-Forwarded-Proto $scheme ; } } Note : Enter the correct path in static and proxy_pass lines. Reload nginx : sudo systemctl reload nginx Updating In order to update the application you will need to run the following commands (probably best to put them into a small script). # Update source files git pull # load envirtonment variables export $( cat /var/www/recipes/.env | grep \"^[^#]\" | xargs ) # migrate database bin/python3.9 manage.py migrate # collect static files bin/python3.9 manage.py collectstatic bin/python3.9 manage.py collectstatic_js_reverse # change to frontend directory cd vue # install and build frontend yarn install yarn build # restart gunicorn service sudo systemctl restart gunicorn_recipes","title":"Manual"},{"location":"install/manual/#manual-installation-instructions","text":"These intructions are inspired from a standard django/gunicorn/postgresql instructions ( for example ) Warning Be sure to use python 3.9 and pip related to python 3.9. Depending on your distribution calling python or pip will use python2 instead of python 3.9.","title":"Manual installation instructions"},{"location":"install/manual/#prerequisites","text":"Setup user: sudo useradd recipes Get the last version from the repository: git clone https://github.com/vabene1111/recipes.git -b master Move it to the /var/www directory: mv recipes /var/www Change to the directory: cd /var/www/recipes Give the user permissions: chown -R recipes:www-data /var/www/recipes Create virtual env: python3.9 -m venv /var/www/recipes Install Javascript Tools apt install nodejs npm install --global yarn","title":"Prerequisites"},{"location":"install/manual/#install-postgresql-requirements","text":"sudo apt install libpq-dev postgresql","title":"Install postgresql requirements"},{"location":"install/manual/#install-project-requirements","text":"Update Dependencies change with most updates so the following steps need to be re-run with every update or else the application might stop working. See section Updating below Using binaries from the virtual env: /var/www/recipes/bin/pip3.9 install -r requirements.txt You will also need to install front end requirements and build them. For this navigate to the ./vue folder and run yarn install yarn build","title":"Install project requirements"},{"location":"install/manual/#setup-postgresql","text":"sudo -u postgres psql In the psql console: CREATE DATABASE djangodb ; CREATE USER djangouser WITH PASSWORD 'password' ; GRANT ALL PRIVILEGES ON DATABASE djangodb TO djangouser ; ALTER DATABASE djangodb OWNER TO djangouser ; --Maybe not necessary, but should be faster: ALTER ROLE djangouser SET client_encoding TO 'utf8' ; ALTER ROLE djangouser SET default_transaction_isolation TO 'read committed' ; ALTER ROLE djangouser SET timezone TO 'UTC' ; --Grant superuser right to your new user, it will be removed later ALTER USER djangouser WITH SUPERUSER ; Download the .env configuration file and edit it accordingly . wget https://raw.githubusercontent.com/vabene1111/recipes/develop/.env.template -O /var/www/recipes/.env Things to edit: - SECRET_KEY : use something secure. - POSTGRES_HOST : probably 127.0.0.1. - POSTGRES_PASSWORD : the password we set earlier when setting up djangodb. - STATIC_URL , MEDIA_URL : these will be in /var/www/recipes , under /staticfiles/ and /mediafiles/ respectively.","title":"Setup postgresql"},{"location":"install/manual/#initialize-the-application","text":"Execute export $(cat /var/www/recipes/.env |grep \"^[^#]\" | xargs) to load variables from /var/www/recipes/.env Execute bin/python3.9 manage.py migrate and revert superuser from postgres: sudo -u postgres psql and ALTER USER djangouser WITH NOSUPERUSER; Generate static files: bin/python3.9 manage.py collectstatic and bin/python3.9 manage.py collectstatic_js_reverse and remember the folder where files have been copied.","title":"Initialize the application"},{"location":"install/manual/#setup-web-services","text":"","title":"Setup web services"},{"location":"install/manual/#gunicorn","text":"Create a service that will start gunicorn at boot: sudo nano /etc/systemd/system/gunicorn_recipes.service And enter these lines: [Unit] Description=gunicorn daemon for recipes After=network.target [Service] Type=simple Restart=always RestartSec=3 User=recipes Group=www-data WorkingDirectory=/var/www/recipes EnvironmentFile=/var/www/recipes/.env ExecStart=/var/www/recipes/bin/gunicorn --error-logfile /tmp/gunicorn_err.log --log-level debug --capture-output --bind unix:/var/www/recipes/recipes.sock recipes.wsgi:application [Install] WantedBy=multi-user.target Note : -error-logfile /tmp/gunicorn_err.log --log-level debug --capture-output are usefull for debugging and can be removed later Note2 : Fix the path in the ExecStart line to where you gunicorn and recipes are Finally, run sudo systemctl enable gunicorn_recipes and sudo systemctl start gunicorn_recipes . You can check that the service is correctly started with systemctl status gunicorn_recipes","title":"gunicorn"},{"location":"install/manual/#nginx","text":"Now we tell nginx to listen to a new port and forward that to gunicorn. sudo nano /etc/nginx/conf.d/recipes.conf And enter these lines: server { listen 8002 ; #access_log /var/log/nginx/access.log; #error_log /var/log/nginx/error.log; # serve media files location /staticfiles { alias /var/www/recipes/staticfiles ; } location /mediafiles { alias /var/www/recipes/mediafiles ; } location / { proxy_set_header Host $http_host ; proxy_pass http://unix:/var/www/recipes/recipes.sock ; proxy_set_header X-Forwarded-Proto $scheme ; } } Note : Enter the correct path in static and proxy_pass lines. Reload nginx : sudo systemctl reload nginx","title":"nginx"},{"location":"install/manual/#updating","text":"In order to update the application you will need to run the following commands (probably best to put them into a small script). # Update source files git pull # load envirtonment variables export $( cat /var/www/recipes/.env | grep \"^[^#]\" | xargs ) # migrate database bin/python3.9 manage.py migrate # collect static files bin/python3.9 manage.py collectstatic bin/python3.9 manage.py collectstatic_js_reverse # change to frontend directory cd vue # install and build frontend yarn install yarn build # restart gunicorn service sudo systemctl restart gunicorn_recipes","title":"Updating"},{"location":"install/other/","text":"Community Contributed The examples in this section were contributed by members of the community. This page especially contains some setups that might help you if you really want to go down a certain path but none of the examples are supported (as I simply am not able to give you support for them). Apache + Traefik + Sub-Path This guide was contributes by incaseoftrouble in Issue #266 My setup is docker-compose / traefik / apache / recipes. Swapping out apache for nginx should be straightforward. Relevant parts: docker-compose: apache : # omitting other config volumes : - ./recipes/static:/var/www/recipes/static:ro - ./recipes/media:/var/www/recipes/media:ro labels : traefik.enable : true traefik.http.routers.apache-recipes.rule : Host(`<host>`) && PathPrefix(`/<www path>`) traefik.http.routers.apache-recipes.entrypoints : http traefik.http.routers.apache-recipes.service : apache traefik.http.services.apache.loadbalancer.server.port : 80 traefik.http.services.apache.loadbalancer.server.scheme : http ... recipes : volumes : - ./recipes/static:/opt/recipes/staticfiles:rw - ./recipes/media:/opt/recipes/mediafiles:rw environment : # all the other env - SCRIPT_NAME=/<sub path> - JS_REVERSE_SCRIPT_PREFIX=/<sub path>/ - STATIC_URL=/<www path>/static/ - MEDIA_URL=/<www path>/media/ labels : traefik.enable : true traefik.http.routers.recipes.rule : Host(`<host>`) && PathPrefix(`/<sub path>`) traefik.http.routers.recipes.entrypoints : http traefik.http.services.recipes.loadbalancer.server.port : 8080 traefik.http.services.recipes.loadbalancer.server.scheme : http apache: Alias /<www path>/static/ /var/www/recipes/static/ Alias /<www path>/media/ /var/www/recipes/media/ <Directory \"/var/www/recipes/\"> Require all granted </Directory> I used two paths <sub path> and <www path> for simplicity. In my case I have <sub path> = recipes and <www path> = serve/recipes . One could also change the matching rules of traefik to have everything under one path. I left out the TLS config in this example for simplicty.","title":"Other setups"},{"location":"install/other/#apache-traefik-sub-path","text":"This guide was contributes by incaseoftrouble in Issue #266 My setup is docker-compose / traefik / apache / recipes. Swapping out apache for nginx should be straightforward. Relevant parts: docker-compose: apache : # omitting other config volumes : - ./recipes/static:/var/www/recipes/static:ro - ./recipes/media:/var/www/recipes/media:ro labels : traefik.enable : true traefik.http.routers.apache-recipes.rule : Host(`<host>`) && PathPrefix(`/<www path>`) traefik.http.routers.apache-recipes.entrypoints : http traefik.http.routers.apache-recipes.service : apache traefik.http.services.apache.loadbalancer.server.port : 80 traefik.http.services.apache.loadbalancer.server.scheme : http ... recipes : volumes : - ./recipes/static:/opt/recipes/staticfiles:rw - ./recipes/media:/opt/recipes/mediafiles:rw environment : # all the other env - SCRIPT_NAME=/<sub path> - JS_REVERSE_SCRIPT_PREFIX=/<sub path>/ - STATIC_URL=/<www path>/static/ - MEDIA_URL=/<www path>/media/ labels : traefik.enable : true traefik.http.routers.recipes.rule : Host(`<host>`) && PathPrefix(`/<sub path>`) traefik.http.routers.recipes.entrypoints : http traefik.http.services.recipes.loadbalancer.server.port : 8080 traefik.http.services.recipes.loadbalancer.server.scheme : http apache: Alias /<www path>/static/ /var/www/recipes/static/ Alias /<www path>/media/ /var/www/recipes/media/ <Directory \"/var/www/recipes/\"> Require all granted </Directory> I used two paths <sub path> and <www path> for simplicity. In my case I have <sub path> = recipes and <www path> = serve/recipes . One could also change the matching rules of traefik to have everything under one path. I left out the TLS config in this example for simplicty.","title":"Apache + Traefik + Sub-Path"},{"location":"install/synology/","text":"Community Contributed This guide was contributed by the community and is neither officially supported, nor updated or tested. Many people appear to host this application on their Synology NAS. The following documentation was provided by @therealschimmi in this issue discussion . There is also this ( word , pdf ) awesome and very detailed guide provided by @DiversityBug. There are, as always, most likely other ways to do this but this can be used as a starting point for your setup. Since I cannot test it myself feedback and improvements are always very welcome. Instructions Basic guide to setup vabenee1111/recipes docker container on Synology NAS Login to Synology DSM through your browser Install Docker through package center Optional: Create a shared folder for your docker projects, they have to store data somewhere outside the containers Create a folder somewhere, I suggest naming it 'recipes' and storing it in the dedicated docker folder Within, create the necessary folder structure. You will need these folders: Download templates vabene1111 gives you a few samples for various setups to work with. I chose to use the plain setup for now. Open https://github.com/vabene1111/recipes/tree/develop/docs/install/docker Download docker-compose.yml to your recipes folder Open https://github.com/vabene1111/recipes/tree/develop/nginx/conf.d Download Recipes.conf to your conf.d folder Open https://github.com/vabene1111/recipes/blob/develop/.env.template Copy the text and save it as '.env' to your recipes folder (no filename extension!) Add a POSTGRES_PASSWORD Once done, it should look like this: Edit docker-compose.yml Open docker-compose.yml in a text editor This file tells docker how to setup recipes. Docker will create three containers for recipes to work, recipes, nginx and postgresql. They are all required and need to store and share data through the folders you created before. Edit line 26, this line specifies which external synology port will point to which internal docker port. Chose a free port to use and replace the first number with it. You will open recipes by browsing to http://your.synology.ip:chosen.port, e.g. http://192.168.1.1:2000 If you want to use port 2000 you would edit to 2000:80 SSH into your Synology You need to access your Synology through SSH execute following commands ssh root@your.synology.ip connect to your synology. root password is the same as admin password, sometimes root access is not possible for whatever reason, then replace root with admin cd /volume1/docker/recipes access the folder where you store docker-compose.yml docker-compose up -d this starts your containers according to your docker-compose.yml. if you logged in with admin you will have to use sudo docker-compose up -d instead, it will ask for the admin password again. This output tells you all 3 containers have been setup ... Creating recipes_nginx_recipes_1 ... done Creating recipes_db_recipes_1 ... done Creating recipes_web_recipes_1 ... done Browse to 192.168.1.1:2000 or whatever your IP and port are While the containers are starting and doing whatever they need to do, you might still get HTTP errors e.g. 500 or 502. Just be patient and try again in a moment Additional SSL Setup create foler ssl inside nginx folder download your ssl certificate from security tab in dsm control panel or create a task in task manager because Synology will update the certificate every few months set task to repeat every day in the script write: SRC=\"/usr/syno/etc/certificate/system/default\" DEST=\"/volume1/docker/recipes/nginx/ssl/\" if [ ! -f \"$DEST/fullchain.pem\" ] || [ \"$SRC/fullchain.pem\" -nt \"$DEST/fullchain.pem\" ]; then cp \"$SRC/fullchain.pem\" \"$DEST/\" cp \"$SRC/privkey.pem\" \"$DEST/\" chown root:root \"$DEST/fullchain.pem\" \"$DEST/privkey.pem\" chmod 600 \"$DEST/fullchain.pem\" \"$DEST/privkey.pem\" /usr/syno/bin/synowebapi --exec api=SYNO.Docker.Container version=1 method=restart name=recipes_nginx_recipes_1 fi change docker-compose.yml add - ./nginx/ssl:/etc/nginx/certs to the volumes of nginx_recipes","title":"Synology"},{"location":"install/synology/#instructions","text":"Basic guide to setup vabenee1111/recipes docker container on Synology NAS Login to Synology DSM through your browser Install Docker through package center Optional: Create a shared folder for your docker projects, they have to store data somewhere outside the containers Create a folder somewhere, I suggest naming it 'recipes' and storing it in the dedicated docker folder Within, create the necessary folder structure. You will need these folders: Download templates vabene1111 gives you a few samples for various setups to work with. I chose to use the plain setup for now. Open https://github.com/vabene1111/recipes/tree/develop/docs/install/docker Download docker-compose.yml to your recipes folder Open https://github.com/vabene1111/recipes/tree/develop/nginx/conf.d Download Recipes.conf to your conf.d folder Open https://github.com/vabene1111/recipes/blob/develop/.env.template Copy the text and save it as '.env' to your recipes folder (no filename extension!) Add a POSTGRES_PASSWORD Once done, it should look like this: Edit docker-compose.yml Open docker-compose.yml in a text editor This file tells docker how to setup recipes. Docker will create three containers for recipes to work, recipes, nginx and postgresql. They are all required and need to store and share data through the folders you created before. Edit line 26, this line specifies which external synology port will point to which internal docker port. Chose a free port to use and replace the first number with it. You will open recipes by browsing to http://your.synology.ip:chosen.port, e.g. http://192.168.1.1:2000 If you want to use port 2000 you would edit to 2000:80 SSH into your Synology You need to access your Synology through SSH execute following commands ssh root@your.synology.ip connect to your synology. root password is the same as admin password, sometimes root access is not possible for whatever reason, then replace root with admin cd /volume1/docker/recipes access the folder where you store docker-compose.yml docker-compose up -d this starts your containers according to your docker-compose.yml. if you logged in with admin you will have to use sudo docker-compose up -d instead, it will ask for the admin password again. This output tells you all 3 containers have been setup ... Creating recipes_nginx_recipes_1 ... done Creating recipes_db_recipes_1 ... done Creating recipes_web_recipes_1 ... done Browse to 192.168.1.1:2000 or whatever your IP and port are While the containers are starting and doing whatever they need to do, you might still get HTTP errors e.g. 500 or 502. Just be patient and try again in a moment Additional SSL Setup create foler ssl inside nginx folder download your ssl certificate from security tab in dsm control panel or create a task in task manager because Synology will update the certificate every few months set task to repeat every day in the script write: SRC=\"/usr/syno/etc/certificate/system/default\" DEST=\"/volume1/docker/recipes/nginx/ssl/\" if [ ! -f \"$DEST/fullchain.pem\" ] || [ \"$SRC/fullchain.pem\" -nt \"$DEST/fullchain.pem\" ]; then cp \"$SRC/fullchain.pem\" \"$DEST/\" cp \"$SRC/privkey.pem\" \"$DEST/\" chown root:root \"$DEST/fullchain.pem\" \"$DEST/privkey.pem\" chmod 600 \"$DEST/fullchain.pem\" \"$DEST/privkey.pem\" /usr/syno/bin/synowebapi --exec api=SYNO.Docker.Container version=1 method=restart name=recipes_nginx_recipes_1 fi change docker-compose.yml add - ./nginx/ssl:/etc/nginx/certs to the volumes of nginx_recipes","title":"Instructions"},{"location":"install/traefik/","text":"Danger Please refer to the offical documentation . This example just shows something similar to my setup in case you dont understand the offical documentation. You need to create a network called traefik using docker network create traefik . docker-compose.yml version: \"3.3\" services: traefik: image: \"traefik:v2.1\" container_name: \"traefik\" ports: - \"443:443\" - \"80:80\" - \"8080:8080\" volumes: - \"./letsencrypt:/letsencrypt\" - \"/var/run/docker.sock:/var/run/docker.sock:ro\" - \"./config:/etc/traefik/\" networks: default: external: name: traefik traefik.toml Place this in a directory called config as this is mounted into the traefik container (see docer compose). Change the email address accordingly . [api] insecure=true [providers.docker] endpoint = \"unix:///var/run/docker.sock\" exposedByDefault = false network = \"traefik\" #[log] # level = \"DEBUG\" [entryPoints] [entryPoints.web] address = \":80\" [entryPoints.web_secure] address = \":443\" [certificatesResolvers.le_resolver.acme] email = \"you_email@mail.com\" storage = \"/letsencrypt/acme.json\" tlsChallenge=true","title":"Traefik"},{"location":"install/traefik/#docker-composeyml","text":"version: \"3.3\" services: traefik: image: \"traefik:v2.1\" container_name: \"traefik\" ports: - \"443:443\" - \"80:80\" - \"8080:8080\" volumes: - \"./letsencrypt:/letsencrypt\" - \"/var/run/docker.sock:/var/run/docker.sock:ro\" - \"./config:/etc/traefik/\" networks: default: external: name: traefik","title":"docker-compose.yml"},{"location":"install/traefik/#traefiktoml","text":"Place this in a directory called config as this is mounted into the traefik container (see docer compose). Change the email address accordingly . [api] insecure=true [providers.docker] endpoint = \"unix:///var/run/docker.sock\" exposedByDefault = false network = \"traefik\" #[log] # level = \"DEBUG\" [entryPoints] [entryPoints.web] address = \":80\" [entryPoints.web_secure] address = \":443\" [certificatesResolvers.le_resolver.acme] email = \"you_email@mail.com\" storage = \"/letsencrypt/acme.json\" tlsChallenge=true","title":"traefik.toml"},{"location":"install/unraid/","text":"Community Contributed This guide was contributed by the community and is neither officially supported, nor updated or tested. Unraid is an operating system that allows you to easily install and setup applications. Thanks to CorneliousJD this application can easily be installed using unraid. Please view Issue #184 for further details. There is also a discussion thread on the unraid forum where he gives additional information. Installation Recipes for unRAID is avialble via Community Applications. You will first need to install Community Applications (CA) by following the directions here: https://forums.unraid.net/topic/38582-plug-in-community-applications/ After that, you can go to the \"Apps\" tab in unRAID and search for Recipes and locate the Recipes container and install it. The default settings should by fine for most users, just be sure to enter a secret key that is randomly generated. Then chooose apply. After the container installs, click on the Recipes icon and click the WebUI button to launch the web user interface. Set the container to auto-start if you wish.","title":"Unraid"},{"location":"install/unraid/#installation","text":"Recipes for unRAID is avialble via Community Applications. You will first need to install Community Applications (CA) by following the directions here: https://forums.unraid.net/topic/38582-plug-in-community-applications/ After that, you can go to the \"Apps\" tab in unRAID and search for Recipes and locate the Recipes container and install it. The default settings should by fine for most users, just be sure to enter a secret key that is randomly generated. Then chooose apply. After the container installs, click on the Recipes icon and click the WebUI button to launch the web user interface. Set the container to auto-start if you wish.","title":"Installation"},{"location":"system/backup/","text":"There is currently no \"good\" way of backing up your data implemented in the application itself. This mean that you will be responsible for backing up your data. It is planned to add a \"real\" backup feature similar to applications like homeassistant where a snapshot can be downloaded and restored trough the web interface. Warning When developing a new backup strategy, make sure to also test the restore process! Database Please use any standard way of backing up your database. For most systems this can be achieved by using a dump command that will create an SQL file with all the required data. Please refer to your Database System documentation. I personally use a little script that I have created to automatically pull SQL dumps from a postgresql database. It is neither well tested nor documented so use at your own risk. I would recommend using it only as a starting place for your own backup strategy. Mediafiles The only Data this application stores apart from the database are the media files (e.g. images) used in your recipes. They can be found in the mediafiles mounted directory (depending on your installation). To create a backup of those files simply copy them elsewhere. Do it the other way around for restoring. The filenames consist of <random uuid4>_<recipe_id> . In case you screw up really badly this can help restore data.","title":"Backup"},{"location":"system/backup/#database","text":"Please use any standard way of backing up your database. For most systems this can be achieved by using a dump command that will create an SQL file with all the required data. Please refer to your Database System documentation. I personally use a little script that I have created to automatically pull SQL dumps from a postgresql database. It is neither well tested nor documented so use at your own risk. I would recommend using it only as a starting place for your own backup strategy.","title":"Database"},{"location":"system/backup/#mediafiles","text":"The only Data this application stores apart from the database are the media files (e.g. images) used in your recipes. They can be found in the mediafiles mounted directory (depending on your installation). To create a backup of those files simply copy them elsewhere. Do it the other way around for restoring. The filenames consist of <random uuid4>_<recipe_id> . In case you screw up really badly this can help restore data.","title":"Mediafiles"},{"location":"system/permissions/","text":"WIP This application was developed for private use in a trusted environment. Due to popular demand a basic permission system has been added. It does its job protecting the most critical parts of the application, but it is not yet recommended to give accounts to completely untrusted users. Work is done to improve the permission system, but it's not yet fully done and tested. Permission levels The following table roughly defines the capabilities of each role Group Capabilities logged in user Can do almost nothing without a group. guest - Search and view recipes - write comments - change user settings (e.g. language, theme, password) user Can do basically everything except for what admins can do admin - Create, edit and delete external storage - Create, edit and delete synced paths django superuser Ignores all permission checks and can access admin interface Creating User accounts Warning Users without groups cannot do anything. Make sure to assign them a group! You can either create new users trough the admin interface or by sending them invite links. Invite links can be generated on the System page. If you specify a username during the creation of the link the person using it won't be able to change that name. Managing Permissions Management of permissions can currently only be achieved trough the django admin interface. Warning Please do not rename the groups as this breaks the permission system.","title":"Permission System"},{"location":"system/permissions/#permission-levels","text":"The following table roughly defines the capabilities of each role Group Capabilities logged in user Can do almost nothing without a group. guest - Search and view recipes - write comments - change user settings (e.g. language, theme, password) user Can do basically everything except for what admins can do admin - Create, edit and delete external storage - Create, edit and delete synced paths django superuser Ignores all permission checks and can access admin interface","title":"Permission levels"},{"location":"system/permissions/#creating-user-accounts","text":"Warning Users without groups cannot do anything. Make sure to assign them a group! You can either create new users trough the admin interface or by sending them invite links. Invite links can be generated on the System page. If you specify a username during the creation of the link the person using it won't be able to change that name.","title":"Creating User accounts"},{"location":"system/permissions/#managing-permissions","text":"Management of permissions can currently only be achieved trough the django admin interface. Warning Please do not rename the groups as this breaks the permission system.","title":"Managing Permissions"},{"location":"system/updating/","text":"The Updating process depends on your chosen method of installation While intermediate updates can be skipped when updating please make sure to read the release notes in case some special action is required to update. Docker For all setups using Docker the updating process look something like this Before updating it is recommended to create a backup ! Stop the container using docker-compose down Pull the latest image using docker-compose pull Start the container again using docker-compose up -d Manual For all setups using a manual installation updates usually involve downloading the latest source code from GitHub. After that make sure to run: manage.py collectstatic manage.py migrate To apply all new migrations and collect new static files.","title":"Updating"},{"location":"system/updating/#docker","text":"For all setups using Docker the updating process look something like this Before updating it is recommended to create a backup ! Stop the container using docker-compose down Pull the latest image using docker-compose pull Start the container again using docker-compose up -d","title":"Docker"},{"location":"system/updating/#manual","text":"For all setups using a manual installation updates usually involve downloading the latest source code from GitHub. After that make sure to run: manage.py collectstatic manage.py migrate To apply all new migrations and collect new static files.","title":"Manual"}]}