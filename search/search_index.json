{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"Tandoor Recipes    The recipe manager that allows you to manage your ever growing collection of digital recipes. <p> Website \u2022 Installation \u2022 Docs \u2022 Demo \u2022 Community \u2022 Discord </p> <p></p>"},{"location":"#core-features","title":"Core Features","text":"<ul> <li>\ud83e\udd57 Manage your recipes with a fast and intuitive editor</li> <li>\ud83d\udcc6 Plan multiple meals for each day</li> <li>\ud83d\uded2 Shopping lists via the meal plan or straight from recipes</li> <li>\ud83d\udcda Cookbooks collect recipes into books</li> <li>\ud83d\udc6a Share and collaborate on recipes with friends and family</li> </ul>"},{"location":"#made-by-and-for-power-users","title":"Made by and for power users","text":"<ul> <li>\ud83d\udd0d Powerful &amp; customizable search with fulltext support and TrigramSimilarity</li> <li>\ud83c\udff7\ufe0f Create and search for tags, assign them in batch to all files matching certain filters</li> <li>\u2194\ufe0f Quickly merge and rename ingredients, tags and units </li> <li>\ud83d\udce5\ufe0f Import recipes from thousands of websites supporting ld+json or microdata</li> <li>\u2797 Support for fractions or decimals</li> <li>\ud83d\udc33 Easy setup with Docker and included examples for Kubernetes, Unraid and Synology</li> <li>\ud83c\udfa8 Customize your interface with themes</li> <li>\ud83d\udce6 Sync files with Dropbox and Nextcloud</li> </ul>"},{"location":"#all-the-must-haves","title":"All the must haves","text":"<ul> <li>\ud83d\udcf1  Optimized for use on mobile devices</li> <li>\ud83c\udf0d Localized in many languages thanks to the awesome community</li> <li>\ud83d\udce5\ufe0f Import your collection from many other recipe managers</li> <li>\u2795 Many more like recipe scaling, image compression, printing views and supermarkets</li> </ul> <p>This application is meant for people with a collection of recipes they want to share with family and friends or simply store them in a nicely organized way. A basic permission system exists but this application is not meant to be run as  a public page.</p>"},{"location":"#your-feedback","title":"Your Feedback","text":"<p>Share some information on how you use Tandoor to help me improve the application Google Survey</p>"},{"location":"#get-in-touch","title":"Get in touch","text":"Community Get support, share best practices, discuss feature ideas, and meet other Tandoor users. Discord We have a public Discord server that anyone can join. This is where all our developers and contributors hang out and where we make announcements"},{"location":"#roadmap","title":"Roadmap","text":"<p>This application has been under rapid development over the last year. During this time I have learnt a lot and added tons of features, I have also moved to some new technologies like Vue.js. This has led to some great features but has left the Quality unsatisfactory in regard to the details and technical implementation.</p> <p>So in addition to the new Features and Ideas which can always be found in the Issues &amp; Milestones there are some greater overall goals for the future (in no particular order)</p> <ul> <li>Improve the UI! The Design is inconsistent and many pages work but don't look great. This needs to change.</li> <li>I strongly believe in Open Data and Systems. Thus adding importers and exporters for all relevant other recipe management systems is something i really want to do.</li> <li>Move all Javascript Libraries to a packet manager and clean up some of the mess I made in the early days</li> <li>Improve Test coverage and also the individual tests themselves</li> <li>Improve the documentation for all features and aspects of this project and add some application integrated help</li> </ul>"},{"location":"#about","title":"About","text":"<p>This application has originally been developed to index, tag and search my collection of digital (PDF) recipes. Over the time tons of features have been added making this the most comprehensive recipe management system. </p> <p>I am just a single developer with many other interests and obligations so development and support might be slow at times,  but I try my best to constantly improve this application.</p> <p>If you have any wishes, feature requests, problems or ideas feel free to open an issue on GitHub.</p>"},{"location":"faq/","title":"FAQ","text":"<p>There are several questions and issues that come up from time to time, here are some answers: please note that the existence of some questions is due the application not being perfect in some parts. Many of those shortcomings are planned to be fixed in future release but simply could not be addressed yet due to time limits.</p>"},{"location":"faq/#is-there-a-tandoor-app","title":"Is there a Tandoor app?","text":"<p>Tandoor can be installed as a progressive web app (PWA) on mobile and desktop devices. The PWA stores recently accessed recipes locally for offline use.</p>"},{"location":"faq/#mobile-browsers","title":"Mobile browsers","text":""},{"location":"faq/#safari-iphoneipad","title":"Safari (iPhone/iPad)","text":"<p>Open Tandoor, click Safari's share button, select <code>Add to Home Screen</code></p>"},{"location":"faq/#chromechromium","title":"Chrome/Chromium","text":"<p>Open Tandoor, click the <code>add Tandoor to the home screen</code> message that pops up at the bottom of the screen</p>"},{"location":"faq/#firefox-for-android","title":"Firefox for Android","text":"<p>Open Tandoor, click on the <code>\u22ee</code> menu icon, then on <code>Install</code></p>"},{"location":"faq/#desktop-browsers","title":"Desktop browsers","text":""},{"location":"faq/#google-chrome","title":"Google Chrome","text":"<p>Open Tandoor, open the menu behind the three vertical dots at the top right, select <code>Install Tandoor Recipes...</code></p>"},{"location":"faq/#microsoft-edge","title":"Microsoft Edge","text":"<p>Open Tandoor, open the menu behind the three horizontal dots at the top right, select <code>Apps &gt; Install Tandoor Recipes</code></p>"},{"location":"faq/#why-is-tandoor-not-working-correctly","title":"Why is Tandoor not working correctly?","text":"<p>If you just set up your Tandoor instance and you're having issues like;</p> <ul> <li>Links not working</li> <li>CSRF errors</li> <li>CORS errors</li> <li>No recipes are loading</li> </ul> <p>then make sure you have set all required headers in your reverse proxy correctly. If that doesn't fix it, you can also refer to the appropriate sub section in the reverse proxy documentation and verify your general webserver configuration.</p>"},{"location":"faq/#required-headers","title":"Required Headers","text":"<p>Navigate to <code>/system/</code> and review the headers listed in the DEBUG section.  At a minimum, if you are using a reverse proxy the headers must match the below conditions.</p> Header Requirement HTTP_HOST:mydomain.tld The host domain must match the url that you are using to open Tandoor. HTTP_X_FORWARDED_HOST:mydomain.tld The host domain must match the url that you are using to open Tandoor. HTTP_X_FORWARDED_PROTO:http(s) The protocol must match the url you are using to open Tandoor.  There must be exactly one protocol listed. HTTP_X_SCRIPT_NAME:/subfolder If you are hosting Tandoor at a subfolder instead of a subdomain this header must exist."},{"location":"faq/#why-am-i-getting-csrf-errors","title":"Why am I getting CSRF Errors?","text":"<p>If you are getting CSRF Errors this is most likely due to a reverse proxy not passing the correct headers.</p> <p>If you are using swag by linuxserver you might need <code>proxy_set_header X-Forwarded-Proto $scheme;</code> in your nginx config. If you are using a plain ngix you might need <code>proxy_set_header Host $http_host;</code>.</p> <p>Further discussions can be found in this Issue #518</p>"},{"location":"faq/#why-are-images-not-loading","title":"Why are images not loading?","text":"<p>If images are not loading this might be related to the same issue as the CSRF errors (see above). A discussion about that can be found at Issue #452</p> <p>The other common issue is that the recommended nginx container is removed from the deployment stack. If removed, the nginx webserver needs to be replaced by something else that servers the /mediafiles/ directory or <code>GUNICORN_MEDIA</code> needs to be enabled to allow media serving by the application container itself.</p>"},{"location":"faq/#why-am-i-getting-an-error-stating-database-files-are-incompatible-with-server","title":"Why am I getting an error stating database files are incompatible with server?","text":"<p>Your version of Postgres has been upgraded.  See Updating PostgreSQL</p>"},{"location":"faq/#why-does-the-textmarkdown-preview-look-different-than-the-final-recipe","title":"Why does the Text/Markdown preview look different than the final recipe?","text":"<p>Tandoor has always rendered the recipe instructions markdown on the server. This also allows tandoor to implement things like ingredient templating and scaling in text. To make editing easier a markdown editor was added to the frontend with integrated preview as a temporary solution. Since the markdown editor uses a different specification than the server the preview is different to the final result. It is planned to improve this in the future.</p> <p>The markdown renderer follows this markdown specification https://daringfireball.net/projects/markdown/</p>"},{"location":"faq/#why-is-tandoor-not-working-on-my-raspberry-pi","title":"Why is Tandoor not working on my Raspberry Pi?","text":"<p>Please refer to here.</p>"},{"location":"faq/#how-can-i-create-users","title":"How can I create users?","text":"<p>To create a new user click on your name (top right corner) and select 'space settings'. Click create listed below invites.</p> <p>It is not possible to create users through the admin because users must be assigned a default group and space.</p> <p>To change a user's space you need to go to the admin and select User Infos.</p> <p>If you use an external auth provider or proxy authentication make sure to specify a default group and space in the environment configuration.</p>"},{"location":"faq/#what-are-spaces","title":"What are spaces?","text":"<p>Spaces are is a type of feature used to separate one installation of Tandoor into several parts. In technical terms it is a multi-tenant system.</p> <p>You can compare a space to something like google drive or dropbox. There is only one installation of the Dropbox system, but it handles multiple users without them noticing each other. For Tandoor that means all people that work together on one recipe collection can be in one space. If you want to host the collection of your friends, family, or neighbor you can create a separate space for them (through the admin interface).</p> <p>Sharing between spaces is currently not possible but is planned for future releases.</p>"},{"location":"faq/#how-can-i-reset-passwords","title":"How can I reset passwords?","text":"<p>To reset a lost password if access to the container is lost you need to:</p> <ol> <li>execute into the container using <code>docker-compose exec web_recipes sh</code></li> <li>activate the virtual environment <code>source venv/bin/activate</code></li> <li>run <code>python manage.py changepassword &lt;username&gt;</code> and follow the steps shown.</li> </ol>"},{"location":"faq/#how-can-i-add-an-admin-user","title":"How can I add an admin user?","text":"<p>To create a superuser you need to</p> <ol> <li>execute into the container using <code>docker-compose exec web_recipes sh</code></li> <li>activate the virtual environment <code>source venv/bin/activate</code></li> <li>run <code>python manage.py createsuperuser</code> and follow the steps shown.</li> </ol>"},{"location":"faq/#why-cant-i-get-support-for-my-manual-setup","title":"Why cant I get support for my manual setup?","text":"<p>Even tough I would love to help everyone get tandoor up and running I have only so much time that I can spend on this project besides work, family and other life things. Due to the countless problems that can occur when manually installing I simply do not have the time to help solving each one.</p> <p>You can install Tandoor manually but please do not expect me or anyone to help you with that.  As a general advice: If you do it manually do NOT change anything at first and slowly work yourself  to your dream setup.</p>"},{"location":"faq/#how-can-i-upgrade-postgres-major-versions","title":"How can I upgrade postgres (major versions)?","text":"<p>Postgres requires manual intervention when updating from one major version to another. The steps are roughly</p> <ol> <li>use <code>pg_dumpall</code> to dump your database into SQL (for Docker <code>docker-compose exec -T &lt;postgres_container_name&gt; pg_dumpall -U &lt;postgres_user_name&gt; -f /path/to/dump.sql</code>)</li> <li>stop the DB / down the container</li> <li>move your postgres directory in order to keep it as a backup (e.g. <code>mv postgres postgres_old</code>)</li> <li>update postgres to the new major version (for Docker just change the version number and pull)</li> <li>start the db / up the container (do not start tandoor as it will automatically perform the database migrations which will conflict with loading the dump)</li> <li>if not using docker, you might need to create the same postgres user you had in the old database</li> <li>load the postgres dump (for Docker <code>'/usr/local/bin/docker-compose exec -T &lt;postgres_container_name&gt; psql -U &lt;postgres_user_name&gt; &lt;postgres_database_name&gt; &lt; /path/to/dump.sql</code>)</li> </ol> <p>If anything fails, go back to the old postgres version and data directory and try again. </p> <p>There are many articles and tools online that might provide a good starting point to help you upgrade 1, 2, 3. </p>"},{"location":"contribute/contribute/","title":"Overview","text":"<p>If you like this application and want it to give back, there are many ways to contribute.</p> <p>Contribution List</p> <p>If you help bring this project forward you deserve to be credited for it.  Feel free to add yourself to <code>CONTRIBUTERS.md</code> or message me to add you if you have contributed anything.</p>"},{"location":"contribute/contribute/#translations","title":"Translations","text":"<p>If you know any foreign languages you can: Improve the translations for any of the existing languages.</p> <p>See here for further information on how to contribute translation to Tandoor.</p>"},{"location":"contribute/contribute/#issues-and-feature-requests","title":"Issues and Feature Requests","text":"<p>The most basic but also crucial way of contributing is reporting issues and commenting on ideas and feature requests over at GitHub issues.</p> <p>Without feedback, improvement can't happen, so don't hesitate to say what you want to say.</p>"},{"location":"contribute/contribute/#documentation","title":"Documentation","text":"<p>Helping improve the documentation for Tandoor is one of the easiest ways to give back and doesn't even require deep technical knowledge. You can write guides on how to install and configure Tandoor expanding our repository of non-standard configuations. Or you can write how-to guides using some of Tandoor's advanced features such as authentication or automation.</p> <p>See here for more information on how to add documentation to Tandoor.</p>"},{"location":"contribute/contribute/#contributing-code","title":"Contributing Code","text":"<p>For the truly ambitious, you can help write code to fix issues, add additional features, or write your own scripts using Tandoor's extensive API and share your work with the community.</p> <p>Guides for contributing specific types of features can be found here</p> <p>Before writing any code, please make sure that you review contribution guidelines and VSCode or PyCharm specific configurations.</p>"},{"location":"contribute/documentation/","title":"Documentation","text":"<p>The documentation is built from the markdown files in the docs folder of the GitHub repository.</p> <p>In order to contribute to the documentation, there are a couple of methods that you can use.</p>"},{"location":"contribute/documentation/#directly-on-github","title":"Directly on GitHub","text":"<p>You can fork the develop repository and edit the markdown files directly on the GitHub website.</p>"},{"location":"contribute/documentation/#with-an-ide","title":"With an IDE","text":"<p>You can fork the develop repository and edit the markdown files from your favorite IDE such as VSCode or PyCharm. One advantage of using as IDE is that you can preview your changes by:</p>"},{"location":"contribute/documentation/#installing-mkdocs","title":"Installing mkdocs","text":"<p>Now install mkdocs and dependencies: <code>pip install mkdocs-material mkdocs-include-markdown-plugin</code>.</p>"},{"location":"contribute/documentation/#serving-documetation","title":"Serving Documetation","text":"<p>If you want to test the documentation, locally run <code>mkdocs serve</code> from the project root.</p>"},{"location":"contribute/documentation/#super-low-tech","title":"Super Low Tech","text":"<p>Create your documentation in any work processor (or even create a video!) and open a feature request attaching your document and requesting that someone add the documentation to Tandoor.</p>"},{"location":"contribute/guidelines/","title":"Code","text":"<p>If you want to contribute bug fixes or small tweaks then your pull requests are always welcome!</p> <p>Discuss First!</p> <p>If you want to contribute larger features that introduce more complexity to the project please  make sure to first submit a technical description outlining what and how you want to do it.  This allows me and the community to give feedback and manage the complexity of the overall  application. If you don't do this please don't be mad if I reject your PR.</p>"},{"location":"contribute/guidelines/#license","title":"License","text":"<p>Contributing to Tandoor requires signing a Contributor License Agreement. You can review the CLA here.</p>"},{"location":"contribute/guidelines/#linting-formatting","title":"Linting &amp; Formatting","text":"<p>Tandoor uses a number of libraries to maintain style and formatting consistency. To contribute to the project you are required to use the following packages with the project defined configurations:</p> <ul> <li>flake8</li> <li>yapf</li> <li>isort</li> <li>prettier</li> </ul> <p>Manual Formatting</p> <p>It is possible to run formatting manually, but it is recommended to setup your IDE to format on save.  <code>bash  flake8 file.py --ignore=E501 | isort -q file.py | yapf -i file.py  prettier --write file.vue</code></p>"},{"location":"contribute/guidelines/#testing","title":"Testing","text":"<p>Django uses pytest-django to implement a full suite of testing. If you make any functional changes, please implement the appropriate tests.</p> <p>Tandoor is also actively soliciting contributors willing to setup vue3 testing. If you have knowledge in this area it would be greatly appreciated.</p>"},{"location":"contribute/guidelines/#api-client","title":"API Client","text":"<p>JAVA required</p> <p>The OpenAPI Generator is a Java project. You must have the java binary executable available on your PATH for this to work.</p> <p>Tandoor uses django-rest-framework for API implementation. Making contributions that impact the API requires an understanding of ViewSets and Serializers.</p> <p>The API Client is generated automatically from the OpenAPI interface provided by the Django REST framework. For this openapi-generator is used.</p> <p>Install it using your desired setup method. (For example, using <code>npm install @openapitools/openapi-generator-cli -g</code>.)</p>"},{"location":"contribute/guidelines/#vue","title":"Vue","text":"<p>Generate the schema using the <code>generate_api_client.py</code> script in the main directory. </p>"},{"location":"contribute/guidelines/#install-and-configuration","title":"Install and Configuration","text":"<p>Instructions for VSCode Instructions for PyCharm</p>"},{"location":"contribute/installation/","title":"Installation","text":"<p>Development Setup</p> <p>The dev setup is a little messy as this application combines the best (at least in my opinion) of both Django and Vue.js.</p>"},{"location":"contribute/installation/#devcontainer-setup","title":"Devcontainer Setup","text":"<p>There is a devcontainer set up to ease development. It is optimized for VSCode, but should be able to be used by other editors as well. Once the container is running, you can do things like start a Django dev server, start a Vue.js dev server, run python tests, etc. by either using the VSCode tasks below, or manually running commands described in the individual technology sections below.</p> <p>In VSCode, simply check out the git repository, and then via the command palette, choose <code>Dev Containers: Reopen in container</code>.</p> <p>If you need to change python dependencies (requierments.txt) or OS packages, you will need to rebuild the container. If you are changing OS package requirements, you will need to update both the main <code>Dockerfile</code> and the <code>.devcontainer/Dockerfile</code>.</p>"},{"location":"contribute/installation/#django","title":"Django","text":"<p>This application is developed using the Django framework for Python. They have excellent documentation on how to get started, so I will only give you the basics here.</p> <ol> <li>Clone this repository wherever you like and install the Python language for your OS (I recommend using version 3.10 or above).</li> <li>Open it in your favorite editor/IDE (e.g. PyCharm).    a. If you want, create a virtual environment for all your packages.</li> <li>Install all required packages: <code>pip install -r requirements.txt</code>.</li> <li>Run the migrations: <code>python manage.py migrate</code>.</li> <li>Start the development server: <code>python manage.py runserver</code>.</li> </ol> <p>There is no need to set any environment variables. By default, a simple SQLite database is used and all settings are populated from default values.</p>"},{"location":"contribute/installation/#vuejs","title":"Vue.js","text":"<p>Development Setup</p> <p>The vite dev server must be started before the django runserver command is run or else django will not recognize it and try to fallback to the build files. </p> <p>The frontend is build using Vue.js.</p> <p>In order to work on these pages, you will have to install a Javascript package manager of your choice. The following examples use yarn.</p> <ol> <li>go to the <code>vue3</code> and run <code>yarn install</code> to install the dependencies  </li> <li>run <code>yarn serve</code> to start the dev server that allows hot reloading and easy and quick development</li> </ol> <p>If you do not wish to work on those pages, but instead want the application to work properly during development, run <code>yarn build</code> to build the frontend pages once. After that you  might need to run <code>python manage.py collectstatic</code> to setup the static files.</p>"},{"location":"contribute/installation/#building-docker-image-from-source","title":"Building Docker Image from Source","text":"<p>Similar to the Vue.js procedure, if you wish to build a docker image from source run you must build the vue3 files first.</p> <ol> <li>in your project files navigate to <code>vue3</code> and run <code>yarn install</code> to install the dependencies</li> <li>run <code>yarn build</code> to build the static files for django to use.</li> <li>navigate back to the root directory and run <code>docker build -t ${tag}:${version} .</code></li> </ol> <p>Django's <code>collectstatic</code> command is not necessary in this instance as the <code>Dockerfile</code>'s entrypoint will collect the static files upon startup on <code>docker run</code>. </p>"},{"location":"contribute/pycharm/","title":"PyCharm","text":"<p>PyCharm can be configured to format and lint on save. Doing so requires some manual configuration as outlined below.</p>"},{"location":"contribute/pycharm/#setup-file-watchers","title":"Setup File Watchers","text":"<ol> <li>Navigate to File -&gt; Settings -&gt; Plugins</li> <li>Download and install File Watchers</li> <li>Navigate to File -&gt; Settings -&gt; Tools -&gt; Black</li> <li>Confirm 'Use Black Formatter' is unchecked for both 'On code reformat' and 'On save'</li> </ol>"},{"location":"contribute/pycharm/#setup-flake8-watcher","title":"Setup flake8 Watcher","text":"<ol> <li>Navigate to File -&gt; Settings -&gt; Tools -&gt; File Watchers</li> <li>Click the '+' to add a new watcher.</li> <li>Configure the watcher as below.</li> </ol> <ol> <li>Navigate to File -&gt; Settings -&gt; Editor -&gt; Inspections -&gt; File watcher problems</li> <li>Under Severity select 'Edit Severities'</li> <li>Click the '+' to add a severity calling it 'Linting Error'</li> <li>Configure a background and effect as below.</li> </ol>"},{"location":"contribute/pycharm/#setup-isort","title":"Setup isort","text":"<ol> <li>Navigate to File -&gt; Settings -&gt; Tools -&gt; File Watchers</li> <li>Click the '+' to add a new watcher.</li> <li>Configure the watcher as below.</li> </ol>"},{"location":"contribute/pycharm/#setup-yapf","title":"Setup yapf","text":"<ol> <li>Navigate to File -&gt; Settings -&gt; Tools -&gt; File Watchers</li> <li>Click the '+' to add a new watcher.</li> <li>Configure the watcher as below.</li> </ol> <p>Hint</p> <p>Adding a comma at the end of a list will trigger yapf to put each element of the list on a new line</p> <p>Note</p> <p>In order to debug vue yarn and vite servers must be started before starting the django server.</p>"},{"location":"contribute/pycharm/#setup-prettier","title":"Setup prettier","text":"<ol> <li>Navigate to File -&gt; Settings -&gt; Tools -&gt; File Watchers</li> <li>Click the '+' to add a new watcher.</li> <li>Change 'File Type' to 'Any'.</li> <li>Click the three dots next to 'Scope' to create a custom scope.</li> <li> <p>Click '+' to add a new scope</p> </li> <li> <p>Name: prettier</p> </li> <li> <p>Pattern: <code>file:vue/src//*||file:vue3/src//*||file:docs//*</code></p> </li> <li> <p>Configure the watcher as below.</p> </li> </ol> <p></p> <ul> <li>Arguments: <code>--cwd $ProjectFileDir$\\vue prettier -w --config $ProjectFileDir$\\.prettierrc $FilePath$</code></li> </ul>"},{"location":"contribute/related/","title":"Related Projects","text":""},{"location":"contribute/related/#recipe-scraper","title":"Recipe Scraper","text":"<p>While not directly related to Tandoor, we make extensive use of the brilliant recipe-scrapers package by hhursev.</p> <p>If you have the skills to add new sites or help resolve issues you are indirectly helping Tandoor.</p>"},{"location":"contribute/related/#unofficial-mobile-apps","title":"Unofficial mobile apps","text":""},{"location":"contribute/related/#kitshn","title":"kitshn","text":"<p>Unofficial Tandoor recipes client</p> <p>Maintained by Aimo</p> <ul> <li>Website: https://kitshn.app/</li> <li>Appstores: Apple, Android</li> </ul>"},{"location":"contribute/related/#untare-discontinued","title":"Untare (discontinued)","text":"<p>Maintained by phantomate</p> <p>iPhone Android</p>"},{"location":"contribute/related/#gpt-recipe","title":"GPT Recipe","text":"<p>Maintained by John Pedrie</p> <p>Convert pictures of recipes to a structure that can be imported to Tandoor with ChatGPT.</p>"},{"location":"contribute/related/#tandoor-menu-generator","title":"Tandoor Menu Generator","text":"<p>Maintained by smilerz</p> <p>Generate a meal plan based on complex criteria and optionally insert it into an SVG menu template.</p>"},{"location":"contribute/translations/","title":"Translations","text":"<p>Translations are managed on translate.tandoor.dev, a self hosted instance of Weblate.</p> <p>You can simply register an account and then follow these steps to add translations:</p> <ol> <li>After registering, you are asked to select your languages. This is optional but allows weblate to only show you relevant translations.</li> <li>In the navigation click on <code>Projects</code> and then <code>Browse all projects</code>.</li> <li>Select Tandoor and on the top-right hand corner, select <code>Watch project Tandoor</code> (click on <code>Not watching</code>).</li> <li>Go back to the dashboard. It now shows you the relevant translations for your languages. Click on the pencil icon to get started.</li> </ol> <p>Creating a new language</p> <p>To create a new language you must first select Tandoor (the project) and then a component.  Here you will have the option to add the language. Afterwards you can also simply add it to the other components as well.  Once a new language is (partially) finished let me know on GitHub so I can add it to the language-switcher in Tandoor itself.</p> <p>There is also a lot of documentation available from Weblate directly.</p> <p></p> <p>It is also possible to provide the translations directly by creating a new language using <code>manage.py makemessages -l &lt;language_code&gt; -i venv</code>. Once finished, simply open a PR with the changed files. This sometimes causes issues merging with weblate, so I would prefer the use of weblate.</p>"},{"location":"contribute/vscode/","title":"VSCode","text":"<p>Configurations for debugging django, volar, testing, linting and formatting are all include in the project files.</p>"},{"location":"contribute/vscode/#extensions","title":"Extensions","text":"<p>VSCode can be configured to format and lint on save instead of manually formatting files before submitting a pull request. To enable auto-formatting and linting install the following extensions in VSCode:</p> <p>Name: Flake8 Publisher: Microsoft VS Marketplace Link: https://marketplace.visualstudio.com/items?itemName=ms-python.flake8</p> <p>Name: yapf Publisher: EeyoreLee VS Marketplace Link: https://marketplace.visualstudio.com/items?itemName=eeyore.yapf</p> <p>Name: isort Publisher: Microsoft VS Marketplace Link: https://marketplace.visualstudio.com/items?itemName=ms-python.isort</p> <p>Name: Vue - Official Publisher: Vue VS Marketplace Link: https://marketplace.visualstudio.com/items?itemName=Vue.volar</p> <p>Name: Prettier - Code formatter Publisher: Prettier VS Marketplace Link: https://marketplace.visualstudio.com/items?itemName=esbenp.prettier-vscode</p> <p>Hint</p> <p>Adding a comma at the end of a list will trigger yapf to put each element of the list on a new line</p>"},{"location":"contribute/vscode/#vscode-tasks","title":"VSCode Tasks","text":"<p>Note</p> <p>In order to hot reload vue, the <code>yarn dev</code> server must be started before starting the django server.</p> <p>There are a number of built in tasks that are available. Here are a few of the key ones:</p> <ul> <li><code>Setup Dev Server</code> - Runs all the prerequisite steps so that the dev server can be run inside VSCode.</li> <li><code>Setup Tests</code> - Runs all prerequisites so tests can be run inside VSCode.</li> </ul> <p>Once these are run, there are 2 options.  If you want to run a vue3 server in a hot reload mode for quick development of the frontend, you should run a development vue server:</p> <ul> <li><code>Yarn Dev</code> - Runs development Vue.js vite server not connected to VSCode. Useful if you want to make Vue changes and see them in realtime.</li> </ul> <p>If not, you need to build and copy the frontend to the django server.  If you make changes to the frontend, you need to re-run this and restart the django server:</p> <ul> <li><code>Collect Static Files</code> - Builds and collects the vue3 frontend so that it can be served via the django server.</li> </ul> <p>Once either of those steps are done, you can start the django server:</p> <ul> <li><code>Run Dev Server</code> - Runs a django development server not connected to VSCode.</li> </ul> <p>There are also a few other tasks specified in case you have specific development needs:</p> <ul> <li><code>Run all pytests</code> - Runs all the pytests outside of VSCode.</li> <li><code>Serve Documentation</code> - Runs a documentation server. Useful if you want to see how changes to documentation show up.</li> </ul>"},{"location":"contribute/feature_contrib/Integration/","title":"Import / Export Integration Contribution Guide","text":""},{"location":"contribute/feature_contrib/Integration/#setup","title":"Setup","text":"<p>There are 5 files you need to configure in order create a new integration 1. Create a new integration class in <code>/cookbook/integration/</code> 2. Include integration in <code>/cookbook/forms.py</code>  3. Add the new integration class import and include in the 'if' chain in <code>/cookbook/views/import_export.py</code> 4. Add your integration to the documentation at <code>/docs/features/import_export.md</code> 5. Include integration and docs link in <code>/vue3/src/utils/integration_utils.ts</code></p>"},{"location":"contribute/feature_contrib/Integration/#1-creating-a-new-integration-class","title":"1. Creating a New Integration Class","text":"<p>Your integration class should be named after what you are integrating with and should inherit from the <code>Integration</code> class. Use the template below to setup your class.</p> <p><code>/cookbook/integration/yourintegration.py</code> <pre><code>from io import BytesIO, StringIO\nfrom zipfile import ZipFile\n\nfrom cookbook.integration.integration import Integration\n# from cookbook.helper.ingredient_parser import IngredientParser\n# import other cookbook.helper as necessary\nfrom cookbook.models import  Ingredient, Keyword, NutritionInformation, Recipe, Step\n\n\nclass YourIntegrationName(Integration):\n\n    def get_recipe_from_file(self, file) -&gt; Recipe:\n        #Import Recipe Logic - convert information from file into Recipe() object\n        pass\n\n    def import_file_name_filter(self, file) -&gt; bool:\n        #check file extension, return True if extension is correct\n        pass\n\n    def get_file_from_recipe(self, recipe) -&gt; tuple[str,str]:\n        #Export Recipe Logic - convert from Recipe() object to a writable string in your integration's format\n        # return 'Filename.extension', 'file string'\n        pass\n\n    def get_files_from_recipes(self, recipes, el, cookie) -&gt; list[list[str,bytes]]:\n        # 'el' and 'cookie' are passed through by the calling function 'do_export'\n        export_zip_stream = BytesIO()\n        export_zip_obj = ZipFile(export_zip_stream, 'w')\n\n        for recipe in recipes:\n            if True: #add any verification logic\n                # get string data and filename from get_file_from_recipe() method and save it to a zip stream\n                recipe_stream = StringIO()\n                filename, data = self.get_file_from_recipe(recipe)\n                recipe_stream.write(data)\n                export_zip_obj.writestr(f'{recipe.name}/{filename}', recipe_stream.getvalue())\n                recipe_stream.close()\n\n            el.exported_recipes += 1\n            el.msg += self.get_recipe_processed_msg(recipe)\n            el.save()\n\n        export_zip_obj.close()\n\n        # returns a [[file name, zip stream data]]\n        # self.get_export_file_name is an inherited from the Integration class and doesn't require definition\n        return [[self.get_export_file_name(), export_zip_stream.getvalue()]]\n</code></pre></p>"},{"location":"contribute/feature_contrib/Integration/#2-including-in-formspy","title":"2. including in Forms.py","text":"<p>In the <code>/cookbook/forms.py</code> find the <code>ImportExportBase</code> class and add to it the following amoung the others: <pre><code>YOURINTEGRATION = \"YOURINTEGRATION\"\n</code></pre> Then you will find under that the following declaration:</p> <p><code>type = forms.ChoiceField(choices=())</code> the choices will have a long list of tuples. Add to the list of tuples the following:</p> <pre><code>(YOURINTEGRATION, 'Your Integration'),\n</code></pre>"},{"location":"contribute/feature_contrib/Integration/#3-including-in-views","title":"3. Including in Views","text":"<p>In the <code>/cookbook/views/import_export.py</code> import your integration</p> <pre><code>from cookbook.integration.yourintegration import YourIntegration\n</code></pre> <p>Then add the following code to the long <code>if</code> chain:</p> <pre><code>if export_type == ImportExportBase.YOURINTEGRATION:\n    return YourIntegration(request, export_type)\n</code></pre> <p>be careful to use the exact all caps name of your integration that you used in the <code>cookbook/forms.py</code> or else it won't recognize it as a type. the snake case is the class that you defined in <code>/cookbook/integration</code></p>"},{"location":"contribute/feature_contrib/Integration/#4-add-to-the-documentation","title":"4. Add to the Documentation","text":"<p>If nothing else, you at least have to add one slugline about your integration in the <code>/docs/features/import_export.md</code> because the Vue pages require a link to send the send the user to if they hit the information button on the import/export form.</p> <p>Go to the bottom of the doc and add: <pre><code>## YourIntegration\na little blurb about how it works or anything users should know about how the data needs to be formated.\n</code></pre></p> <p>Additionally add your integration to the table at the top of the document, marking the state of your integration, or wait until it is integrated and tested before adding to the table.</p>"},{"location":"contribute/feature_contrib/Integration/#5-add-to-vue-integration-utils","title":"5. Add to Vue Integration Utils","text":"<p>In the <code>/vue3/src/utils/integration_utils.ts</code> find <code>export const INTEGRATIONS: Array&lt;Integration&gt;</code> and in the long list add: <pre><code>{id: 'YOURINTEGRATION', name: \"Your Integration\", import: true, export: false, helpUrl: 'https://docs.tandoor.dev/features/import_export/#yourintegration'},\n</code></pre> be sure to change 'true' or 'false' value for the import and export options to the correct values for your integration. 'true' indicates that it should be listed in the menu for imports or exports respectively.</p>"},{"location":"contribute/feature_contrib/Integration/#be-sure-to-update-vue-using-yarn-after-to-be-sure-the-html-files-get-updated","title":"Be sure to update vue using <code>yarn</code> after to be sure the html files get updated","text":""},{"location":"contribute/feature_contrib/Integration/#integration-test-setup","title":"Integration Test Setup","text":""},{"location":"contribute/feature_contrib/Integration/#file-structure-and-files","title":"File Structure and Files","text":"<p>Tandoor uses Pytest to implement its testing features. To add tests and test documents navigate to  <pre><code>cookbook/tests/other/\n</code></pre> There you can create a test file <code>test_yourintegration.py</code>. It is very important that it starts with \"test_\" as that is how pytest knows to run it as a test.</p> <p>For the text files that you will want to parse and test for your integration you can put them at:</p> <p><pre><code>cookbook/test/other/test_data/your_integration/\n</code></pre> making your own folder for your test inputs there. When directing your tests to pull the files from that folder make sure to include the whole path starting at <code>cookbook/</code></p>"},{"location":"contribute/feature_contrib/Integration/#creating-an-integration-test-with-a-request-object","title":"Creating an Integration Test with a Request object","text":"<p>Like the filename, inside the file <code>test_yourintegration.py</code> pytest looks specifically for the functions that start with the string <code>test_</code> any function that does not have that prefex won't be run. This is useful if you want to define helper methods to your tests.</p> <p>Since your integration is a child of the <code>Integration</code> class you must pass your integration the required arguments: <code>request</code> and <code>export_type</code>. Unless your test has a specific export_type you are trying to test, it is not consequential what you put for <code>export_type</code>, so long as it is a string. I generally just use \"export\" in my test. For request though we need to generate one</p> <p>You can accomplish this with the following code: <pre><code>from io import BytesIO\n\nfrom django.contrib import auth\nfrom django.test import RequestFactory\nfrom django_scopes import scope\n\nfrom cookbook.integration.cooklang import YourIntegrationClass\n\ndef test_yourintegration(u1_s1):\n    user = auth.get_user(u1_s1)\n    space = user.userspace_set.first().space\n    request = RequestFactory()\n    request.user = user\n    request.space = space\n\n    with scope(space=space):\n        integration_object = YourIntegrationClass(request, \"export\")\n        with open(\"cookbook/test/other/test_data/your_integration/recipe_file.txt\", \"rb\") as file:\n            recipe_bytes = file.read()\n            recipe_name = file.name\n        buffer = BytesIO(recipe_bytes)\n        buffer.name = recipe_name\n        recipe_object = integration_object.get_recipe_from_file(buffer)\n        # all of your test function logic inside this with clause \n</code></pre> though it is not important for you to understand, the u1_s1 is a pytest fixture that can be passed into your tests. By adding it as an argument for the test, pytest will fill that fixture in and you can use it to get a test user using the <code>auth.get_user()</code> method</p> <p>with that you can add your assertions and test it using pytest.</p>"},{"location":"contribute/feature_contrib/Integration/#integration-class-logic","title":"Integration Class Logic","text":"<p>Now that the setup is complete you need to implement the logic on the new Integration class you created.</p>"},{"location":"contribute/feature_contrib/Integration/#get_recipe_from_file-method","title":"get_recipe_from_file method","text":"<p>This function is called by the <code>Integration.do_import()</code> class method when a file is imported through the web portal. The <code>get_recipe_from_file(self, file)</code> takes only a file as an argument, which is passed from the <code>Integration.do_import()</code> as an <code>IOByte</code> binary object containing only the binary characters of the contents of the file, as well as a property called <code>name</code> that has a \"utf-8\" string of what the file name was.</p>"},{"location":"contribute/feature_contrib/Integration/#reading-the-file","title":"Reading the File","text":"<p>To get the string values of the contents of the file, you must call the following methods:</p> <p><pre><code>file_text = file.getvalue().decode(\"utf-8\")\n</code></pre> Then you can parse the file_text however you see fit for your integration. no need to do a <code>with open()</code> statement. The <code>Integration</code> parent class handles the opening and the closing of the file.</p> <p>If your recipe name is dependent on the filename you can access the file name with: <pre><code>filename = file.name\n</code></pre></p>"},{"location":"contribute/feature_contrib/Integration/#managing-the-tandoor-recipe-object","title":"Managing the Tandoor 'Recipe' Object","text":"<p>The <code>Recipe</code> class has many properties, and it is recommended to view all of them here in order to determine specifically how your integration will organize its data into the <code>Recipe</code> object data structure. The important ones to know are: <pre><code>name = models.CharField(max_length=128)\ndescription = models.CharField(max_length=512, blank=True, null=True)\nservings = models.IntegerField(default=1)\nservings_text = models.CharField(default='', blank=True, max_length=32)\nimage = models.ImageField(upload_to='recipes/', blank=True, null=True)\nkeywords = models.ManyToManyField(Keyword, blank=True)\nsteps = models.ManyToManyField(Step, blank=True)\ninternal = models.BooleanField(default=False)\n\ncreated_by = models.ForeignKey(User, on_delete=models.PROTECT)\n\nspace = models.ForeignKey(Space, on_delete=models.CASCADE)\n</code></pre> You can define as many of these variables as you like at the time of creating the Recipe object but the bare minimum should be:</p> <p><pre><code>from cookbook.models import Recipe\n\ndef get_recipe_from_file(self, file)-&gt; Recipe:\n    #opening the file and parsing it\n\n    recipe_object = Recipe.objects.create(\n        name = your_recipe_name,\n        created_by = self.request.user,\n        internal = True,\n        space = self.request.space,\n    )\n\n    #translating the parsed file into th recipe object\n\n    return recipe_object\n</code></pre> Both <code>created_by</code> and <code>space</code> require the request object from the webpage or API that initiated the request, the <code>Integration</code> parent class handles both of those and they can be retrieved through the <code>self.request</code> property. The <code>name</code> allows the recipe to be identifiable from the other recipes, making it uniquely identifiable from other newly instantiated <code>Recipe</code> objects. lasty <code>True</code> is the default value for <code>internal</code> only change it to false if that is what you intend.</p> <p>After the <code>Recipe</code> object is created you can change or add data to its properties, these changes will show up in tests and work as expected until the program drops it from memory. Then all those changes will be lost unless you use the <code>.save()</code> method. It is recommended not to use the <code>.save()</code> after every change, but instead to make all your changes and call <code>.save()</code> once at the end of the <code>get_recipe_from_file</code> method before the object gets returned back to the <code>Integration.do_import()</code> method.</p> <pre><code>from cookbook.models import Recipe\n\ndef get_recipe_from_file(self, file)-&gt; Recipe:\n    #opening the file and parsing it\n\n    recipe_object = Recipe.objects.create(\n        name = your_recipe_name,\n        created_by = self.request.user,\n        internal = True,\n        space = self.request.space,\n    )\n\n    # Integration logic, making many changes to the recipe_object\n\n    recipe_object.description = \"A yummy treat for any day!\"\n    recipe_object.save()\n    return recipe_object\n</code></pre>"},{"location":"contribute/feature_contrib/Integration/#other-models-you-need-to-know","title":"Other Models You Need To Know","text":"<p>The 3 main models other than <code>Recipe</code> you will need to use are the <code>Step</code>, <code>Ingredient</code>(also <code>Food</code> and <code>Unit</code>- They all go hand in hand), and <code>Keyword</code>. The rough structure of these object in a <code>Recipe</code> are:</p> <p>(Note that the <code>Recipe</code> object is not a <code>Json</code> object, the below is just a representation of the data) <pre><code>{Recipe: \n    [{\"steps\": \n        [{Step: [\n            {\"ingredients\": [\n                {Ingredient: \n                  {\"food\": \n                    {Food:\n                      [{\"name\": \"food name\"},\n                        {Unit: {\"name\": \"unit name\"}},\n                        {\"amount\": int}\n                    ]}}}]},\n            {\"instruction\": \"recipe step text\"}\n        ]}]},\n    {\"keywords\": [\n        {Keyword: \n          {\"name\": \"keyword name\"}\n        }]}]}\n</code></pre> Below are their bare-bones implementations in regard to creating a <code>Recipe</code> object integration.</p> <pre><code>from cookbook.models import Recipe, Keyword, Step, Ingredient, Food, Unit\n\ndef get_recipe_from_file(self, file)-&gt; Recipe:\n    #opening the file and parsing it\n\n    recipe_object = Recipe.objects.create(\n        name = your_recipe_name,\n        created_by = self.request.user,\n        internal = True,\n        space = self.request.space,)\n\n    #logic for creating a list of keywords\n\n    for keyword in parsed_file.keywords:\n        recipe_object.keywords.add(\n            Keyword.objects.get_or_create(\n                space=self.request.space, \n                name=keyword)[0])\n\n    i = 0\n    for line in parsed_file:\n        #logic for creating a list of ingredients\n        #logic for instructions\n        step = Step.objects.create(\n            instruction=line.instruction_string, \n            order=i, \n            space=self.request.space, \n            show_ingredients_table=self.request.user.userpreference.show_step_ingredients)\n        for ingredient in line.ingredients:\n            step.ingredients.add(\n                Ingredient.objects.create(\n                    food=Food.objects.get_or_create(name=ingredient.name, space=self.request.space)[0],\n                    unit=Unit.objects.get_or_create(name=ingredient.quantity.unit, space=self.request.space)[0],\n                    amount=ingredient.quantity.amount,\n                    space=self.request.space, ))\n        recipe_object.steps.add(step)\n        i+=1\n    recipe_object.save()\n    return recipe_object\n</code></pre>"},{"location":"contribute/feature_contrib/Integration/#import_file_name_filter-method","title":"import_file_name_filter method","text":"<p>Documentation to come.</p>"},{"location":"contribute/feature_contrib/Integration/#get_file_from_recipe-method","title":"get_file_from_recipe method","text":"<p>Documentation to come.</p>"},{"location":"contribute/feature_contrib/Integration/#get_files_from_recipes-method","title":"get_files_from_recipes method","text":"<p>Documentation to come.</p>"},{"location":"contribute/feature_contrib/featureguides/","title":"Featureguides","text":"<p>If there is a not a guide below for the type of feature you wish to implement then please add a request on github for the type of feature you wish to contribute. </p> <p>Alternatively please document the process of adding a feature type if you have already contributed a feature.</p>"},{"location":"contribute/feature_contrib/featureguides/#feature-contribution-guides","title":"Feature Contribution Guides","text":"<ul> <li>Import / Export Integrations Guide</li> </ul>"},{"location":"features/ai/","title":"Ai","text":"<p>Tandoor has several AI based features. To allow maximum flexibility, you can configure different AI providers and select them based on the task you want to perform. To prevent accidental cost escalation Tandoor has a robust system of tracking and limiting AI costs.</p>"},{"location":"features/ai/#where-ai-is-used","title":"Where AI is used","text":"<p>AI is currently used for a few focused tasks:</p> <ul> <li>Importing recipes from images, PDFs, or raw text.</li> <li>Sorting recipe steps and assigning ingredients to steps.</li> <li>Extracting food and recipe properties (nutrition and other metadata).</li> </ul> <p>All AI calls are routed through LiteLLM, so any provider supported by LiteLLM (or an OpenAI compatible endpoint) can be used when configured correctly.</p>"},{"location":"features/ai/#default-configuration","title":"Default Configuration","text":"<p>By default the AI features are enabled for every space. Each space has a spending limit of roughly 1 USD per month. This can be changed using the configuration variables</p> <p>You can change these settings any time using the django admin. If you do not care about AI cost you can enter a very high limit or disable cost tracking for your providers. The limit resets on the first of every month. </p>"},{"location":"features/ai/#configure-ai-providers","title":"Configure AI Providers","text":"<p>When AI support is enabled for a space every user in a space can configure AI providers.  The models shown in the editor have been tested and work with Tandoor. Most other models that can parse images/files and return text should also work. </p> <p>Superusers also have the ability to configure global AI providers that every space can use.</p>"},{"location":"features/ai/#self-hosting-setup","title":"Self-hosting setup","text":"<p>To use AI on a self-hosted instance, you need to:</p> <ol> <li>Enable AI in your space (or set defaults via environment variables)</li> <li>Create at least one AI Provider</li> <li>Pick that provider when using an AI feature </li> </ol> <p>If you want a provider to be available in every space, create a global AI Provider as a superuser. Otherwise create a space-specific provider.</p>"},{"location":"features/ai/#provider-fields","title":"Provider fields","text":"<p>When creating an AI Provider, the following fields matter:</p> <ul> <li>Name: Friendly label shown in the UI.</li> <li>Model name: Provider model identifier (example: <code>gpt-4o-mini</code>).</li> <li>API key: Required by the model. For local providers that do not need a key, set any non-empty value.</li> <li>URL: Optional base URL for OpenAI compatible endpoints (e.g. a self-hosted gateway).</li> <li>Log credit cost: Enables cost tracking. If disabled, the monthly credit limit will not be enforced for that provider.</li> </ul>"},{"location":"features/ai/#provider-examples","title":"Provider examples","text":"<p>Examples for commonly used providers. For model naming, auth, and base URL details, see the LiteLLM provider docs: <code>https://docs.litellm.ai/docs/providers</code></p>"},{"location":"features/ai/#openai-gpt52-mini","title":"OpenAI (gpt5.2-mini)","text":"<pre><code>Name: OpenAI gpt5.2-mini\nModel name: gpt5.2-mini\nAPI key: &lt;your OpenAI API key&gt;\nURL: \nLog credit cost: enabled\n</code></pre>"},{"location":"features/ai/#openrouter-gemini","title":"OpenRouter (Gemini)","text":"<p>OpenRouter provides OpenAI compatible endpoints for many models. Model names must be prefixed with <code>openrouter/</code>. Pick a Gemini model that supports JSON mode and (if needed) vision inputs. LiteLLM can route OpenRouter without a base URL, but setting it explicitly also works.</p> <pre><code>Name: OpenRouter Gemini\nModel name: openrouter/google/gemini-2.5-flash-lite\nAPI key: &lt;your OpenRouter API key&gt;\nURL: https://openrouter.ai/api/v1\nLog credit cost: enabled\n</code></pre>"},{"location":"features/ai/#google-ai-studio-gemini","title":"Google AI Studio (Gemini)","text":"<pre><code>Name: Gemini 2.5 Flash\nModel name: gemini/gemini-2.5-flash\nAPI key: &lt;your Google AI Studio API key&gt;\nURL: (leave empty)\nLog credit cost: enabled\n</code></pre>"},{"location":"features/ai/#requirements-for-models","title":"Requirements for models","text":"<p>Tandoor expects structured JSON responses from every AI call, so your model must support JSON mode or reliably return JSON. For image/PDF import the provider must support vision inputs.</p> <p>Warning</p> <p>AI import sends the entire file as base64 inside the request. Large files can exceed provider limits or reverse proxy limits.  Consider reducing image size or using the text import path for large documents.</p>"},{"location":"features/ai/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>JSON mode is required: if the model ignores <code>response_format</code>, Tandoor will fail to parse the response and the request will error.</li> <li>Vision support matters: image/PDF import uses <code>image_url</code>. Models without vision support will fail. PDF handling depends on the provider; some only accept images.</li> <li>Timeouts: AI calls are synchronous. Slow models can hit reverse proxy or application server timeouts. Increase timeouts if your provider is slow.</li> <li>Rate limits: <code>AI_RATELIMIT</code> throttles AI endpoints (<code>60/hour</code> by default). For batch usage, raise this limit.</li> <li>Cost tracking relies on LiteLLM: if the provider does not return usage or cost data, logs and credit limits may not reflect real usage.</li> <li>OpenRouter model names: use the <code>openrouter/</code> prefix and select a model that supports structured outputs (OpenRouter model list: <code>https://openrouter.ai/api/v1/models?supported_parameters=structured_outputs</code>).</li> </ul>"},{"location":"features/ai/#ai-log","title":"AI Log","text":"<p>The AI Log allows you to track the usage of AI calls. Here you can also see the usage.</p>"},{"location":"features/authentication/","title":"Authentication","text":"<p>Besides the normal django username and password authentication this application supports multiple methods of central account management and authentication.</p>"},{"location":"features/authentication/#allauth","title":"Allauth","text":"<p>Django Allauth is an awesome project that allows you to use a huge number of different authentication providers.</p> <p>They basically explain everything in their documentation, but the following is a short overview on how to get started.</p> <p>Public Providers</p> <p>If you choose Google, Github or any other publicly available service as your authentication provider anyone with an account on that site can create an account on your installation. A new account does not have any permission but it is still not recommended to give public access to your installation.</p> <p>Choose a provider from the list and install it using the environment variable <code>SOCIAL_PROVIDERS</code> as shown in the example below.</p> <p>When at least one social provider is set up, the social login sign in buttons should appear on the login page. The example below enables Nextcloud and the generic OpenID Connect providers.</p> <pre><code>SOCIAL_PROVIDERS=allauth.socialaccount.providers.openid_connect,allauth.socialaccount.providers.nextcloud\n</code></pre> <p>Formatting</p> <p>The exact formatting is important so make sure to follow the steps explained here!</p>"},{"location":"features/authentication/#configuration-via-environment","title":"Configuration, via environment","text":"<p>Depending on your authentication provider you might need to configure it. This needs to be done through the settings system. To make the system flexible (allow multiple providers) and to not require another file to be mounted into the container the configuration ins done through a single environment variable. The downside of this approach is that the configuration needs to be put into a single line as environment files loaded by docker compose don't support multiple lines for a single variable.</p> <p>The line data needs to either be in json or as Python dictionary syntax.</p> <p>Take the example configuration from the allauth docs, fill in your settings and then inline the whole object (you can use a service like www.freeformatter.com for formatting). Assign it to the additional <code>SOCIALACCOUNT_PROVIDERS</code> variable.</p> <p>The example below is for a generic OIDC provider with PKCE enabled. Most values need to be customized for your specifics!</p> <pre><code>SOCIALACCOUNT_PROVIDERS = \"{ 'openid_connect': { 'OAUTH_PKCE_ENABLED': True, 'APPS': [ { 'provider_id': 'oidc', 'name': 'My-IDM', 'client_id': 'my_client_id', 'secret': 'my_client_secret', 'settings': { 'server_url': 'https://idm.example.com/oidc/recipes' } } ] } }\"\n</code></pre> <p>Because this JSON contains sensitive data (client id and secret), you may instead choose to save the JSON in a file and set the environment variable <code>SOCIALACCOUNT_PROVIDERS_FILE</code> to the path of the file containing the JSON.</p> <pre><code>SOCIALACCOUNT_PROVIDERS_FILE=/run/secrets/socialaccount_providers.txt\n</code></pre> <p>Improvements ?</p> <p>There are most likely ways to achieve the same goal but with a cleaner or simpler system. If you know such a way feel free to let me know.</p>"},{"location":"features/authentication/#configuration-via-django-admin","title":"Configuration, via Django Admin","text":"<p>Instead of defining <code>SOCIALACCOUNT_PROVIDERS</code> in your environment, most configuration options can be done via the Admin interface. PKCE for <code>openid_connect</code> cannot currently be enabled this way. Use your superuser account to configure your authentication backend by opening the admin page and do the following</p> <ol> <li>Select <code>Sites</code> and edit the default site with the URL of your installation (or create a new).</li> <li>Create a new <code>Social Application</code> with the required information as stated in the provider documentation of allauth.</li> <li>Make sure to add your site to the list of available sites</li> </ol> <p>Now the provider is configured and you should be able to sign up and sign in using the provider. Use the superuser account to grant permissions to the newly created users, or enable default access via <code>SOCIAL_DEFAULT_ACCESS</code> &amp; <code>SOCIAL_DEFAULT_GROUP</code>.</p> <p>WIP</p> <p>I do not have a ton of experience with using various single signon providers and also cannot test all of them. If you have any Feedback or issues let me know.</p>"},{"location":"features/authentication/#third-party-authentication-example","title":"Third-party authentication example","text":"<p>Keycloak is a popular IAM solution and integration is straight forward thanks to Django Allauth. This example can also be used as reference for other third-party authentication solutions, as documented by Allauth.</p> <p>At Keycloak, create a new client and assign a <code>Client-ID</code>, this client comes with a <code>Secret-Key</code>. Both values are required later on. Make sure to define the correct Redirection-URL for the service, for example <code>https://tandoor.example.com/*</code>. Depending on your Keycloak setup, you need to assign roles and groups to grant access to the service.</p> <p>To enable Keycloak as a sign in option, set those variables to define the social provider and specify its configuration:</p> <pre><code>SOCIAL_PROVIDERS=allauth.socialaccount.providers.openid_connect\nSOCIALACCOUNT_PROVIDERS='{\"openid_connect\":{\"APPS\":[{\"provider_id\":\"keycloak\",\"name\":\"Keycloak\",\"client_id\":\"KEYCLOAK_CLIENT_ID\",\"secret\":\"KEYCLOAK_CLIENT_SECRET\",\"settings\":{\"server_url\":\"https://auth.example.org/realms/KEYCLOAK_REALM/.well-known/openid-configuration\"}}]}}\n'\n</code></pre> <p>You are now able to sign in using Keycloak after a restart of the service.</p>"},{"location":"features/authentication/#linking-accounts","title":"Linking accounts","text":"<p>To link an account to an already existing normal user go to the settings page of the user and link it. Here you can also unlink your account if you no longer want to use a social login method.</p>"},{"location":"features/authentication/#ldap","title":"LDAP","text":"<p>LDAP authentication can be enabled in the <code>.env</code> file by setting <code>LDAP_AUTH=1</code>. If set, users listed in the LDAP instance will be able to sign in without signing up. These variables must be set to configure the connection to the LDAP instance:</p> <pre><code>AUTH_LDAP_SERVER_URI=ldap://ldap.example.org:389\nAUTH_LDAP_BIND_DN=uid=admin,ou=users,dc=example,dc=org\nAUTH_LDAP_BIND_PASSWORD=adminpassword\nAUTH_LDAP_USER_SEARCH_BASE_DN=ou=users,dc=example,dc=org\n</code></pre> <p>Additional optional variables:</p> <pre><code>AUTH_LDAP_USER_SEARCH_FILTER_STR=(uid=%(user)s)\nAUTH_LDAP_USER_ATTR_MAP={'first_name': 'givenName', 'last_name': 'sn', 'email': 'mail'}\nAUTH_LDAP_ALWAYS_UPDATE_USER=1\nAUTH_LDAP_CACHE_TIMEOUT=3600\nAUTH_LDAP_START_TLS=1\nAUTH_LDAP_TLS_CACERTFILE=/etc/ssl/certs/own-ca.pem\n</code></pre>"},{"location":"features/authentication/#external-authentication","title":"External Authentication","text":"<p>Security Impact</p> <p>If you just set <code>REMOTE_USER_AUTH=1</code> without any additional configuration, anybody can authenticate with any username!</p> <p>Community Contributed Tutorial</p> <p>This tutorial was provided by a community member. We are not able to provide any support! Please only use, if you know what you are doing!</p> <p>In order use external authentication (i.e. using a proxy auth like Authelia, Authentik, etc.) you will need to:</p> <ol> <li>Set <code>REMOTE_USER_AUTH=1</code> in the <code>.env</code> file</li> <li>Update your nginx configuration file</li> </ol> <p>Using any of the examples above will automatically generate a configuration file inside a docker volume. Use <code>docker volume inspect recipes_nginx</code> to find out where your volume is stored.</p> <p>Configuration File Volume</p> <p>The nginx config volume is generated when the container is first run. You can change the volume to a bind mount in the <code>docker-compose.yml</code>, but then you will need to manually create it. See section <code>Volumes vs Bind Mounts</code> below for more information.</p>"},{"location":"features/authentication/#configuration-example-for-authelia","title":"Configuration Example for Authelia","text":"<pre><code>server {\n  listen 80;\n  server_name localhost;\n\n  client_max_body_size 16M;\n\n  # serve static files\n  location /static/ {\n    alias /static/;\n  }\n  # serve media files\n  location /media/ {\n    alias /media/;\n  }\n\n  # Authelia endpoint for authentication requests\n  include /config/nginx/auth.conf;\n\n  # pass requests for dynamic content to gunicorn\n  location / {\n    proxy_set_header Host $host;\n    proxy_pass http://web_recipes:8080;\n\n    # Ensure Authelia is specifically required for this endpoint\n    # This line is important as it will return a 401 error if the user doesn't have access\n    include /config/nginx/authelia.conf;\n\n    auth_request_set $user $upstream_http_remote_user;\n    proxy_set_header REMOTE-USER $user;\n  }\n\n  # Required to allow user to logout of authentication from within Recipes\n  # Ensure the &lt;auth_endpoint&gt; below is changed to actual the authentication url\n  location /accounts/logout/ {\n    return 301 http://&lt;auth_endpoint&gt;/logout;\n  }\n}\n</code></pre> <p>Please refer to the appropriate documentation on how to set up the reverse proxy, authentication, and networks.</p> <p>Ensure users have been configured for Authelia, and that the endpoint recipes is pointed to is protected but available.</p> <p>There is a good guide to the other additional files that need to be added to your nginx set up at the Authelia Docs.</p> <p>Remember to add the appropriate environment variables to <code>.env</code> file (example for nginx proxy):</p> <pre><code>VIRTUAL_HOST=\nLETSENCRYPT_HOST=\nLETSENCRYPT_EMAIL=\nPROXY_HEADER=\n</code></pre>"},{"location":"features/automation/","title":"Automation","text":"<p>Warning</p> <p>Automations are currently in a beta stage. They work pretty stable but if I encounter any  issues while working on them, I might change how they work breaking existing automations.  I will try to avoid this and am pretty confident it won't happen.</p> <p>Automations allow Tandoor to automatically perform certain tasks, especially when importing recipes, that would otherwise have to be done manually. Currently, the following automations are supported.</p>"},{"location":"features/automation/#unit-food-keyword-alias","title":"Unit, Food, Keyword Alias","text":"<p>Foods, Units and Keywords can have automations that automatically replace them with another object to allow aliasing them.</p> <p>This helps to add consistency to the naming of objects, for example to always use the singular form for the main name if a plural form is configured.</p> <p>These automations are best created by dragging and dropping Foods, Units or Keywords in their respective views and creating the automation there.</p> <p>You can also create them manually by setting the following</p> <ul> <li>Parameter 1: name of food/unit/keyword to match</li> <li>Parameter 2: name of food/unit/keyword to replace matched food with</li> </ul> <p>These rules are processed whenever you are importing recipes from websites or other apps and when using the simple ingredient input (shopping, recipe editor, ...).</p>"},{"location":"features/automation/#description-replace","title":"Description Replace","text":"<p>This automation is a bit more complicated than the alias rules. It is run when importing a recipe from a website.</p> <p>It uses Regular Expressions (RegEx) to determine if a description should be altered, what exactly to remove and what to replace it with.  The search string ignores case, the replacement string respects case.</p> <ul> <li>Parameter 1: pattern of which sites to match (e.g. <code>.*.chefkoch.de.*</code>, <code>.*</code>)</li> <li>Parameter 2: pattern of what to replace (e.g. <code>.*</code>)</li> <li>Parameter 3: value to replace matched occurrence of parameter 2 with. Only the first occurrence of the pattern is replaced.</li> </ul> <p>To replace the description the python re.sub function is used like this <code>re.sub(&lt;parameter 2&gt;, &lt;parameter 3&gt;, &lt;description&gt;, count=1)</code></p> <p>To test out your patterns and learn about RegEx you can use regexr.com ChatGPT and similiar LLMs are also useful for creating RegEx patterns: <code>ChatGPT please create a Regex expression in the format of re.sub(&lt;parameter 2&gt;, &lt;parameter 3&gt;, &lt;description&gt;, count=1) that will change the string &lt;example string here&gt; into the string &lt;desired result here&gt;</code></p> <p>Info</p> <p>In order to prevent denial of service attacks on the RegEx engine the number of replace automations and the length of the inputs that are processed are limited. Those limits should never be reached during normal usage.</p>"},{"location":"features/automation/#instruction-replace-title-replace-food-replace-unit-replace","title":"Instruction Replace, Title Replace, Food Replace &amp; Unit Replace","text":"<p>These work just like the Description Replace automation. Instruction, Food and Unit Replace will run against every iteration of the object in a recipe during import. - Instruction Replace will run for the instructions in every step.  It will also replace every occurrence, not just the first. - Food &amp; Unit Replace will run for every food and unit in every ingredient in every step.</p> <p>Also instead of just replacing a single occurrence of the matched pattern it will replace all.</p>"},{"location":"features/automation/#never-unit","title":"Never Unit","text":"<p>Some ingredients have a pattern of AMOUNT and FOOD, if the food has multiple words (e.g. egg yolk) this can cause Tandoor to detect the word \"egg\" as a unit. This automation will detect the word 'egg' as something that should never be considered a unit.</p> <p>You can also create them manually by setting the following</p> <ul> <li>Parameter 1: string to detect</li> <li>Parameter 2: Optional: unit to insert into ingredient (e.g. 1 whole 'egg yolk' instead of 1  'egg yolk') <p>These rules are processed whenever you are importing recipes from websites or other apps and when using the simple ingredient input (shopping, recipe editor, ...).</p>"},{"location":"features/automation/#transpose-words","title":"Transpose Words","text":"<p>Some recipes list the food before the units for some foods (garlic cloves). This automation will transpose 2 words in an ingredient so \"garlic cloves\" will automatically become \"cloves garlic\"</p> <ul> <li>Parameter 1: first word to detect</li> <li>Parameter 2: second word to detect</li> </ul> <p>These rules are processed whenever you are importing recipes from websites or other apps and when using the simple ingredient input (shopping, recipe editor, ...).</p>"},{"location":"features/automation/#order","title":"Order","text":"<p>If the Automation type allows for more than one rule to be executed (for example description replace) the rules are processed in ascending order (ordered by the order property of the automation). The default order is always 1000 to make it easier to add automations before and after other automations.</p> <p>Example:</p> <ol> <li>Rule ABC (order 1000) replaces <code>everything</code> with <code>abc</code></li> <li>Rule DEF (order 2000) replaces <code>everything</code> with <code>def</code></li> <li>Rule XYZ (order 500) replaces <code>everything</code> with <code>xyz</code></li> </ol> <p>After processing rules XYZ, then ABC and then DEF the description will have the value <code>def</code></p>"},{"location":"features/connectors/","title":"Connectors","text":"<p>Warning</p> <p>Connectors are currently in a beta stage.</p>"},{"location":"features/connectors/#connectors","title":"Connectors","text":"<p>Connectors are a powerful add-on component to TandoorRecipes. They allow for certain actions to be translated to api calls to external services.</p> <p>Danger</p> <p>In order for this application to push data to external providers it needs to store authentication information. Please use read only/separate accounts or app passwords wherever possible.</p> <p>for the configuration please see Configuration</p>"},{"location":"features/connectors/#current-connectors","title":"Current Connectors","text":""},{"location":"features/connectors/#homeassistant","title":"HomeAssistant","text":"<p>The current HomeAssistant connector supports the following features: 1. Push newly created shopping list items. 2. Pushes all shopping list items if a recipe is added to the shopping list. 3. Removed todo's from HomeAssistant IF they are unchanged and are removed through TandoorRecipes.</p>"},{"location":"features/connectors/#how-to-configure","title":"How to configure:","text":"<p>Step 1: 1. Generate a HomeAssistant Long-Lived Access Tokens  2. Get/create a todo list entry you want to sync too.  3. Create a connector   4. ??? 5. Profit</p>"},{"location":"features/external_recipes/","title":"Storages and Sync","text":"<p>The original intend of this application was to provide a search interface to my large collection of PDF scans of recipes. This feature is now called External recipes.</p> <p>Info</p> <p>Internal recipes are stored in a structured manner inside the database. They can be displayed using the standardized interface and support features like shopping lists, scaling and steps. External recipes are basically files that are displayed within the interface. The benefit is that you can quickly import all your old recipes and convert them one by one.</p> <p>To use external recipes you will first need to configure a storage source. After that a synced path can be created. Lastly you will need to sync with the external path and import recipes you desire.</p>"},{"location":"features/external_recipes/#storage","title":"Storage","text":"<p>Danger</p> <p>In order for this application to retrieve data from external providers it needs to store authentication information. Please use read only/separate accounts or app passwords wherever possible. There are better ways to do this but they are currently not implemented</p> <p>A <code>Storage Backend</code> is a remote storage location where files are read from. To add a new backend click on <code>username &gt;&gt; External Recipes &gt;&gt; Manage External Storage &gt;&gt; the + next to Storage Backend List</code>. There click the plus button.</p> <p>The basic configuration is the same for all providers.</p> Field Value Name Your identifier for this storage source, can be everything you want. Method The desired method. <p>Success</p> <p>Only the providers listed below are currently implemented. If you need anything else feel free to open an issue or pull request.</p>"},{"location":"features/external_recipes/#local","title":"Local","text":"<p>Info</p> <p>There is currently no way to upload files through the webinterface. This is a feature that might be added later.</p> <p>The local provider does not need any configuration (username, password, token or URL). For the monitor you will need to define a valid path on your host system. (Path) The Path depends on your setup and can be both relative and absolute.</p> <p>Volume</p> <p>By default no data other than the mediafiles and the database is persisted. If you use the local provider make sure to mount the path you choose to monitor to your host system in order to keep it persistent.</p>"},{"location":"features/external_recipes/#docker","title":"Docker","text":"<p>If you use docker the default directory is <code>/opt/recipes/</code>. add</p> <pre><code>      - ./externalfiles:/opt/recipes/externalfiles\n</code></pre> <p>to your docker-compose.yml file under the <code>web_recipes &gt;&gt; volumes</code> section. This will create a folder in your docker directory named <code>externalfiles</code> under which you could choose to store external pdfs (you could of course store them anywhere, just change <code>./externalfiles</code> to your preferred location). save the docker-compose.yml and restart your docker container.</p>"},{"location":"features/external_recipes/#dropbox","title":"Dropbox","text":"Field Value Username Dropbox username Token Dropbox API Token. Can be found here"},{"location":"features/external_recipes/#nextcloud","title":"Nextcloud","text":"<p>Path</p> <p>It appears that the correct webdav path varies from installation to installation (for whatever reason). In the Nextcloud webinterface click the <code>Settings</code> button in the bottom left corner, there your WebDav Url will be displayed.</p> Field Value Username Nextcloud username Password Nextcloud app password Url Nextcloud Server URL (e.g. <code>https://cloud.mydomain.com</code>) Path (optional) webdav path (e.g. <code>/remote.php/dav/files/vabene1111</code>). If no path is supplied <code>/remote.php/dav/files/</code> plus your username will be used."},{"location":"features/external_recipes/#adding-external-recipes","title":"Adding External Recipes","text":"<p>To add a new path from your Storage backend to the sync list, go to <code>username &gt;&gt; External Recipes</code> and select the storage backend you want to use. Then enter the path you want to monitor starting at the storage root (e.g. <code>/Folder/RecipesFolder</code>, or `/opt/recipes/externalfiles' in the docker example above) and save it.</p>"},{"location":"features/external_recipes/#syncing-data","title":"Syncing Data","text":"<p>To sync the recipes app with the storage backends press <code>Sync now</code> under <code>username &gt;&gt; External Recipes</code></p>"},{"location":"features/external_recipes/#discovered-recipes","title":"Discovered Recipes","text":"<p>All files found by the sync can be found under <code>Manage Data &gt;&gt; Discovered recipes</code>. There you can either import all at once without modifying them or import one by one, adding tags while importing.</p>"},{"location":"features/import_export/","title":"Import/Export","text":"<p>This application features a very versatile import and export feature in order to offer the best experience possible and allow you to freely choose where your data goes.</p> <p>WIP</p> <p>The module is relatively new. There is a known issue with timeouts on large exports. A fix is being developed and will likely be released with the next version.</p> <p>The module is built with maximum flexibility and expandability in mind and allows to easily add new integrations to allow you to both import and export your recipes into whatever format you desire.</p> <p>Feel like there is an important integration missing? Just take a look at the integration issues or open a new one if your favorite one is missing.</p> <p>Export</p> <p>I strongly believe in everyone's right to use their data as they please and therefore want to give you the best possible flexibility with your recipes. That said, for most of the people getting this application running with their recipes is the biggest priority. Because of this, importing as many formats as possible is prioritized over exporting. An exporter for the different formats will follow over time.</p> <p>Overview of the capabilities of the different integrations.</p> Integration Import Export Images Default \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Nextcloud \u2714\ufe0f \u231a \u2714\ufe0f Mealie \u2714\ufe0f \u231a \u2714\ufe0f Chowdown \u2714\ufe0f \u231a \u2714\ufe0f Safron \u2714\ufe0f \u2714\ufe0f \u274c Paprika \u2714\ufe0f \u231a \u2714\ufe0f ChefTap \u2714\ufe0f \u274c \u274c Pepperplate \u2714\ufe0f \u231a \u274c RecipeSage \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Rezeptsuite.de \u2714\ufe0f \u274c \u2714\ufe0f Domestica \u2714\ufe0f \u231a \u2714\ufe0f MealMaster \u2714\ufe0f \u274c \u274c RezKonv \u2714\ufe0f \u274c \u274c OpenEats \u2714\ufe0f \u274c \u231a Plantoeat \u2714\ufe0f \u274c \u2714 CookBook Manager \u2714\ufe0f \u231a \u2714\ufe0f Cooklang \u2714\ufe0f \u231a \u231a CopyMeThat \u2714\ufe0f \u274c \u2714\ufe0f Mela \u2714\ufe0f \u231a \u2714\ufe0f Cookmate \u2714\ufe0f \u231a \u2714\ufe0f PDF (experimental) \u231a\ufe0f \u2714\ufe0f \u2714\ufe0f Gourmet \u2714\ufe0f \u274c \u2714\ufe0f <p>\u2714\ufe0f = implemented, \u274c = not implemented and not possible/planned, \u231a = not yet implemented</p>"},{"location":"features/import_export/#default","title":"Default","text":"<p>The default integration is the built-in (and preferred) way to import and export recipes. It is maintained with new fields added and contains all data to transfer your recipes from one installation to another.</p> <p>It is also one of the few recipe formats that is actually structured in a way that allows for easy machine readability if you want to use the data for any other purpose.</p>"},{"location":"features/import_export/#recipesage","title":"RecipeSage","text":"<p>Go to Settings &gt; Export Recipe Data and select <code>EXPORT AS JSON-LD (BEST)</code>. Then simply upload the exported file to Tandoor.</p> <p>The RecipeSage integration also allows exporting. To migrate from Tandoor to RecipeSage simply export with RecipeSage selected and import the json file in RecipeSage. Images are currently not supported for exporting.</p>"},{"location":"features/import_export/#domestica","title":"Domestica","text":"<p>Go to Import/Export and select <code>Export Recipes</code>. Then simply upload the exported file to Tandoor.</p>"},{"location":"features/import_export/#nextcloud","title":"Nextcloud","text":"<p>Importing recipes from Nextcloud Cookbook is very easy and since Nextcloud Cookbook provides nice, standardized and structured information most of your recipe is going to be intact.</p> <p>Follow these steps to import your recipes</p> <ol> <li>Go to your Nextcloud web interface</li> <li>Find the <code>Recipes</code> folder (usually located in the root directory of your account)</li> <li>Download that folder to get your <code>Recipes.zip</code> which includes the folder <code>Recipes</code> and in that a folder for each recipe</li> <li>Upload the <code>Recipes.zip</code> to Tandoor and import it</li> </ol> <p>Folder structure</p> <p>Importing only works if the folder structure is correct. If you do not use the standard path or create the zip file in any other way, make sure the structure is as follows <code>Recipes.zip/     \u2514\u2500\u2500 Recipes/         \u251c\u2500\u2500 Recipe1/         \u2502   \u251c\u2500\u2500 recipe.json         \u2502   \u2514\u2500\u2500 full.jpg         \u2514\u2500\u2500 Recipe2/             \u251c\u2500\u2500 recipe.json             \u2514\u2500\u2500 full.jpg</code></p>"},{"location":"features/import_export/#mealie","title":"Mealie","text":"<p>Mealie provides structured data similar to Nextcloud.</p> <p>Versions</p> <p>There are two different versions of the Mealie importer: one for all backups created prior to Version 1.0 and another one for all backups created from Version 1.0 onwards. </p> <p>Versions</p> <p>The Mealie UI does not indicate whether or not nutrition information is stored per serving or per recipe. This choice is left to the user. During the import you will have to choose  how Tandoor should treat your nutrition data.</p> <p>To migrate your recipes</p> <ol> <li>Go to your Mealie admin settings and create a new backup (note that exporting only recipe data from Mealie's data management section will result in an incomplete import).</li> <li>Download the backup.</li> <li>Upload the entire <code>.zip</code> file to the importer page and import everything.</li> </ol>"},{"location":"features/import_export/#chowdown","title":"Chowdown","text":"<p>Chowdown stores all your recipes in plain text markdown files in a directory called <code>_recipes</code>. Images are saved in a directory called <code>images</code>.</p> <p>In order to import your Chowdown recipes simply create a <code>.zip</code> file from those two folders and import them. The folder structure should look as follows:</p> <p>_recipes</p> <p>For some reason chowdown uses <code>_</code> before the <code>recipes</code> folder. To avoid confusion, the import supports both <code>\\_recipes</code> and <code>recipes</code>.</p> <pre><code>Recipes.zip/\n    \u251c\u2500\u2500 _recipes/\n    \u2502   \u251c\u2500\u2500 recipe one.md\n    \u2502   \u251c\u2500\u2500 recipe two.md\n    \u2502   \u2514\u2500\u2500 ...\n    \u2514\u2500\u2500 images/\n        \u251c\u2500\u2500 image-name.jpg\n        \u251c\u2500\u2500 second-image-name.jpg\n        \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"features/import_export/#safron","title":"Safron","text":"<p>Go to your Safron settings page and export your recipes. Then simply upload the entire <code>.zip</code> file to the importer.</p> <p>Images</p> <p>Safron exports do not contain any images. They will be lost during the import.</p>"},{"location":"features/import_export/#paprika","title":"Paprika","text":"<p>A Paprika export contains a folder with an html representation of your recipes and a <code>.paprikarecipes</code> file.</p> <p>The <code>.paprikarecipes</code> file is basically just a zip with gzipped contents. Simply upload the whole file and import all your recipes.</p>"},{"location":"features/import_export/#pepperplate","title":"Pepperplate","text":"<p>Pepperplate provides a <code>.zip</code> file containing all of your recipes as <code>.txt</code> files. These files are well-structured and allow the import of all data without losing anything.</p> <p>Simply export the recipes from Pepperplate and upload the zip to Tandoor. Images are not included in the export and thus cannot be imported.</p>"},{"location":"features/import_export/#cheftap","title":"ChefTap","text":"<p>ChefTaps allows you to export your recipes from the app (I think). The export is a zip file containing a folder called <code>cheftap_export</code> which in turn contains <code>.txt</code> files with your recipes.</p> <p>This format is basically completely unstructured and every export looks different. This makes importing it very hard and leads to suboptimal results. Images are also not supported as they are not included in the export (at least the tests I had).</p> <p>Usually the import should recognize all ingredients and put everything else into the instructions. If your import fails or is worse than this feel free to provide me with more example data and I can try to improve the importer.</p> <p>As ChefTap cannot import these files anyway there won't be an exporter implemented in Tandoor.</p>"},{"location":"features/import_export/#mealmaster","title":"MealMaster","text":"<p>MealMaster can be imported by uploading one or more MealMaster files. Files should be in <code>.txt</code>, <code>.MMF</code> or <code>.MM</code> format.</p> <p>The MealMaster spec allows for many variations. Currently, only the one-column format for ingredients is supported. Second-line notes to ingredients are currently also not imported as a note but simply put into the instructions. If you have MealMaster recipes that cannot be imported, feel free to raise an issue.</p>"},{"location":"features/import_export/#rezkonv","title":"RezKonv","text":"<p>The RezKonv format is primarily used in the German recipe manager RezKonv Suite. To migrate from RezKonv Suite to Tandoor, select <code>Export &gt; Gesamtes Kochbuch exportieren</code> (the last option in the export menu). The generated file can simply be imported into Tandoor.</p> <p>As I only had limited sample data, feel free to open an issue if your RezKonv export cannot be imported.</p>"},{"location":"features/import_export/#recipe-keeper","title":"Recipe Keeper","text":"<p>Recipe Keeper allows you to export a zip file containing recipes and images using its apps. This zip file can simply be imported into Tandoor.</p>"},{"location":"features/import_export/#openeats","title":"OpenEats","text":"<p>OpenEats does not provide any way to export the data using the interface. Luckily it is relatively easy to export it from the command line. You need to run the command <code>python manage.py dumpdata recipe ingredient</code> inside the application API container. If you followed the default installation method, you can use the following command <code>docker-compose -f docker-prod.yml run --rm --entrypoint 'sh' api ./manage.py dumpdata recipe ingredient</code>. This command might also work <code>docker exec -it openeats_api_1 ./manage.py dumpdata recipe ingredient rating recipe_groups &gt; recipe_ingredients.json</code></p> <p>Store the outputted json string in a <code>.json</code> file and simply import it using the importer. The file should look something like this:</p> <pre><code>[\n   {\n      \"model\":\"recipe.recipe\",\n      \"pk\":1,\n      \"fields\":{\n         \"title\":\"Tasty Chili\",\n         ...\n      }\n   },\n  ...\n    {\n      \"model\":\"ingredient.ingredientgroup\",\n      \"pk\":1,\n      \"fields\":{\n         \"title\":\"Veges\",\n         \"recipe\":1\n      }\n   },\n  ...\n  {\n      \"model\":\"ingredient.ingredient\",\n      \"pk\":1,\n      \"fields\":{\n         \"title\":\"black pepper\",\n         \"numerator\":1.0,\n         \"denominator\":1.0,\n         \"measurement\":\"dash\",\n         \"ingredient_group\":1\n      }\n   }\n]\n</code></pre> <p>To import your images, you will need to create the folder <code>openeats-import</code> in your Tandoor <code>recipes</code> media folder (which is usually found inside <code>/opt/recipes/mediafiles</code>). After that you will need to copy the <code>/code/site-media/upload</code> folder from the OpenEats API Docker container to the <code>openeats</code> folder you created. You should now have the file path <code>/opt/recipes/mediafiles/recipes/openeats-import/upload/...</code> in Tandoor.</p>"},{"location":"features/import_export/#plan-to-eat","title":"Plan to Eat","text":"<p>Plan to Eat allows you to export a text file containing all your recipes. Simply upload that text file to Tandoor to import all recipes</p>"},{"location":"features/import_export/#cookbook-manager","title":"CookBook Manager","text":"<p>CookBook Manager (previously named CookBookApp) can export .zip files containing YAML files.  In Settings -&gt; Backup, select the YAML option when exporting. Upload the entire ZIP to Tandoor to import all included recipes.</p>"},{"location":"features/import_export/#copymethat","title":"CopyMeThat","text":"<p>CopyMeThat can export <code>.zip</code> files containing an <code>.html</code> file as well as a folder containing all the images. Upload the entire <code>.zip</code> file to Tandoor to import all included recipes.</p>"},{"location":"features/import_export/#cookmate","title":"Cookmate","text":"<p>Cookmate allows you to export a <code>.mcb</code> file which you can simply upload to Tandoor and import all your recipes.</p>"},{"location":"features/import_export/#cooklang","title":"Cooklang","text":"<p>Cooklang allows you to import a <code>.cook</code> file into tandoor. Does not yet support attaching images or importing a zip file.</p>"},{"location":"features/import_export/#recettetek","title":"RecetteTek","text":"<p>RecetteTek exports are <code>.rtk</code> files which can simply be uploaded to Tandoor to import all your recipes.</p>"},{"location":"features/import_export/#rezeptsuitede","title":"Rezeptsuite.de","text":"<p>Rezeptsuite.de exports are <code>.xml</code> files which can simply be uploaded to Tandoor to import all your recipes.</p> <p>It appears that Rezeptsuite.de, depending on the client, might export a <code>.zip</code> file containing a <code>.cml</code> file. If this happens, just unzip the <code>.zip</code> file and change <code>.cml</code> to <code>.xml</code> to import your recipes.</p>"},{"location":"features/import_export/#mela","title":"Mela","text":"<p>Mela provides multiple export formats, but only the <code>MelaRecipes</code> format can export the complete collection. Perform this export and open the <code>.melarecipes</code> file using your favorite archive opening program (e.g. 7-Zip). Repeat this if the file contains another <code>.melarecipes</code> file until you get a list of one or many <code>.melarecipe</code> files. Upload all <code>.melarecipe</code> files you want to import to Tandoor and start the import.</p>"},{"location":"features/import_export/#pdf","title":"PDF","text":"<p>The PDF exporter is an experimental feature that uses the Puppeteer browser renderer to render each recipe and export it to PDF. For that to work, it downloads a Chromium binary of about 140 MB to your server and then renders the PDF files using that.</p> <p>As that is something some server administrators might not want, the PDF exporter is disabled by default and can be enabled with <code>ENABLE_PDF_EXPORT=1</code> in <code>.env</code>.</p> <p>See this issue for more discussion on this and this issue for the future plans to support server-side rendering.</p>"},{"location":"features/import_export/#gourmet","title":"Gourmet","text":"<p>An importer for files from Gourmet. As the <code>.grmt</code> files appears to lack the unit for ingredients a file with <code>.zip</code> file with <code>.htm</code> and <code>.jpg</code> is expected.</p> <p>To generate the file, export to HTML in Gourmet and zip the generated folder.</p> <p>The import of menus is not supported.</p> <p>Export is not supported due to problems with the <code>.grmt</code> format.</p>"},{"location":"features/shopping/","title":"Shopping","text":"<p>WIP</p> <p>While being around for a while there are still a lot of features that I plan on adding to the shopping list. You can see an overview of what is still planned on this issue.</p> <p>Shopping lists allow you to easily convert a recipe or even a whole meal plan into a shopping list. From there you can either use it on the site or export it to your shopping list of choice.  It also includes automatic supermarket specific ordering.</p> <p></p>"},{"location":"features/shopping/#create-shopping-lists","title":"Create Shopping Lists","text":"<p>You have three options to create a shopping list</p> <ol> <li>Open a recipe of your choice. From the context menu choose <code>Add to Shoppinglist</code> and create a new list with the recipe already added.</li> <li>After adding recipes to the meal plan you can click the little shopping cart icon to add the recipes to the shopping list.    They will be shown below the plan, from there you can open a new shopping list with them.</li> <li>The last option is to open the shopping list page and click the little plus icon to create a new list.</li> </ol>"},{"location":"features/shopping/#supermarket-ordering","title":"Supermarket Ordering","text":"<p>WIP</p> <p>This feature is relatively new and I did not have the time to completely polished it yet, that said  it already works quite well.</p> <p>You can create Supermarket Categories and Supermarkets in the admin interface. After setting this up you can choose a supermarket for each shopping list. This will automatically show the categories configured for this supermarket in the order specified. All Foods that are not yet categorized can be dragged into their category, this will save the categories for the future.</p>"},{"location":"features/shopping/#sharing-autosync","title":"Sharing &amp; Autosync","text":"<p>If you want to collaborate on the creation and usage of the shopping list you can add a user to the list of shared users. Each user now has access to the list and can edit it. </p> <p>When checking items in viewing mode the change is synced to all other clients that currently have the same list open. You can set the syncing interval in your user settings.</p>"},{"location":"features/shopping/#other-features","title":"Other Features","text":"<p>There are a few more features worth pointing out</p> <ol> <li>You can export recipes for use in other applications (Google Keep, etc.) by using the export button</li> <li>In the export popup you can define a prefix to be put before each row in case an external app requires that</li> <li>Marking a shopping list as finished will hide it from the shopping list page</li> </ol>"},{"location":"features/telegram_bot/","title":"Telegram bot","text":"<p>The telegram bot is meant to simplify certain interactions with Tandoor. It is currently very basic but might be expanded in the future.</p> <p>Experimental</p> <p>This feature is considered experimental. You can use it and it should not break anything but you might be  required to update your configuration in the future. The setup is also definitely not user-friendly, this will likely improve if the feature is well-received/expanded.</p> <p>Public IP/Domain</p> <p>To use the Telegram Bot you will need an installation that is accessible from the outside, otherwise telegram can't send messages. This could be circumvented using the polling API but this is currently not implemented.</p>"},{"location":"features/telegram_bot/#shopping-bot","title":"Shopping Bot","text":"<p>The shopping bot will add any message you send it to your latest open shopping list.</p> <p>To get a shopping bot follow these steps</p> <ol> <li>Create a new Telegram Bot using the BotFather</li> <li>If you want to use the bot with multiple persons add the bot to a group and grant it admin privileges</li> <li>Open the Admin Page (click your username, then admin) and select <code>Telegram Bots</code></li> <li>Create a new Bot</li> <li>token: the token obtained in step one </li> <li>space: your space (usually Default)</li> <li>user: to the user the bot is meant for (determines the shopping list used)</li> <li>chat id: if you know where messages will be sent from enter the chat ID, otherwise it is set to the first chat the bot received a message from</li> <li>Visit your installation at <code>recipes.mydomin.tld/telegram/setup/&lt;botid&gt;</code> with botid being the ID of the bot you just created    You should see the following message:     <pre><code>{\n    \"hook_url\": \"https://recipes.mydomin.tld/telegram/hook/c0c08de9-5e1e-4480-8312-3e256af61340/\",\n    \"create_response\": {\n        \"ok\": true,\n        \"result\": true,\n        \"description\": \"Webhook was set\"\n    },\n    \"info_response\": {\n        \"ok\": true,\n        \"result\": {\n            \"url\": \"recipes.mydomin.tld/telegram/hook/&lt;webhook_token&gt;\",\n            \"has_custom_certificate\": false,\n            \"pending_update_count\": 0,\n            \"max_connections\": 40,\n            \"ip_address\": \"46.4.105.116\"\n        }\n    }\n}\n</code></pre></li> </ol> <p>You should now be able to send messages to the bot and have the entries appear in your latest shopping list.</p>"},{"location":"features/telegram_bot/#resetting","title":"Resetting","text":"<p>To reset a bot open <code>recipes.mydomin.tld/telegram/remove/&lt;botid&gt;</code></p>"},{"location":"features/templating/","title":"Templating","text":"<p>Danger</p> <p>The version containing Templating is not yet released! This documentation is only to illustrate the pending changes facilitate the discussion.</p> <p>With the Version <code>0.14.0</code> support for using a custom Jinja2 Template in recipe step instructions has been added.</p> <p>This allows you to write ingredients with their corresponding amount directly inside the text while still profiting from recipe scaling.</p> <p></p> <p>Info</p> <p>Templating is a very new feature and still WIP. Feel free to open an issue to provide feedback and ideas. Please also refer to Issue #218 where this feature has been discussed.</p>"},{"location":"features/templating/#using-templating","title":"Using Templating","text":"<p>Currently the only available variable in the Templating context is <code>ingredients</code>.</p> <p><code>ingredients</code> is an array that contains all ingredients of the current recipe step. You can access an ingredient by using <code>{{ ingredients[&lt;index in list&gt;] }}</code> where the index refers to the position in the list of ingredients starting with zero. You can also use the interaction menu of the ingredient to copy its reference.</p> <p>Warning</p> <p>Please note that changing the order of the ingredients will break the reference (or at least make it useless). See the technical reasoning for more information on why it is this way.</p> <p></p> <p>You can also access only the amount, unit, note or food inside your instruction text using <pre><code>{{ ingredients[0].amount }}\n{{ ingredients[0].unit }}\n{{ ingredients[0].food }}\n{{ ingredients[0].note }}\n</code></pre></p>"},{"location":"features/templating/#technical-reasoning","title":"Technical Reasoning","text":"<p>There are several options how the ingredients in the list can be related to the Template Context in the Text.</p> <p>The template could access them by ID, the food name or the position in the list. All options have their benefits and disadvantages.</p> <ol> <li>ID: ugly to write and read when not rendered and also more complex from a technical standpoint</li> <li>Name: very nice to read and easy but does not work when a food occurs twice in a step. Could have workaround but would then be inconsistent.</li> <li>Position: easy to write and understand but breaks when ordering is changed and not really nice to read when instructions are not rendered.</li> </ol> <p>I decided to go for the position based system. If you know of any better way feel free to open an issue or PR.</p>"},{"location":"install/archlinux/","title":"ArchLinux","text":"<p>Community Contributed</p> <p>This guide was contributed by the community and is neither officially supported, nor updated or tested.</p> <p>Tandoor 2 Compatibility</p> <p>This guide has not been verified/tested for Tandoor 2, which now integrates a nginx service inside the default docker container and exposes its service on port 80 instead of 8080.</p> <p>These are instructions for pacman based distributions, like ArchLinux. The package is available from the AUR or from GitHub.</p>"},{"location":"install/archlinux/#features","title":"Features","text":"<ul> <li>systemd integration.</li> <li>Provide configuration for Nginx.</li> <li>Use socket activation.</li> <li>Use a non-root user.</li> <li>Apply migrations automatically.</li> </ul>"},{"location":"install/archlinux/#installation","title":"Installation","text":"<ol> <li> <p>Clone the package, build and install with makepkg: <pre><code>git clone https://aur.archlinux.org/tandoor-recipes-git.git\ncd tandoor-recipes-git\nmakepkg -si\n</code></pre> or use your favourite AUR helper.</p> </li> <li> <p>Setup a PostgreSQL database and user, as explained here: https://docs.tandoor.dev/install/manual/#setup-postgresql</p> </li> <li> <p>Configure the service in <code>/etc/tandoor/tandoor.conf</code>.</p> </li> <li> <p>Reinstall the package, or follow the official instructions to have tandoor creates its DB tables.</p> </li> <li> <p>Optionally configure a reverse proxy. A configuration for Nginx is provided, but you can Traefik, Apache, etc.. Edit <code>/etc/nginx/sites-available/tandoor.conf</code>. You may want to use another <code>server_name</code>, or configure TLS. Then: <pre><code>cd /etc/nginx/sites-enabled\nln -s ../sites-available/tandoor.conf\nsystemctl restart nginx\n</code></pre></p> </li> <li> <p>Enable the service <pre><code>systemctl enable --now tandoor\n</code></pre></p> </li> </ol>"},{"location":"install/archlinux/#upgrade","title":"Upgrade","text":"<p><pre><code>cd tandoor-recipes-git\ngit pull\nmakepkg -sif\n</code></pre> Or use your favourite AUR helper. You shouldn't need to do anything else. This package applies migration automatically. If PostgreSQL has been updated to a new major version, you may need to run pg_upgrade.</p>"},{"location":"install/archlinux/#help","title":"Help","text":"<p>This package is non-official. Issues should be posted to https://github.com/jdecourval/tandoor-recipes-pkgbuild or https://aur.archlinux.org/packages/tandoor-recipes-git.</p>"},{"location":"install/docker/","title":"Docker","text":"<p>Recommended Installation</p> <p>Setting up this application using Docker is recommended. This does not mean that other options are bad, but its the only method  that is officially maintained and gets regularly tested. </p> <p>This guide shows you some basic setups using Docker and docker compose. For configuration options see the configuration page.</p>"},{"location":"install/docker/#versions","title":"Versions","text":"<p>There are different versions (tags) released on Docker Hub.</p> <ul> <li>latest Default image. The one you should use if you don't know that you need anything else.</li> <li>beta Partially stable version that gets updated every now and then. Expect to have some problems.</li> <li>develop If you want the most bleeding-edge version with potentially many breaking changes, feel free to use this version (not recommended!).</li> <li>X.Y.Z each released version has its own image. If you need to revert to an old version or want to make sure you stay on one specific use these tags.</li> </ul> <p>No Downgrading</p> <p>There is currently no way to migrate back to an older version as there is no mechanism to downgrade the database. You could probably do it but I cannot help you with that. Choose wisely if you want to use the unstable images. That said beta should usually be working if you like frequent updates and new stuff.</p>"},{"location":"install/docker/#docker","title":"Docker","text":"<p>The docker image (<code>vabene1111/recipes</code>) simply exposes the application on the container's port <code>80</code> through the integrated nginx webserver.</p> <pre><code>docker run -d \\\n    -v \"$(pwd)\"/staticfiles:/opt/recipes/staticfiles \\\n    -v \"$(pwd)\"/mediafiles:/opt/recipes/mediafiles \\\n    -p 80:80 \\\n    -e SECRET_KEY=YOUR_SECRET_KEY \\\n    -e DB_ENGINE=django.db.backends.postgresql \\\n    -e POSTGRES_HOST=db_recipes \\\n    -e POSTGRES_PORT=5432 \\\n    -e POSTGRES_USER=djangodb \\\n    -e POSTGRES_PASSWORD=YOUR_POSTGRES_SECRET_KEY \\\n    -e POSTGRES_DB=djangodb \\\n    --name recipes_1 \\\n    vabene1111/recipes\n</code></pre> <p>Please make sure to replace the <code>SECRET_KEY</code> and <code>POSTGRES_PASSWORD</code> placeholders!</p>"},{"location":"install/docker/#docker-compose","title":"Docker Compose","text":"<p>The main, and also recommended, installation option for this application is Docker Compose.</p> <ol> <li>Choose your <code>docker-compose.yml</code> from the examples below.</li> <li>Download the <code>.env</code> configuration file with <code>wget</code> <pre><code>wget https://raw.githubusercontent.com/vabene1111/recipes/develop/.env.template -O .env\n</code></pre></li> <li>Edit it accordingly (you NEED to set <code>SECRET_KEY</code> and <code>POSTGRES_PASSWORD</code>), see configuration page.</li> <li>Start your container using <code>docker-compose up -d</code>.</li> </ol>"},{"location":"install/docker/#plain","title":"Plain","text":"<p>This configuration exposes the application through a containerized nginx web server on port 80 of your machine. Be aware that having some other web server or container running on your host machine on port 80 will block this from working.</p> <pre><code>wget https://raw.githubusercontent.com/vabene1111/recipes/develop/docs/install/docker/plain/docker-compose.yml\n</code></pre> <pre><code>services:\n  db_recipes:\n    restart: always\n    image: postgres:16-alpine\n    volumes:\n      - ./postgresql:/var/lib/postgresql/data\n    env_file:\n      - ./.env\n\n  web_recipes:\n    restart: always\n    image: vabene1111/recipes\n    env_file:\n      - ./.env\n    ports:\n      - 80:80\n    volumes:\n      - staticfiles:/opt/recipes/staticfiles\n      - ./mediafiles:/opt/recipes/mediafiles\n    depends_on:\n      - db_recipes\n\nvolumes:\n  staticfiles:\n</code></pre>"},{"location":"install/docker/#reverse-proxy","title":"Reverse Proxy","text":"<p>Most deployments will likely use a reverse proxy.</p>"},{"location":"install/docker/#traefik","title":"Traefik","text":"<p>If you use Traefik, this configuration is the one for you.</p> <p>Info</p> <p>Traefik can be a little confusing to setup. Please refer to their excellent documentation. If that does not help, this little example might be for you.</p> <pre><code>wget https://raw.githubusercontent.com/vabene1111/recipes/develop/docs/install/docker/traefik-nginx/docker-compose.yml\n</code></pre> <pre><code>services:\n  db_recipes:\n    restart: always\n    image: postgres:16-alpine\n    volumes:\n      - ./postgresql:/var/lib/postgresql/data\n    env_file:\n      - ./.env\n    networks:\n      - default\n\n  web_recipes:\n    restart: always\n    image: vabene1111/recipes\n    env_file:\n      - ./.env\n    volumes:\n      - staticfiles:/opt/recipes/staticfiles\n      - ./mediafiles:/opt/recipes/mediafiles\n    depends_on:\n      - db_recipes\n    labels: # traefik example labels\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.recipes.rule=Host(`recipes.mydomain.com`, `recipes.myotherdomain.com`)\"\n      - \"traefik.http.routers.recipes.entrypoints=web_secure\" # your https endpoint\n      - \"traefik.http.routers.recipes.tls.certresolver=le_resolver\" # your cert resolver\n    networks:\n      - default\n      - traefik\n\n\nnetworks:\n  default:\n  traefik: # This is your external traefik network\n    external: true\n\nvolumes:\n  staticfiles:\n</code></pre>"},{"location":"install/docker/#jwilders-nginx-proxy","title":"jwilder's Nginx-proxy","text":"<p>This is a docker compose example using jwilder's nginx reverse proxy in combination with jrcs's letsencrypt companion.</p> <p>Please refer to the appropriate documentation on how to setup the reverse proxy and networks.</p> <p>Adjust client_max_body_size</p> <p>By using jwilder's Nginx-proxy, uploads will be restricted to 1 MB file size. This can be resolved by adjusting the <code>client_max_body_size</code> variable in the jwilder nginx configuration.</p> <p>Remember to add the appropriate environment variables to the <code>.env</code> file:</p> <pre><code>VIRTUAL_HOST=\nLETSENCRYPT_HOST=\nLETSENCRYPT_EMAIL=\n</code></pre> <pre><code>wget https://raw.githubusercontent.com/vabene1111/recipes/develop/docs/install/docker/nginx-proxy/docker-compose.yml\n</code></pre> <pre><code>services:\n  db_recipes:\n    restart: always\n    image: postgres:16-alpine\n    volumes:\n      - ./postgresql:/var/lib/postgresql/data\n    env_file:\n      - ./.env\n    networks:\n      - default\n\n  web_recipes:\n    restart: always\n    image: vabene1111/recipes\n    env_file:\n      - ./.env\n    volumes:\n      - staticfiles:/opt/recipes/staticfiles\n      - ./mediafiles:/opt/recipes/mediafiles\n    depends_on:\n      - db_recipes\n    networks:\n      - default\n      - nginx-proxy\n\nnetworks:\n  default:\n  nginx-proxy:\n    external:\n      name: nginx-proxy\n\nvolumes:\n  staticfiles:\n</code></pre>"},{"location":"install/docker/#apache-proxy","title":"Apache proxy","text":"<p>If you use Apache as a reverse proxy, this configuration is the one for you.</p> <pre><code>services:\n  db_recipes:\n    restart: always\n    image: postgres:16-alpine\n    volumes:\n      - ./postgresql:/var/lib/postgresql/data\n    env_file:\n      - ./.env\n\n  web_recipes:\n    restart: always\n    image: vabene1111/recipes\n    ports:\n      - 127.0.0.1:8080:80 # replace port\n    env_file:\n      - ./.env\n    volumes:\n      - staticfiles:/opt/recipes/staticfiles\n      - ./mediafiles:/opt/recipes/mediafiles\n    depends_on:\n      - db_recipes\n\nvolumes:\n  staticfiles:\n</code></pre> <p>Keep in mind, that the port configured for the service <code>web_recipes</code> should be the same as in chapter Required Headers: Apache.</p>"},{"location":"install/docker/#dockstarter","title":"DockSTARTer","text":"<p>The main goal of DockSTARTer is to make it quick and easy to get up and running with Docker. You may choose to rely on DockSTARTer for various changes to your Docker system or use DockSTARTer as a stepping stone and learn to do more advanced configurations. Follow the guide for installing DockSTARTer and then run <code>ds</code> then select 'Configuration' and 'Select Apps' to get Tandoor up and running quickly and easily.</p> <p>Note</p> <p>DockSTARTer might not be updated for Tandoor 2 configurations</p>"},{"location":"install/docker/#additional-information","title":"Additional Information","text":""},{"location":"install/docker/#nginx-config","title":"Nginx Config","text":"<p>Starting with Tandoor 2 the Docker container includes a nginx service. Its default configuration is pulled from the http.d folder in the repository. </p> <p>You can setup a volume to link to the <code>/opt/recipes/http.d</code> folder inside your container to change the configuration. Keep in mind that you will not receive any updates on the configuration  if you manually change it/bind the folder as a volume. </p>"},{"location":"install/docker/#required-headers","title":"Required Headers","text":"<p>Please be sure to supply all required headers in your nginx/Apache/Caddy/... configuration!</p>"},{"location":"install/docker/#nginx","title":"nginx","text":"<pre><code>location / {\n    proxy_set_header Host $http_host; # try $host instead if this doesn't work\n    proxy_set_header X-Forwarded-Proto $scheme;\n    proxy_pass http://127.0.0.1:8080; # replace port\n    proxy_redirect http://127.0.0.1:8080 https://recipes.domain.tld; # replace port and domain\n}\n</code></pre>"},{"location":"install/docker/#apache","title":"Apache","text":"<pre><code>RequestHeader set X-Forwarded-Proto \"https\"\nHeader always set Access-Control-Allow-Origin \"*\"\n\nProxyPreserveHost  On\nProxyRequests Off\nProxyPass / http://localhost:8080/ # replace port\nProxyPassReverse / http://localhost:8080/ # replace port\n</code></pre>"},{"location":"install/docker/#setup-issues-on-raspberry-pi","title":"Setup issues on Raspberry Pi","text":"<p>Danger</p> <p>Tandoor 2 does no longer build images for arm/v7 architectures. You can certainly get Tandoor working there but it has simply been to much effort to maintain these architectures over the past years to justify the continued support of this mostly deprecated platform. </p> <p>Info</p> <p>Always wait at least 2-3 minutes after the very first start, since migrations will take some time!</p> <p>If you're having issues with installing Tandoor on your Raspberry Pi or similar device, follow these instructions:</p> <ul> <li>Stop all Tandoor containers (<code>docker-compose down</code>)</li> <li>Delete local database folder (usually 'postgresql' in the same folder as your 'docker-compose.yml' file)</li> <li>Start Tandoor containers again (<code>docker-compose up -d</code>)</li> <li>Wait for at least 2-3 minutes and then check if everything is working now (migrations can take quite some time!)</li> <li>If not, check logs of the web_recipes container with <code>docker logs &lt;container_name&gt;</code> and make sure that all migrations are indeed already done</li> </ul>"},{"location":"install/docker/#sub-path-nginx-config","title":"Sub Path nginx config","text":"<p>If hosting under a sub-path you might want to change the default nginx config with the following config.</p> <pre><code>location /my_app { # change to subfolder name\n    include /config/nginx/proxy.conf;\n    proxy_pass https://mywebapp.com/; # change to your host name:port\n    proxy_set_header Host $host;\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header X-Script-Name /my_app; # change to subfolder name\n    proxy_cookie_path / /my_app; # change to subfolder name\n}\n\nlocation /media/ {\n    include /config/nginx/proxy.conf;\n    alias /mediafiles/;\n    client_max_body_size 16M;\n\n}\n\nlocation /static/ {\n    include /config/nginx/proxy.conf;\n    alias /staticfiles/;\n    client_max_body_size 16M;\n\n}\n</code></pre>"},{"location":"install/docker/#tandoor-1-vs-tandoor-2","title":"Tandoor 1 vs Tandoor 2","text":"<p>Tandoor 1 includes gunicorn, a python WSGI server that handles python code well but is not meant to serve mediafiles. Thus, it has always been recommended to set up a nginx webserver  (not just a reverse proxy) in front of Tandoor to handle mediafiles. The gunicorn server by default is exposed on port 8080.</p> <p>Tandoor 2 now bundles nginx inside the container and exposes port 80 where mediafiles are handled by nginx and all the other requests are (mostly) passed to gunicorn.</p> <p>A GitHub Issue has been created to allow for discussions and FAQ's on this issue while this change is fresh. It will later be updated in the docs here if necessary. </p>"},{"location":"install/helmChart/","title":"helmChart","text":"<p>Community Contributed</p> <p>This guide was contributed by the community and is neither officially supported, nor updated or tested.</p>"},{"location":"install/helmChart/#helm-install-setup","title":"Helm Install Setup","text":"<p>Assumptions:</p> <ol> <li>You have a running postgres database you can access.</li> <li>The initial version of this chart does not include a LB. It assume you will point to the service that will be create by using either an Ingress manifest or a httproute.</li> </ol> <p>Example config values.yaml. Please see helm-chart repo for the last version.</p> <p>Basic minimal example:</p> <p>values.yaml <pre><code>## these are not needed but I'm setting them so they're consistent with my env. The routes I give assume these settings.\nnamespaceOverride: food\nfullnameOverride: \"recipes\"\n\n\nChange to latest version if out of date.\n#global:\n#  create_namespace: false\n#  image: vabene1111/recipes\n#  tandoor_version: 2.3\n\n# Environment variables\nenv: \n## Values below will get you to a basic working installation\n  - name: DB_ENGINE\n    value: django.db.backends.postgresql\n  - name: POSTGRES_HOST\n    value: shared-rw.postgres-operator.svc.cluster.local\n  - name: POSTGRES_PORT\n    value: \"5432\"\n  - name: POSTGRES_DB\n    value: fooddb\n  - name: SECRET_KEY\n    valueFrom:\n      secretKeyRef:\n        name: recipes-secrets\n        key: secret-key\n  - name: POSTGRES_USER\n    valueFrom:\n      secretKeyRef:\n        name: recipes-secrets\n        key: username\n  - name: POSTGRES_PASSWORD\n    valueFrom:\n      secretKeyRef:\n        name: recipes-secrets\n        key: password\n## I skipped email support but feel free to add it as well. \n\n# Persistent Volume Claims, is not strictly required but it's highly recommended\n# to create a few volumes to persist your data. Otherwise those files would reboot\n# on each pod restart.\npersistence:\n  enabled: true\n  volumes:\n    - name: staticfiles\n      mountPath: /opt/recipes/staticfiles\n      size: 1Gi\n    - name: mediafiles\n      mountPath: /opt/recipes/mediafiles\n      size: 1Gi\n\n## In Production, use a different way of getting the secrets in. unless this code never leaves your server.\n## In a \"Prod\" like homelab you should use ESO or Sealed Secrets, etc populate these values.\nextraResources:\n  - apiVersion: v1\n    kind: Secret\n    metadata:\n      name: recipes-secrets\n      namespace: food\n    type: Opaque\n    stringData:\n      password: superSecretDBPass\n      secret-key: ## output of openssl rand -base64 32 | tr -d '/+=' | head -c 32 \n      username: db_username\n</code></pre></p> <p>Install the chart:</p> <pre><code>helm install recipe-manager -n food oci://ghcr.io/csg33k/helm-charts/tandoor --version 0.0.1 -f myvalues.yaml \n</code></pre> <p>Once that is complete all you need is to setup your Ingress / httproute. Everyone does this differently but if you have an Gateway already setup setting up a route is as easy as:</p> <pre><code>apiVersion: gateway.networking.k8s.io/v1\nkind: HTTPRoute\nmetadata:\n  name: food-https\n  namespace: food\nspec:\n  parentRefs:\n    - name: http-gateway ## Change this\n      namespace: default  ## Change this\n      sectionName: https\n  hostnames:\n    - food.domain.tld ## Change this\n  rules:\n    - backendRefs:\n        - name: recipes ## If the name is different for your env, update it accordingly.\n          port: 80\n</code></pre> <p>That's it! Happy cooking! ~~~</p>"},{"location":"install/homeassistant/","title":"HomeAssistant","text":"<p>Community Contributed</p> <p>This guide was contributed by the community and is neither officially supported, nor updated or tested.  Many thanks to alexbelgium for making implementing everything required to have  Tandoor run in HA.</p> <p>Tandoor 2 Compatibility</p> <p>This guide has not been verified/tested for Tandoor 2, which now integrates a nginx service inside the default docker container and exposes its service on port 80 instead of 8080.</p> <p> </p>"},{"location":"install/homeassistant/#introduction","title":"Introduction","text":"<p>Home Assistant (HA) is a free and open-source software for home automation designed to be a central control system for smart home devices with a focus on local control and privacy. It can be accessed through a web-based user interface by using companion apps for Android and iOS, or by voice commands via a supported virtual assistant such as Google Assistant or Amazon Alexa.</p> <p>It can be installed as a standalone Operating System on a dedicated system, making it easy to deploy and maintain through Over The Air updates. It can also be installed as Docker container.</p> <p>In addition to its large depth of native functions, modular addons can be added to expand its functions. An addon for Tandoor Recipes was created, allowing to store the server on the Home Assistant devices and access the user interface either through direct web access or securely through the native Home Assistant app.</p>"},{"location":"install/homeassistant/#installation","title":"Installation","text":"<ol> <li>Once you have a running Home Assistant system, the next step is to add the alexbelgium's custom repository to your system. This is performed by clicking on the button below, and simply filling your HA url. </li> <li>Install the addon </li> <li>Set the add-on options to your preferences (see below)</li> <li>Start the add-on</li> <li>Check the logs of the add-on to see if everything went well.</li> <li>Open the webUI (either through Ingress, or direct webUI with http://homeassistant.local:9928) and adapt the software options</li> </ol>"},{"location":"install/homeassistant/#configuration","title":"Configuration","text":"<p>The following environment variable are configurable from the addon options. Please see the Docker documentation for more information on how they should be filled.</p> <pre><code>Required :\n    \"ALLOWED_HOSTS\": \"your system url\", # You need to input your homeassistant urls (comma separated, without space) to allow ingress to work\n    \"DB_TYPE\": \"list(sqlite|postgresql_external|mariadb_addon)\" # Type of database to use. Mariadb_addon allows to be automatically configured if the maria_db addon is already installed on your system. Sqlite is an internal database. For postgresql_external, you'll need to fill the below settings\n    \"SECRET_KEY\": \"str\", # Your secret key\n    \"PORT\": 9928 # By default, the webui is available on http://homeassistant.local:9928. If you ever need to change the port, you should never do it within the app, but only through this option\nOptional :\n    \"POSTGRES_HOST\": \"str?\", # Needed for postgresql_external\n    \"POSTGRES_PORT\": \"str?\", # Needed for postgresql_external\n    \"POSTGRES_USER\": \"str?\", # Needed for postgresql_external\n    \"POSTGRES_PASSWORD\": \"str?\", # Needed for postgresql_external\n    \"POSTGRES_DB\": \"str?\" # Needed for postgresql_external\n</code></pre>"},{"location":"install/homeassistant/#updates-and-backups","title":"Updates and backups","text":"<p>The alexbelgium's repo incorporates a script that aligns every 3 days the addon to the containers released. Just wait a few hours for HA to refreshes its repo list and the uodate will be proposed automatically in your HA system.</p> <p>It is recommended to frequently backup. All data is stored outside of the addon, the main location <code>/config/addons_config/tandoor_recipes</code>, so be sure to backup this folder in addition to the addon itself when updating. If you have selected mariadb as database option, don't forget to also backup it.</p>"},{"location":"install/homeassistant/#support","title":"Support","text":"<p>Issues related to the addon itself should be reported on the maintainer repo.</p> <p>Issues related to HA should be reported on the HA Community Forum.</p> <p>Issues related to Tandoor recipes should be reported on this github repo.</p>"},{"location":"install/kubernetes/","title":"Kubernetes","text":"<p>Community Contributed</p> <p>This guide was contributed by the community and is neither officially supported, nor updated or tested.</p> <p>Tandoor 2 Compatibility</p> <p>This guide has not been verified/tested for Tandoor 2, which now integrates a nginx service inside the default docker container and exposes its service on port 80 instead of 8080.</p>"},{"location":"install/kubernetes/#k8s-setup","title":"K8s Setup","text":"<p>This is a setup which should be sufficient for production use. Be sure to replace the default secrets! You can find the example files here on Github.</p>"},{"location":"install/kubernetes/#files","title":"Files","text":""},{"location":"install/kubernetes/#10-configmapyaml","title":"10-configmap.yaml","text":"<p>The nginx config map. This is loaded as nginx.conf in the nginx sidecar to configure nginx to deliver static content.</p>"},{"location":"install/kubernetes/#15-secretsyaml","title":"15-secrets.yaml","text":"<p>Contains secrets</p> <p>Replace them!</p> <p>This file is only here for a quick start. Be aware that changing secrets after installation will be messy and is not documented here. You should set new secrets before the installation. As you are reading this document before the installation ;-)</p> <p>Create your own postgresql passwords and the secret key for the django app.</p> <p>See also Managing Secrets using kubectl</p> <p>Replace <code>db-password</code>, <code>postgres-user-password</code> and <code>secret-key</code> with something - well - secret :-)</p> <pre><code>echo -n 'db-password' &gt; ./db-password.txt\necho -n 'postgres-user-password' &gt; ./postgres-password.txt\necho -n 'secret-key' | sha256sum | awk '{ printf $1 }' &gt; ./secret-key.txt\n</code></pre> <p>Delete the default secrets file <code>15-secrets.yaml</code> and generate the K8s secret from your files.</p> <pre><code>kubectl create secret generic recipes \\\n  --from-file=postgresql-password=./db-password.txt \\\n  --from-file=postgresql-postgres-password=./postgres-password.txt \\\n  --from-file=secret-key=./secret-key.txt\n</code></pre>"},{"location":"install/kubernetes/#20-service-accountyml","title":"20-service-account.yml","text":"<p>Creating service account <code>recipes</code> for deployment and stateful set.</p>"},{"location":"install/kubernetes/#30-pvcyaml","title":"30-pvc.yaml","text":"<p>The creation of the persistent volume claims for media and static content. May you want to increase the size. This expects to have a storage class installed.</p>"},{"location":"install/kubernetes/#40-sts-postgresqlyaml","title":"40-sts-postgresql.yaml","text":"<p>The PostgreSQL stateful set, based on a bitnami image. It runs a init container as root to do the preparations. The postgres container itself runs as a lower privileged user. The recipes app uses the database super user (postgres) as the recipes app is doing some db migrations on startup, which needs super user privileges.</p>"},{"location":"install/kubernetes/#45-service-dbyaml","title":"45-service-db.yaml","text":"<p>Creating the database service.</p>"},{"location":"install/kubernetes/#50-deploymentyaml","title":"50-deployment.yaml","text":"<p>The deployment first fires up a init container to do the database migrations and file modifications. This init container runs as root. The init container runs part of the boot.sh script from the <code>vabene1111/recipes</code> image. </p> <p>The deployment then runs two containers, the recipes-nginx and the recipes container which runs the gunicorn app. The nginx container gets it's nginx.conf via config map to deliver static content <code>/static</code> and <code>/media</code>. The guincorn container gets it's secret key and the database password from the secret <code>recipes</code>. <code>gunicorn</code> runs as user <code>nobody</code>.</p> <p>Currently, this deployment is using the <code>latest</code> image. You may want to explicitly set the tag, e.g.</p> <pre><code>image: vabene1111/recipes:1.4.7\n</code></pre> <p>It is extremely important to use the same image in both the initialization <code>init-chmod-data</code> and the main <code>recipes</code> containers.</p>"},{"location":"install/kubernetes/#60-serviceyaml","title":"60-service.yaml","text":"<p>Creating the app service.</p>"},{"location":"install/kubernetes/#70-ingressyaml","title":"70-ingress.yaml","text":"<p>Setting up the ingress for the recipes service. Requests for static content <code>/static</code> and <code>/media</code> are send to the nginx container, everything else to gunicorn. TLS setup via cert-manager is prepared. You have to change the host from <code>recipes.local</code> to your specific domain.</p>"},{"location":"install/kubernetes/#conclusion","title":"Conclusion","text":"<p>All in all:</p> <ul> <li>The database is set up as a stateful set.</li> <li>The database container runs as a low privileged user.</li> <li>Database and application use secrets.</li> <li>The application also runs as a low privileged user.</li> <li>nginx runs as root but forks children with a low privileged user.</li> <li>There's an ingress rule to access the application from outside.</li> </ul> <p>I tried the setup with kind and it runs well on my local cluster.</p> <p>There is a warning, when you check your system as super user:</p> <p>Media Serving Warning</p> <p>Serving media files directly using gunicorn/python is not recommend! Please follow the steps described here to update your installation.</p> <p>I don't know how this check works, but this warning is simply wrong! ;-) Media and static files are routed by ingress to the nginx container - I promise :-)</p>"},{"location":"install/kubernetes/#updates","title":"Updates","text":"<p>These manifests have been tested for several releases. Newer versions may not work without changes.</p> <p>If everything works as expected, the <code>init-chmod-data</code> initialization container performs the database migration and the update procedure is transparent. However, it is recommended to use specific tags to increase stability and avoid unnecessary migrations.</p>"},{"location":"install/kubernetes/#apply-the-manifets","title":"Apply the manifets","text":"<p>To apply the manifest with kubectl, use the following command:</p> <pre><code>kubectl apply -f ./docs/install/k8s/\n</code></pre>"},{"location":"install/kubesail/","title":"KubeSail or PiBox","text":"<p>Community Contributed</p> <p>This guide was contributed by the community and is neither officially supported, nor updated or tested.</p> <p>Tandoor 2 Compatibility</p> <p>This guide has not been verified/tested for Tandoor 2, which now integrates a nginx service inside the default docker container and exposes its service on port 80 instead of 8080.</p> <p>KubeSail lets you install Tandoor by providing a simple web interface for installing and managing apps. You can connect any server running Kubernetes, or get a pre-configured PiBox.</p> <p>The KubeSail template is closely based on the Kubernetes installation configs</p>"},{"location":"install/kubesail/#quick-start","title":"Quick Start","text":"<p>Load the Tandoor Recipes template, and click Launch Template.</p> <p>If you have not yet attached your server to KubeSail, see the Getting a Cluster section on the KubeSail docs.</p>"},{"location":"install/kubesail/#important-notes","title":"Important notes","text":"<p>In the \"Template Variables\" section you will see two input fields. These should show <code>RANDOM(16)</code>, indicating they will be randomly generated and specific to your install when you launch the template. If you prefer to set these yourself, you can type them in before launching the template.</p> <p></p>"},{"location":"install/manual/","title":"Manual installation instructions","text":"<p>These instructions are inspired from a standard django/gunicorn/postgresql instructions (for example)</p> <p>Warning</p> <p>Make sure to use at least Python 3.12 or higher, and ensure that <code>pip</code> is associated with Python 3. Depending on your system configuration, using <code>python</code> or <code>pip</code> might default to Python 2. Make sure your machine has at least 2048 MB of memory; otherwise, the <code>yarn build</code> process may fail with the error: <code>FATAL ERROR: Reached heap limit - Allocation failed: JavaScript heap out of memory</code>.</p> <p>Warning</p> <p>These instructions are not regularly reviewed and might be outdated.</p>"},{"location":"install/manual/#prerequisites","title":"Prerequisites","text":"<p>Setup user: <code>sudo useradd recipes</code></p> <p>Update the repositories and upgrade your OS: <code>sudo apt update &amp;&amp; sudo apt upgrade -y</code></p> <p>Install all prerequisits <code>sudo apt install -y git curl python3 python3-pip python3-venv nginx</code></p> <p>Get the last version from the repository: <code>git clone https://github.com/vabene1111/recipes.git -b master</code></p> <p>Move it to the <code>/var/www</code> directory: <code>mv recipes /var/www</code></p> <p>Change to the directory: <code>cd /var/www/recipes</code></p> <p>Give the user permissions: <code>chown -R recipes:www-data /var/www/recipes</code></p> <p>Create virtual env: <code>python3 -m venv /var/www/recipes</code></p> <p>Activate virtual env: <code>source /var/www/recipes/bin/activate</code></p> <p>Install Javascript Tools (nodejs &gt;= 12 required) <pre><code>### Just use one of these possibilites!\n# Using Ubuntu\ncurl -fsSL https://deb.nodesource.com/setup_lts.x | sudo -E bash -\nsudo apt install -y nodejs\n\n# Using Debian, as root\ncurl -fsSL https://deb.nodesource.com/setup_lts.x | bash -\napt install -y nodejs\n\n# Using a RPM based distro\n## ... as root\ncurl -fsSL https://rpm.nodesource.com/setup_lts.x | bash -\n\n## ... no root privileges\ncurl -fsSL https://rpm.nodesource.com/setup_lts.x | sudo bash -\n</code></pre> <pre><code>sudo npm install --global yarn\n</code></pre></p> <p>NodeJS installation issues</p> <p>If you run into problems with the NodeJS installation, please refer to the official documentation.</p>"},{"location":"install/manual/#install-postgresql-requirements","title":"Install postgresql requirements","text":"<pre><code>sudo apt install -y libpq-dev postgresql\n</code></pre>"},{"location":"install/manual/#install-ldap-requirements","title":"Install LDAP requirements","text":"<pre><code>sudo apt install -y libsasl2-dev python3-dev libldap2-dev libssl-dev\n</code></pre>"},{"location":"install/manual/#install-project-requirements","title":"Install project requirements","text":"<p>Update</p> <p>Dependencies change with most updates so the following steps need to be re-run with every update or else the application might stop working. See section Updating below.</p> <p>Using binaries from the virtual env:</p> <pre><code>/var/www/recipes/bin/pip3 install -r requirements.txt\n</code></pre> <p>You will also need to install front end requirements and build them. For this navigate to the <code>./vue3</code> folder and run</p> <pre><code>cd ./vue3\nyarn install\nyarn build\n</code></pre>"},{"location":"install/manual/#setup-postgresql","title":"Setup postgresql","text":"<pre><code>sudo -u postgres psql\n</code></pre> <p>In the psql console:</p> <pre><code>CREATE DATABASE djangodb;\nCREATE USER djangouser WITH PASSWORD 'password';\nGRANT ALL PRIVILEGES ON DATABASE djangodb TO djangouser;\nALTER DATABASE djangodb OWNER TO djangouser;\n\n--Maybe not necessary, but should be faster:\nALTER ROLE djangouser SET client_encoding TO 'utf8';\nALTER ROLE djangouser SET default_transaction_isolation TO 'read committed';\nALTER ROLE djangouser SET timezone TO 'UTC';\n\n--Grant superuser right to your new user, it will be removed later\nALTER USER djangouser WITH SUPERUSER;\n\n--exit Postgres Environment\nexit\n</code></pre> <p>Download the <code>.env</code> configuration file and edit it accordingly. <pre><code>wget https://raw.githubusercontent.com/vabene1111/recipes/develop/.env.template -O /var/www/recipes/.env\n</code></pre></p> <p>Things to edit:</p> <ul> <li><code>SECRET_KEY</code>: use something secure (generate it with <code>base64 /dev/urandom | head -c50</code> f.e.).</li> <li><code>POSTGRES_HOST</code>: probably 127.0.0.1.</li> <li><code>POSTGRES_PASSWORD</code>: the password we set earlier when setting up djangodb.</li> <li><code>STATIC_URL</code>, <code>MEDIA_URL</code>: these will be in <code>/var/www/recipes</code>, under <code>/staticfiles/</code> and <code>/mediafiles/</code> respectively.</li> </ul>"},{"location":"install/manual/#initialize-the-application","title":"Initialize the application","text":"<p>Execute <code>export $(cat /var/www/recipes/.env |grep \"^[^#]\" | xargs)</code> to load variables from <code>/var/www/recipes/.env</code></p> <p>Execute <code>bin/python3 manage.py migrate</code></p> <p>and revert superuser from postgres:</p> <pre><code>sudo -u postgres psql` and `ALTER USER djangouser WITH NOSUPERUSER;\nexit\n</code></pre> <p>Generate static files: <code>bin/python3 manage.py collectstatic --no-input</code> and <code>bin/python3 manage.py collectstatic_js_reverse</code> and remember the folder where files have been copied.</p>"},{"location":"install/manual/#setup-web-services","title":"Setup web services","text":""},{"location":"install/manual/#gunicorn","title":"gunicorn","text":"<p>Create a service that will start gunicorn at boot: <code>sudo nano /etc/systemd/system/gunicorn_recipes.service</code></p> <p>And enter these lines:</p> <pre><code>[Unit]\nDescription=gunicorn daemon for recipes\nAfter=network.target\n\n[Service]\nType=simple\nRestart=always\nRestartSec=3\nUser=recipes\nGroup=www-data\nWorkingDirectory=/var/www/recipes\nEnvironmentFile=/var/www/recipes/.env\nExecStart=/var/www/recipes/bin/gunicorn --error-logfile /tmp/gunicorn_err.log --log-level debug --capture-output --bind unix:/var/www/recipes/recipes.sock recipes.wsgi:application\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Note: <code>-error-logfile /tmp/gunicorn_err.log --log-level debug --capture-output</code> are useful for debugging and can be removed later</p> <p>Note2: Fix the path in the <code>ExecStart</code> line to where you gunicorn and recipes are</p> <p>Finally, run <code>sudo systemctl enable --now gunicorn_recipes</code>. You can check that the service is correctly started with <code>systemctl status gunicorn_recipes</code></p>"},{"location":"install/manual/#nginx","title":"nginx","text":"<p>Now we tell nginx to listen to a new port and forward that to gunicorn. <code>sudo nano /etc/nginx/conf.d/recipes.conf</code></p> <p>And enter these lines:</p> <pre><code>server {\n    listen 8002;\n    #access_log /var/log/nginx/access.log;\n    #error_log /var/log/nginx/error.log;\n\n    # serve media files\n    location /static/ {\n        alias /var/www/recipes/staticfiles;\n    }\n\n    location /media/ {\n        alias /var/www/recipes/mediafiles;\n    }\n\n    location / {\n        proxy_set_header Host $http_host;\n        proxy_pass http://unix:/var/www/recipes/recipes.sock;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_set_header X-Forwarded-For $remote_addr;\n    }\n}\n</code></pre> <p>Note: Enter the correct path in static and proxy_pass lines.</p> <p>Reload nginx : <code>sudo systemctl reload nginx</code></p>"},{"location":"install/manual/#updating","title":"Updating","text":"<p>In order to update the application you will need to run the following commands (probably best to put them into a small script).</p> <pre><code># change directory\ncd /var/www/recipes\n# Update source files\ngit pull\n# load envirtonment variables\nexport $(cat /var/www/recipes/.env |grep \"^[^#]\" | xargs)\n#install project requirements\nbin/pip3 install -r requirements.txt\n# migrate database \nbin/python3 manage.py migrate\n# collect static files\n# if the output is not \"0 static files copied\" you might want to run the commands again to make sure everythig is collected\nbin/python3 manage.py collectstatic --no-input\nbin/python3 manage.py collectstatic_js_reverse\n# change to frontend directory\ncd vue3\n# install and build frontend\nyarn install\nyarn build\n# restart gunicorn service\nsudo systemctl restart gunicorn_recipes\n</code></pre>"},{"location":"install/other/","title":"Other setups","text":"<p>Community Contributed</p> <p>The examples in this section were contributed by members of the community. This page especially contains some setups that might help you if you really want to go down a certain path but none of the examples are supported (as I simply am not able to give you support for them).</p> <p>Tandoor 2 Compatibility</p> <p>This guide has not been verified/tested for Tandoor 2, which now integrates a nginx service inside the default docker container and exposes its service on port 80 instead of 8080.</p>"},{"location":"install/other/#apache-traefik-sub-path","title":"Apache + Traefik + Sub-Path","text":"<p>This guide was contributes by incaseoftrouble in Issue #266</p> <p>My setup is docker-compose / traefik / apache / recipes. Swapping out apache for nginx should be straightforward.</p> <p>Relevant parts:</p> <p>docker-compose: <pre><code>  apache:\n    # omitting other config\n    volumes:\n      - ./recipes/static:/var/www/recipes/static:ro\n      - ./recipes/media:/var/www/recipes/media:ro\n    labels:\n      traefik.enable: true\n      traefik.http.routers.apache-recipes.rule: Host(`&lt;host&gt;`) &amp;&amp; PathPrefix(`/&lt;www path&gt;`)\n      traefik.http.routers.apache-recipes.entrypoints: http\n      traefik.http.routers.apache-recipes.service: apache\n      traefik.http.services.apache.loadbalancer.server.port: 80\n      traefik.http.services.apache.loadbalancer.server.scheme: http\n...\n\n  recipes:\n    volumes:\n      - ./recipes/static:/opt/recipes/staticfiles:rw\n      - ./recipes/media:/opt/recipes/mediafiles:rw\n    environment:\n      # all the other env\n      - SCRIPT_NAME=/&lt;sub path&gt;\n      - STATIC_URL=/&lt;www path&gt;/static/\n      - MEDIA_URL=/&lt;www path&gt;/media/\n    labels:\n      traefik.enable: true\n      traefik.http.routers.recipes.rule: Host(`&lt;host&gt;`) &amp;&amp; PathPrefix(`/&lt;sub path&gt;`)\n      traefik.http.routers.recipes.entrypoints: http\n      traefik.http.services.recipes.loadbalancer.server.port: 8080\n      traefik.http.services.recipes.loadbalancer.server.scheme: http\n</code></pre></p> <p>apache:  <pre><code>  Alias /&lt;www path&gt;/static/ /var/www/recipes/static/\n  Alias /&lt;www path&gt;/media/ /var/www/recipes/media/\n  &lt;Directory \"/var/www/recipes/\"&gt;\n    Require all granted\n  &lt;/Directory&gt;\n</code></pre></p> <p>I used two paths <code>&lt;sub path&gt;</code> and <code>&lt;www path&gt;</code> for simplicity. In my case I have <code>&lt;sub path&gt; = recipes</code> and <code>&lt;www path&gt; = serve/recipes</code>. One could also change the matching rules of traefik to have everything under one path.</p> <p>I left out the TLS config in this example for simplicity.</p>"},{"location":"install/other/#docker-apache-sub-path","title":"Docker + Apache + Sub-Path","text":"<p>The following could prove to be useful if you are not using Traefik, but instead run Apache as your reverse proxy to route all calls for a shared (sub)domain to a sub path, e.g. https://mydomain.tld/tandoor</p> <p>As a side note, I am using Blocky + Consul + Registrator as a DNS solution.</p> <p>The relevant Apache config: <pre><code>    &lt;Location /tandoor&gt;\n        # in case you want to restrict access to specific IP addresses:\n        Require local\n        Require forward-dns [myhomedomain.useyourdomain.com]\n        Require ip [anylocalorremoteipyouwanttowhitelist]\n\n        # The following assumes that tandoor.service.consul.local resolves to the IP address of the Docker container.\n        ProxyPass http://tandoor.service.consul.local:8080/tandoor\n        ProxyPassReverse http://tandoor.service.consul.local:8080/tandoor\n        RequestHeader add X-Script-Name /tandoor\n        RequestHeader set X-Forwarded-Proto \"https\"\n        ProxyPreserveHost On\n    &lt;/Location&gt;\n    &lt;Location /tandoor/static&gt;\n        Require local\n        Require forward-dns [myhomedomain.useyourdomain.com]\n        Require ip [anylocalorremoteipyouwanttowhitelist]\n\n        ProxyPass http://tandoor.service.consul.local:8080/tandoor/tandoor/static\n        ProxyPassReverse http://tandoor.service.consul.local:8080/tandoor/static\n        RequestHeader add X-Script-Name /tandoor\n        RequestHeader set X-Forwarded-Proto \"https\"\n        ProxyPreserveHost On\n    &lt;/Location&gt;\n</code></pre> and the relevant section from the docker-compose.yml: <pre><code>   tandoor:\n     restart: always\n     container_name: tandoor\n     image: vabene1111/recipes\n     environment:\n       - SCRIPT_NAME=/tandoor\n       - STATIC_URL=/tandoor/static/\n       - MEDIA_URL=/tandoor/media/\n       - GUNICORN_MEDIA=0\n       - SECRET_KEY=${YOUR_TANDOOR_SECRET_KEY}\n       - POSTGRES_HOST=postgres.service.consul.local\n       - POSTGRES_PORT=${POSTGRES_PORT}\n       - POSTGRES_USER=${YOUR_TANDOOR_POSTGRES_USER}\n       - POSTGRES_PASSWORD=${YOUR_TANDOOR_POSTGRES_PASSWORD}\n       - POSTGRES_DB=${YOUR_TANDOOR_POSTGRES_DB}\n     labels:\n        # The following is relevant only if you are using Registrator and Consul\n       - \"SERVICE_NAME=tandoor\"\n     volumes:\n       - ${YOUR_DOCKER_VOLUME_BASE_DIR}/tandoor/static:/opt/recipes/staticfiles:rw\n       # Do not make this a bind mount, see https://docs.tandoor.dev/install/docker/#volumes- vs-bind-mounts\n       - tandoor_nginx_config:/opt/recipes/nginx/conf.d\n       - ${YOUR_DOCKER_VOLUME_BASE_DIR}}/tandoor/media:/opt/recipes/mediafiles:rw\n     depends_on:\n        # You will have to set up postgres accordingly\n       - postgres\n</code></pre></p> <p>The relevant docker-compose.yml for Registrator, Consul, and Blocky, and Autoheal: <pre><code>  consul:\n    image: hashicorp/consul\n    container_name: consul\n    command: &gt;\n      agent -server\n      -domain consul.local\n      -advertise=${YOUR_DOCKER_HOST_IP_ON_THE_LAN}\n      -client=0.0.0.0\n      -encrypt=${SOME_SECRET_KEY}\n      -datacenter=${YOUR_DC_NAME}\n      -bootstrap-expect=1\n      -ui\n      -log-level=info\n    environment:\n      - \"CONSUL_LOCAL_CONFIG={\\\"skip_leave_on_interrupt\\\": true, \\\"dns_config\\\": { \\\"service_ttl\\\": { \\\"*\\\": \\\"0s\\\" } } }\"\n    network_mode: \"host\"\n    restart: always\n\n  registrator:\n    image: gliderlabs/registrator:latest\n    container_name: registrator\n    extra_hosts:\n      - \"host.docker.internal:host-gateway\"\n    volumes:\n      - /var/run/docker.sock:/tmp/docker.sock:ro\n    command: &gt;\n      -internal\n      -cleanup=true\n      -deregister=\"always\"\n      -resync=60\n      consul://host.docker.internal:8500\n    restart: always\n\n  blocky:\n    image: spx01/blocky\n    container_name: blocky\n    restart: unless-stopped\n    healthcheck:\n      interval: 30s\n      timeout: 5s\n      start_period: 1m\n    labels:\n        # The following is only relevant if you use autoheal\n      autoheal: true\n    # Optional the instance hostname for logging purpose\n    hostname: blocky\n    extra_hosts:\n      - \"host.docker.internal:host-gateway\"\n    ports:\n      - \"1153:53/tcp\"\n      - \"1153:53/udp\"\n      - 4000:4000\n    environment:\n      - TZ=YOUR_TIMEZONE # Optional to synchronize the log timestamp with host\n    volumes:\n      # Optional to synchronize the log timestamp with host\n      - /etc/localtime:/etc/localtime:ro\n      # config file\n      - ${YOUR_DOCKER_VOLUME_BASE_DIR}/blocky/config.yml:/app/config.yml\n    networks:\n        # in case you want to bind Blocky to an IP address\n      your-docker-network-name:\n        ipv4_address: 'some-ip-address-in-the-docker-network-subnet'\n\n  autoheal:\n    image: willfarrell/autoheal\n    volumes:\n        - '/var/run/docker.sock:/var/run/docker.sock'\n    environment:\n        - AUTOHEAL_CONTAINER_LABEL=autoheal\n    restart: always\n    container_name: autoheal\n</code></pre> as well as a snippet of the Blocky configuration: <pre><code>conditional:\n  fallbackUpstream: false\n  mapping:\n    consul.local: tcp+udp:host.docker.internal:8600\n</code></pre></p>"},{"location":"install/other/#wsl","title":"WSL","text":"<p>If you want to install Tandoor on the Windows Subsystem for Linux you can find a detailed post here: https://github.com/TandoorRecipes/recipes/issues/1733.</p>"},{"location":"install/swag/","title":"Swag","text":"<p>Danger</p> <pre><code>Please refer to the [official documentation](https://github.com/linuxserver/docker-swag#usage) for the container setup. This example shows just one setup that may or may not differ from yours in significant ways. This tutorial does not cover security measures, backups, and many other things that you might want to consider.\n</code></pre> <p>Tandoor 2 Compatibility</p> <p>This guide has not been verified/tested for Tandoor 2, which now integrates a nginx service inside the default docker container and exposes its service on port 80 instead of 8080.</p>"},{"location":"install/swag/#prerequisites","title":"Prerequisites","text":"<ul> <li>You have a newly spun-up Ubuntu server with docker (pre-)installed.</li> <li>At least one <code>mydomain.com</code> and one <code>mysubdomain.mydomain.com</code> are pointing to the server's IP. (This tutorial does not cover subfolder installation.)</li> <li>You have an ssh terminal session open.</li> </ul>"},{"location":"install/swag/#installation","title":"Installation","text":""},{"location":"install/swag/#download-and-edit-tandoor-configuration","title":"Download and edit Tandoor configuration","text":"<p><pre><code>cd /opt\nmkdir recipes\ncd recipes\nwget https://raw.githubusercontent.com/vabene1111/recipes/develop/.env.template -O .env\nbase64 /dev/urandom | head -c50\n</code></pre> Copy the response from that last command and paste the key into the <code>.env</code> file: <pre><code>nano .env\n</code></pre> You'll also need to enter a Postgres password into the <code>.env</code> file. Then, save the file and exit the editor.</p>"},{"location":"install/swag/#install-and-configure-docker-compose","title":"Install and configure Docker Compose","text":"<p>In keeping with these instructions: <pre><code>cd /opt\ncurl -L --fail https://raw.githubusercontent.com/linuxserver/docker-docker-compose/master/run.sh -o /usr/local/bin/docker-compose\nchmod +x /usr/local/bin/docker-compose\n</code></pre></p> <p>Next, create and edit the docker compose file.</p> <pre><code>nano docker-compose.yml\n</code></pre> <p>Paste the following and adjust your domains, subdomains and time zone.</p> <pre><code>---\nversion: \"2.1\"\nservices:\n  swag:\n    image: ghcr.io/linuxserver/swag\n    container_name: swag\n    cap_add:\n      - NET_ADMIN\n    environment:\n      - PUID=1000\n      - PGID=1000\n      - TZ=Europe/Berlin # &lt;---- EDIT THIS &lt;----  &lt;---- \n      - URL=mydomain.com # &lt;---- EDIT THIS &lt;----  &lt;---- \n      - SUBDOMAINS=mysubdomain,myothersubdomain # &lt;---- EDIT THIS &lt;----  &lt;---- \n      - EXTRA_DOMAINS=myotherdomain.com # &lt;---- EDIT THIS &lt;----  &lt;---- \n      - VALIDATION=http\n    volumes:\n      - ./swag:/config\n      - ./recipes/media:/media\n    ports:\n      - 443:443\n      - 80:80\n    restart: unless-stopped\n\n  db_recipes:\n    restart: always\n    container_name: db_recipes\n    image: postgres:16-alpine\n    volumes:\n      - ./recipes/db:/var/lib/postgresql/data\n    env_file:\n      - ./recipes/.env\n\n  recipes:\n    image: vabene1111/recipes\n    container_name: recipes\n    restart: unless-stopped\n    env_file:\n      - ./recipes/.env\n    environment:\n      - UID=1000\n      - GID=1000\n      - TZ=Europe/Berlin # &lt;---- EDIT THIS  &lt;----  &lt;---- \n    volumes:\n      - ./recipes/static:/opt/recipes/staticfiles\n      - ./recipes/media:/opt/recipes/mediafiles\n    depends_on:\n      - db_recipes\n</code></pre> <p>Save and exit.</p>"},{"location":"install/swag/#create-containers-and-configure-swag-reverse-proxy","title":"Create containers and configure swag reverse proxy","text":"<pre><code>docker-compose up -d\n</code></pre> <pre><code>cd /opt/swag/nginx/proxy-confs\ncp recipes.subdomain.conf.sample recipes.subdomain.conf\nnano recipes.subdomain.conf\n</code></pre> <p>Change the line <code>server_name recipes.*;</code> to <code>server_name mysubdomain.*;</code>, save and exit.</p>"},{"location":"install/swag/#finalize","title":"Finalize","text":"<pre><code>cd /opt\ndocker restart swag recipes\n</code></pre> <p>Go to <code>https://mysubdomain.mydomain.com</code>. (If you get a \"502 Bad Gateway\" error, be patient. It might take a short while until it's functional.)</p>"},{"location":"install/synology/","title":"Synology","text":"<p>Community Contributed</p> <p>This guide was contributed by the community and is neither officially supported, nor updated or tested. Since I cannot test it myself, feedback and improvements are always very welcome.</p>"},{"location":"install/synology/#instructions","title":"Instructions","text":"<p>Basic guide to setup <code>vabenee1111/recipes</code> docker container on Synology NAS.</p>"},{"location":"install/synology/#1-preparations","title":"1. Preparations","text":"<ul> <li>Login to Synology DSM through your browser</li> <li>Install <code>Container Manager</code> through package center</li> <li>Install <code>Text Editor</code> through package center (needed to edit <code>.env</code> if you don't edit it locally first)</li> <li>If you do not already have a shared <code>docker</code> folder in your File Station, create one at the root of your volume. </li> <li>inside of your <code>volume1/docker</code> folder, create a <code>recipes</code> folder. </li> <li>Within, create the necessary folder structure. You will need these folders:</li> </ul> <pre><code>volume1/docker/\n\u251c\u2500 recipes/\n\u2502  \u251c\u2500 postgresql/\n\u2502  \u251c\u2500 mediafiles/\n\u2502  \u251c\u2500 staticfiles/\n\u2502  \u251c\u2500 nginx_config/\n</code></pre>"},{"location":"install/synology/#2-env-and-docker-composeyml","title":"2. <code>.env</code> and <code>docker-compose.yml</code>","text":"<p>!!!info The guide uses the <code>plain</code> setup.</p> <ul> <li>Open the .env template</li> <li>Copy the text and save it as <code>.env.txt</code> to your recipes folder (the .txt extension allows you to modify it)</li> <li>Open the file with Text Editor. Populate the necessary fields, such as <code>SECRET_KEY</code> and <code>POSTGRES_PASSWORD</code>. </li> <li>Save the file and then rename it as <code>.env</code> (without the .txt extension) </li> <li>Open the docker-compose.yml template</li> <li>Copy the text and keep reading. </li> </ul>"},{"location":"install/synology/#3-creating-the-container","title":"3. Creating the Container","text":"<ul> <li>In DSM, open <code>Container Manager</code>. Click on <code>Project</code>. </li> <li>Click <code>Create</code> to create a new project. Fill out the following fields: </li> <li><code>Name</code>: <code>tandoor_recipes</code> or similar. </li> <li><code>Path</code>: select your <code>recipes</code> folder. If you have been following along <code>/docker/recipes</code></li> <li><code>Source</code>: Select <code>Create docker-compose.yml</code>. A textbox will appear. </li> </ul>"},{"location":"install/synology/#4-edit-docker-composeyml","title":"4. Edit docker-compose.yml","text":"<ul> <li>Paste the <code>docker-compose.yml</code> into the <code>source</code> textbox. </li> <li>This file tells docker how to setup recipes. Docker will create two containers for recipes to work, <code>web_recipes</code> and <code>db_recipes</code>. They are all required and need to store and share data through the folders you created before.</li> <li>Under the <code>web_recipes</code> section, you can add <code>ports</code> . This line specifies which external synology port will point to which internal docker port. Chose a free port to use and replace the first number with it. You will open recipes by browsing to http://your.synology.ip:chosen.port, e.g. http://192.168.1.1:2000</li> <li>If you want to use port 2000 you would edit the <code>ports</code> to <code>2000:80</code> <pre><code>ports:\n    - \"2000:80\"\n</code></pre></li> </ul>"},{"location":"install/synology/#5-finishing-up","title":"5. Finishing up","text":"<ul> <li>Click <code>Next</code>. </li> <li>Synology will take you to a <code>web portal settings</code> page. Skip this page by clicking <code>Next</code>. </li> <li>If you enable this option then the container will not build because your specified port will be used by the Web Service. The Container already comes with nginx configured to serve files so you do not need the <code>web portal settings</code>. </li> <li>You'll see a <code>Summary</code> page. Review and click <code>Done</code>. </li> <li>The project will begin being built and should finish.      <pre><code>Container recipes-db_recipes-1 Starting\nContainer recipes-db_recipes-1 Started\nContainer recipes-web_recipes-1 Starting\nContainer recipes-web_recipes-1 Started\nExit Code: 0\n</code></pre></li> <li>If you get an error, review the error and fix. A common reason it might fail is because you did not create the folders specified in the directory tree in step 1.</li> <li>If you notice that <code>web_recipes</code> cannot connect to the database there is probably a misconfiguration in you Firewall, see next section.</li> <li>Browse to 192.168.1.1:2000 or whatever your IP and port are</li> </ul>"},{"location":"install/synology/#6-firewall","title":"6. Firewall","text":"<p>You need to set up firewall rules in order for the <code>recipes_web</code> container to be able to connect to the <code>recipes_db</code> container.</p> <ul> <li>Control Panel -&gt; Security -&gt; Firewall -&gt; Edit Rules -&gt; Create<ul> <li>Ports: All<ul> <li>if you only want to allow the database port 5432, you'll need to create 2 rules to allow ingoing and outgoing port (and eventually also specify ip more restrictive)</li> </ul> </li> <li>Source IP: Specific IP -&gt; Select -&gt; Subnet<ul> <li>insert docker network ip (can be found in the docker application, network tab)</li> <li>Example: IP address: 172.18.0.0 and Subnet mask/Prefix length: 255.255.255.0</li> </ul> </li> <li>Action: Allow</li> </ul> </li> <li>Save and make sure it's above the deny rules</li> <li>If you want to skip the SSL Setup via Reverse Proxy you'll also need to allow access to the port you used to expose the container (e.g. 2000 in this example).<ul> <li>Ports: 2000</li> <li>Source: depends on how broad the access should be</li> <li>Action: Allow</li> </ul> </li> </ul>"},{"location":"install/synology/#7-additional-ssl-setup","title":"7. Additional SSL Setup","text":"<p>Easiest way is to do it via Reverse Proxy.</p> <ul> <li>Control Panel -&gt; Login Portal -&gt; Advanced -&gt; Reverse Proxy</li> <li>Create<ul> <li>insert name</li> <li>Source:<ul> <li>Protocol: HTTPS</li> <li>Hostname: URL if you access from outside, otherwise ip in network</li> <li>Port: The port you want to access, has to be a different one that the one in the docker-compose file</li> <li>HSTS can be enabled</li> </ul> </li> <li>Destination:<ul> <li>Protocol: HTTP</li> <li>Hostname: localhost</li> <li>Port: port in docker-compose file</li> </ul> </li> <li>Click on Custom Header and press Create -&gt; Websocket</li> <li>Save</li> </ul> </li> <li>Control Panel -&gt; Security -&gt; Firewall -&gt; Edit Rules -&gt; Create<ul> <li>Ports: Select form a list of built-in applications -&gt; Select -&gt; You find your Reverse Proxy, enable it</li> <li>Source IP: Depends, All allows access from outside, i use specific to only connect in my network</li> <li>Action: Allow</li> </ul> </li> <li>Save and make sure it's above the deny rules</li> </ul>"},{"location":"install/synology/#8-deprecated-guides","title":"8. Deprecated Guides","text":"<p>The following are older guides that may be useful if you are running older versions of DSM. </p> <ul> <li> <p>The following documentation was provided by  @therealschimmi in this issue discussion.</p> </li> <li> <p>There is also this  (word,  pdf) awesome and very detailed guide provided by @DiversityBug.</p> </li> </ul>"},{"location":"install/truenas_portainer/","title":"TrueNAS Portainer","text":"<p>Community Contributed</p> <p>This guide was contributed by the community and is neither officially supported, nor updated or tested.</p> <p>Tandoor 2 Compatibility</p> <p>This guide has not been verified/tested for Tandoor 2, which now integrates a nginx service inside the default docker container and exposes its service on port 80 instead of 8080.</p> <p>This guide is to assist those installing Tandoor Recipes on Truenas Core using Docker and or Portainer</p> <p>Docker install instructions adapted from PhasedLogix IT Services's guide. Portainer install instructions adopted from the Portainer Official Documentation. Tandoor installation on Portainer provided by users <code>Szeraax</code> and <code>TransatlanticFoe</code> on Discord (Thank you two!)</p>"},{"location":"install/truenas_portainer/#instructions","title":"Instructions","text":"<p>Basic guide to setup Docker and Portainer TrueNAS Core.</p>"},{"location":"install/truenas_portainer/#1-login-to-truenas-through-your-browser","title":"1. Login to TrueNAS through your browser","text":"<ul> <li>Go to the Virtual Machines Menu ![Screenshot of TrueNAS VM Menu[(https://d33wubrfki0l68.cloudfront.net/e5bc016268e41fadea77fd91a35c40d52280d221/c9daf/images/blog/truenasvmpage.png)</li> <li>Click Add to add a new virtual machine. You will want the following settings:     -Guest operating system: Linux     -Name: UBUDocker (or whatever you want it to be)     -System Clock: Local     -Boot method: UEFI     -Shutdown time: 90     -Start on boot enabled     -Enable VNC enabled </li> <li>Click next to dedicate resources to the VM (see below image of authors setup, you may need to change resources to fit your needs) </li> <li>Hit next to go to disk setup     -You want to create a new disk, here are the settings you should use     -Disk Type: AHCI     -Zvol location: tank/vm (Or wherever you have your VM memory located at)     -Size: Atleast 30 gigs  -Hit next to go to network interface (The defaults are fine but make sure you select the right network adapter) -Hit next to go to installation     -Navigate to your ubuntu ISO file (The original author and this author used Ubuntu Server. This OS uses less resources than some other OS's and can be ran Headless with either VNC or SSH access. You can use other OS's, but this guide was written with Ubuntu Server) -Hit next, then submit, you have made the virtual machine!     -Open the virtual machine then hit VNC to open ubuntu  -Once its up choose your language and go through the installer     -Once you are done with the setup we want to SSH into the ubuntu VM to setup docker     -Open powershell and type SSH \"user\"@(ip) (replace \"user\" with the user you setup in the OS installation)     -Enter your Password if requested     -Close the VNC Console     -Go back into the SSH console and get ready to type some commands. Type these commands in order:     <code>sudo apt update</code> <code>sudo apt install apt-transport-https ca-certificates curl software-properties-common</code> <code>y</code> (If prompted with a question)     <code>curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -</code> <code>sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu focal stable\"</code> <code>sudo apt update</code> <code>apt-cache policy docker-ce</code>     -To make it so you don\u2019t have to use sudo for every docker command run this command     <code>sudo usermod -aG docker ${USER}</code> <code>su - ${USER}</code></li> </ul>"},{"location":"install/truenas_portainer/#2-install-portainer","title":"2. Install Portainer","text":"<p>!!! Note: By default, Portainer Server will expose the UI over port 9443 and expose a TCP tunnel server over port 8000. The latter is optional and is only required if you plan to use the Edge compute features with Edge agents.</p> <p>-First, create the volume that Portainer Server will use to store its database: <code>docker volume create portainer_data</code> -Then, download and install the Portainer Server container: <code>docker run -d -p 8000:8000 -p 9443:9443 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:latest</code> -Portainer Server has now been installed. You can check to see whether the Portainer Server container has started by running <code>docker ps</code> -Now that the installation is complete, you can log into your Portainer Server instance by opening a web browser and going to:     <code>https://localhost:9443</code>     -Replace <code>localhost</code> with the relevant IP address or FQDN if needed, and adjust the port if you changed it earlier. -You will be presented with the initial setup page for Portainer Server. -Create your first user     -Your first user will be an administrator. The username defaults to admin but you can change it if you prefer. The password must be at least 12 characters long and meet the listed password requirements. -Connect Portainer to your environments.     -Once the admin user has been created, the \"Environment Wizard\" will automatically launch. The wizard will help get you started with Portainer.     -Select \"Get Started\" to use the Enviroment Portainer is running in </p>"},{"location":"install/truenas_portainer/#3-install-tandoor-recipes-via-portainer-web-editor","title":"3. Install Tandoor Recipes VIA Portainer Web Editor","text":"<p>-From the menu select Stacks, click Add stack, give the stack a descriptive name then select Web editor.  -Use the below code and input it into the Web Editor:</p> <pre><code>version: \"3\"\nservices:\n  db_recipes:\n    restart: always\n    image: postgres:16-alpine\n    volumes:\n      - ./postgresql:/var/lib/postgresql/data\n    env_file:\n      - stack.env\n\n  web_recipes:\n    image: vabene1111/recipes:latest\n    env_file:\n      - stack.env\n    volumes:\n      - staticfiles:/opt/recipes/staticfiles\n      # Do not make this a bind mount, see https://docs.tandoor.dev/install/docker/#volumes-vs-bind-mounts\n      - nginx_config:/opt/recipes/nginx/conf.d \n      - ./mediafiles:/opt/recipes/mediafiles\n    depends_on:\n      - db_recipes\n\n  nginx_recipes:\n    image: nginx:mainline-alpine\n    restart: always\n    ports:\n      - 12008:80\n    env_file:\n      - stack.env\n    depends_on:\n      - web_recipes\n    volumes:\n      # Do not make this a bind mount, see https://docs.tandoor.dev/install/docker/#volumes-vs-bind-mounts\n      - nginx_config:/etc/nginx/conf.d:ro\n      - staticfiles:/static\n      - ./mediafiles:/media\n\nvolumes:\n  nginx_config:\n  staticfiles:\n</code></pre> <p>-Download the .env template from HERE and load this file by pressing the \"Load Variables from .env File\" button: </p> <p>-You will need to change the following variables:     -<code>SECRET_KEY</code> needs to be replaced with a new key. This can be generated from websites like Djecrety     -<code>TIMEZONE</code> needs to be replaced with the appropriate code for your timezone. Accepted values can be found at TimezoneDB     -<code>POSTGRES_USER</code> and <code>POSTGRES_PASSWORD</code> needs to be replaced with your username and password from PostgreSQL !!!NOTE Do not sign in using social media. You need to sign up using Email and Password. -After those veriables are changed, you may press the <code>Deploy the Stack</code> button at the bottom of the page. This will create the needed containers to run Tandoor Recipes.</p>"},{"location":"install/truenas_portainer/#4-login-and-setup-your-new-server","title":"4. Login and Setup your new server!","text":"<ul> <li>You need to access your Tandoor Server through its Webpage: <code>https://localhost:xxxx</code> replacing <code>localhost</code> with the IP of the VM running Docker and <code>xxxx</code> with the port you chose in the Web Editor for <code>nginx_recipes</code> above. In this case, <code>12008</code>.  !!! While the containers are starting and doing whatever they need to do, you might still get HTTP errors e.g. 500 or 502. Just be patient and try again in a moment -You will now need to set up the Tandoor Server through the WebGUI.</li> </ul>"},{"location":"install/unraid/","title":"Unraid","text":"<p>Community Contributed</p> <p>This guide was contributed by the community and is neither officially supported, nor updated or tested.</p> <p>Tandoor 2 Compatibility</p> <p>This guide has not been verified/tested for Tandoor 2, which now integrates a nginx service inside the default docker container and exposes its service on port 80 instead of 8080.</p> <p>Unraid is an operating system that allows you to easily install and setup applications.</p> <p>Thanks to CorneliousJD this application can easily be installed using unraid. Please view Issue #184 for further details. There is also a discussion thread on the  unraid forum where he gives additional information.</p>"},{"location":"install/unraid/#installation","title":"Installation","text":""},{"location":"install/unraid/#install-community-applications","title":"Install Community Applications","text":"<p>Tandoor for unRAID is available via <code>Community Applications</code>. You will first need to install <code>Community Applications (CA)</code> by following the directions here: Unraid forums</p>"},{"location":"install/unraid/#locate-and-install-tandoor-recipes","title":"Locate and install Tandoor Recipes","text":"<p>After that, you can go to the \"Apps\" tab in unRAID and search for <code>Tandoor Recipes</code>, locate the correct container and install it.  </p>"},{"location":"install/unraid/#configure-settings","title":"Configure settings","text":"<p>The default settings should be fine for most users, just be sure to enter a secret key that is randomly generated. Then click <code>Apply</code>. </p>"},{"location":"install/unraid/#access-website","title":"Access website","text":"<p>After the container is installed, click on the <code>Tandoor Recipes</code> icon and click the WebUI button to launch the web user interface. Set the container to auto-start if you wish.  </p>"},{"location":"install/wsl/","title":"WSL","text":"<p>Community Contributed</p> <p>This guide was contributed by the community and is neither officially supported, nor updated or tested. Since I cannot test it myself, feedback and improvements are always very welcome.</p> <p>Tandoor 2 Compatibility</p> <p>This guide has not been verified/tested for Tandoor 2, which now integrates a nginx service inside the default docker container and exposes its service on port 80 instead of 8080.</p>"},{"location":"install/wsl/#ubuntu-installation-on-windows-wsl-and-docker-desktop","title":"Ubuntu Installation on Windows (WSL) and Docker Desktop","text":"<p>Install Docker from https://docs.docker.com/desktop/install/windows-install/ Be sure to select the Use WSL 2 instead of Hyper-V option on the configuration page when prompted</p> <p>Follow the instructions to install Tandoor on Docker. Tandoor installation instructions using Docker is gotten from https://docs.tandoor.dev/install/docker/</p> <p>You may get the error below if you are using Docker Desktop: /usr/bin/docker-credential-desktop.exe: Invalid argument</p> <p>This indicates that Docker Compose is not able to pull authentication credentials that are needed to pull recipe files.</p> <p>Run the command: export DOCKER_CONFIG=/non-existent-directory</p> <p>\"non-existent-directory\" could be an arbitrary directory of your choosing. It could be empty, we are just giving docker a file to point to. You can create a credentials file at a later date to add security to your application.</p> <p>After you run the command docker-compose up -d, you may encounter an error similar to the one below: fixing permissions on existing directory /var/lib/postgresql/data ... 2023-03-01T15:38:27.140501700Z chmod: /var/lib/postgresql/data: Operation not permitted</p> <p>This indicates that the postgresql user 'postgres' does not have the necessary permissions to  change the permissions of the /var/lib/postgresql/data directory. Note: This issue does not occuer in the Powershell terminal, so it might be easier to install Tandoor in powershell and continue development using WSL. Steps to fix this error: Since the permissions have to be changed within the docker container, we will need to create a file that runs as soon as the container starts up. This container will change the permissions of the /var/lib/postgresql/data directory before the db_recipes-1 container is started up. This container sets up the database to accept connections. Docker allows us to set up an entrypoint in the docker-compose.yml file. This is where we will set the commands to change the permissions of the postgres user. Steps to set up entry-point file: 1.  Create a new file \u2018docker-entrypoint.sh\u2019 in the same directory as your docker-compose.yml file. This will be a bash file. 2.  Add the following commands to the file a.  #!/bin/sh (This is called a shebang. It tells the OS the shell to use which is the sh shell in this case) b.  chmod 777 /var/lib/postgresql/data (Gives read, write and execute permissions on the directory to all users, you may change these permissions as you wish) c.  exec \u201c@\u201d (Runs the script with the commands above)</p> <p>Your folder structure should look like this with docker-compose.yml and docker-entrypoint.sh in the same directory: </p> <p>The docker-entrypoint.sh file should look like this: </p> <ol> <li>Open the docker-compose.yml file</li> <li>Add an entrypoint configuration to the db_recipes service entrypoint:</li> <li> <p>docker-entrypoint.sh This command makes sure that the docker-entrypoint.sh file is run first before the db_recipes services is started. Using this, we set the database user permission before they are needed, so it gets rid of the error. Your docker-compose.yml file should look like this: </p> </li> <li> <p>Run docker-compose up -d, all the containers should run!</p> </li> </ol>"},{"location":"system/backup/","title":"Backup","text":"<p>There is currently no \"good\" way of backing up your data implemented in the application itself. This mean that you will be responsible for backing up your data.</p> <p>It is planned to add a \"real\" backup feature similar to applications like homeassistant where a snapshot can be downloaded and restored through the web interface.</p> <p>Warning</p> <p>When developing a new backup strategy, make sure to also test the restore process!</p>"},{"location":"system/backup/#database","title":"Database","text":"<p>Please use any standard way of backing up your database. For most systems this can be achieved by using a dump command that will create an SQL file with all the required data.</p> <p>Please refer to your Database System documentation.</p> <p>I personally use a little script that I have created to automatically pull SQL dumps from a postgresql database. It is neither well tested nor documented so use at your own risk. I would recommend using it only as a starting place for your own backup strategy.</p>"},{"location":"system/backup/#mediafiles","title":"Mediafiles","text":"<p>The only Data this application stores apart from the database are the media files (e.g. images) used in your recipes.</p> <p>They can be found in the mediafiles mounted directory (depending on your installation).</p> <p>To create a backup of those files simply copy them elsewhere. Do it the other way around for restoring.</p> <p>The filenames consist of <code>&lt;random uuid4&gt;_&lt;recipe_id&gt;</code>. In case you screw up really badly this can help restore data.</p>"},{"location":"system/backup/#manual-backup-from-docker-build","title":"Manual backup from docker build","text":"<p>The standard docker build of tandoor uses postgresql as the back end database. This can be backed up using a function called \"dumpall\". This generates a .SQL file containing a list of commands for a postgresql server to use to rebuild your database. You will also need to back up the media files separately.</p> <p>Making a full copy of the docker directory can work as a back up, but only if you know you will be using the same hardware, os, and postgresql version upon restore. If not, then the different version of postgresql won't be compatible with the existing tables. You can back up from docker even when the tandoor container is failing, so long as the postgresql database has started successfully. When using this backup method, ensure that your recipes have imported successfully. One user reported only the titles and images importing on first try, requiring a second run of the import command.</p> <p>the following commands assume that your docker-compose files are in a folder called \"docker\". replace \"docker_db_recipes_1\" with the name of your db container. The commands also assume you use a backup name of pgdump.sql. It's a good idea to include a date in this filename, so that successive backups do not get deleted. To back up: <pre><code>sudo docker exec -t docker_db_recipes_1 pg_dumpall -U djangouser &gt; pgdump.sql\n</code></pre></p> <p>To restore: <pre><code>cat pgdump.sql | sudo docker exec -i docker_db_recipes_1 psql postgres -U djangouser\n</code></pre> This connects to the postgres table instead of the actual djangodb table, as the import function needs to delete the table, which can't be dropped off you're connected to it.</p>"},{"location":"system/backup/#backup-using-export-and-import","title":"Backup using export and import","text":"<p>You can now export recipes from Tandoor using the export function. This method requires a working web interface. 1. Click on a recipe 2. Click on the three meatballs then export 3. Select the all recipes toggle and then export. This should download a zip file.</p> <p>Import: Go to Import &gt; from app &gt; tandoor and select the zip file you want to import from.</p>"},{"location":"system/backup/#backing-up-using-the-pgbackup-container","title":"Backing up using the pgbackup container","text":"<p>You can add pgbackup to manage the scheduling and automatic backup of your postgres database. Modify the below to match your environment and add it to your <code>docker-compose.yml</code></p> <p><pre><code>  pgbackup:\n    container_name: pgbackup\n    env_file:\n      - ./.env\n    environment:\n      BACKUP_KEEP_DAYS: \"8\"\n      BACKUP_KEEP_MONTHS: \"6\"\n      BACKUP_KEEP_WEEKS: \"4\"\n      POSTGRES_EXTRA_OPTS: -Z6 --schema=public --blobs\n      SCHEDULE: '@daily'\n    # Note: the tag must match the version of postgres you are using\n    image: prodrigestivill/postgres-backup-local:15\n    restart: unless-stopped\n    volumes:\n      - backups/postgres:/backups\n</code></pre> You can manually initiate a backup by running <code>docker exec -it pgbackup ./backup.sh</code></p>"},{"location":"system/configuration/","title":"Configuration","text":"<p>This page describes all configuration options for the application server. All settings must be configured in the environment of the application server, usually by adding them to the <code>.env</code> file.</p>"},{"location":"system/configuration/#required-settings","title":"Required Settings","text":"<p>The following settings need to be set appropriately for your installation. They are included in the default <code>env.template</code>.</p>"},{"location":"system/configuration/#secret-key","title":"Secret Key","text":"<p>Random secret key (at least 50 characters), use for example <code>base64 /dev/urandom | head -c50</code> to generate one. It is used internally by django for various signing/cryptographic operations and should be kept secret. See Django Docs</p> <pre><code>SECRET_KEY=#$tp%v6*(*ba01wcz(ip(i5vfz8z$f%qdio&amp;q@anr1#$=%(m4c\n</code></pre> <p>Alternatively you can point to a file containing just the secret key value. If using containers make sure the file is persistent and available inside the container.</p> <pre><code>SECRET_KEY_FILE=/path/to/file.txt\n\n// contents of file\n#$tp%v6*(*ba01wcz(ip(i5vfz8z$f%qdio&amp;q@anr1#$=%(m4c\n</code></pre>"},{"location":"system/configuration/#allowed-hosts","title":"Allowed Hosts","text":"<p>default <code>*</code> - options: <code>recipes.mydomain.com,cooking.mydomain.com,...</code> (comma seperated domain/ip list)</p> <p>Security setting to prevent HTTP Host Header Attacks, see Django docs. Some proxies require <code>*</code> (default) but it should be set to the actual host(s).</p> <pre><code>ALLOWED_HOSTS=recipes.mydomain.com\n</code></pre>"},{"location":"system/configuration/#database","title":"Database","text":"<p>Multiple parameters are required to configure the database. Note: You can setup parameters for a test database by defining all of the parameters preceded by <code>TEST_</code> e.g. TEST_DB_ENGINE=</p> Var Options Description DB_ENGINE django.db.backends.postgresql (default) django.db.backends.sqlite3 Type of database connection. Production should always use postgresql. POSTGRES_HOST any Used to connect to database server. Use container name in docker setup. POSTGRES_DB any Name of database. POSTGRES_PORT 1-65535 Port of database, Postgresql default <code>5432</code> POSTGRES_USER any Username for database connection. POSTGRES_PASSWORD any Password for database connection."},{"location":"system/configuration/#password-file","title":"Password file","text":"<p>default <code>None</code> - options: file path</p> <p>Path to file containing the database password. Overrides <code>POSTGRES_PASSWORD</code>. Only applied when using Docker (or other setups running <code>boot.sh</code>)</p> <pre><code>POSTGRES_PASSWORD_FILE=\n</code></pre>"},{"location":"system/configuration/#connection-string","title":"Connection String","text":"<p>default <code>None</code> - options: according to database specifications</p> <p>Instead of configuring the connection using multiple individual environment parameters, you can use a connection string. The connection string will override all other database settings.</p> <pre><code>DATABASE_URL = engine://username:password@host:port/dbname\n</code></pre>"},{"location":"system/configuration/#connection-options","title":"Connection Options","text":"<p>default <code>{}</code> - options: according to database specifications</p> <p>Additional connection options can be set as shown in the example below.</p> <pre><code>DB_OPTIONS={\"sslmode\":\"require\"}\n</code></pre>"},{"location":"system/configuration/#optional-settings","title":"Optional Settings","text":"<p>All optional settings are, as their name says, optional and can be ignored safely. If you want to know more about what you can do with them take a look through this page. I recommend using the categories to guide yourself.</p>"},{"location":"system/configuration/#server-configuration","title":"Server configuration","text":"<p>Configuration options for serving related services.</p>"},{"location":"system/configuration/#port","title":"Port","text":"<p>default <code>80</code> - options: <code>1-65535</code></p> <p>Warning</p> <p>Changed in version 2.3 to no longer configure the port of gunicorn but the port of the internal nginx</p> <p>Port where Tandoor exposes its internal web server.</p> <pre><code>TANDOOR_PORT=80\n</code></pre>"},{"location":"system/configuration/#url-path","title":"URL Path","text":"<p>default <code>None</code> - options: <code>/custom/url/base/path</code></p> <p>If base URL is something other than just / (you are serving a subfolder in your proxy for instance http://recipe_app/recipes/) Be sure to not have a trailing slash: e.g. '/recipes' instead of '/recipes/'</p> <pre><code>SCRIPT_NAME=/recipes\n</code></pre>"},{"location":"system/configuration/#static-url","title":"Static URL","text":"<p>default <code>/static/</code> - options: <code>/any/url/path/</code>, <code>https://any.domain.name/and/url/path</code></p> <p>If staticfiles are stored or served from a different location uncomment and change accordingly. This can either be a relative path from the applications base path or the url of an external host.</p> <p>Info</p> <ul> <li>MUST END IN <code>/</code></li> <li>This is not required if you are just using a subfolder</li> </ul> <pre><code>STATIC_URL=/static/\n</code></pre>"},{"location":"system/configuration/#static-root","title":"Static root","text":"<p>default <code>&lt;basedir&gt;/staticfiles</code> - options <code>/some/other/media/path</code>.</p> <p>Where staticfiles should be stored on disk. The default location is a <code>staticfiles</code> subfolder at the root of the application directory.</p>"},{"location":"system/configuration/#media-url","title":"Media URL","text":"<p>default <code>/static/</code> - options: <code>/any/url/path/</code>, <code>https://any.domain.name/and/url/path</code></p> <p>If mediafiles are stored at a different location uncomment and change accordingly. This can either be a relative path from the applications base path or the url of an external host</p> <p>Info</p> <ul> <li>MUST END IN <code>/</code></li> <li>This is not required if you are just using a subfolder</li> <li>This is not required if using S3/object storage</li> </ul> <pre><code>MEDIA_URL=/media/\n</code></pre>"},{"location":"system/configuration/#media-root","title":"Media root","text":"<p>default <code>&lt;basedir&gt;/mediafiles</code> - options <code>/some/other/media/path</code>.</p> <p>Where mediafiles should be stored on disk. The default location is a <code>mediafiles</code> subfolder at the root of the application directory.</p>"},{"location":"system/configuration/#local-storage-paths","title":"Local Storage Paths","text":"<p>default <code>&lt;MEDIA_ROOT&gt;/local_provider</code> - options: <code>/path/to/local/recipes,/another/path</code> (comma separated list)</p> <p>Allowed paths for the local provider. The local provider will only serve files that are within these paths.</p> <pre><code>LOCAL_STORAGE_PATHS=/path/to/local/recipes\n</code></pre>"},{"location":"system/configuration/#gunicorn-workers","title":"Gunicorn Workers","text":"<p>default <code>3</code> - options <code>1-X</code></p> <p>Set the number of gunicorn workers to start when starting using <code>boot.sh</code> (all container installations). The default is likely appropriate for most installations. See Gunicorn docs for recommended settings.</p> <pre><code>GUNICORN_WORKERS=3\n</code></pre>"},{"location":"system/configuration/#gunicorn-threads","title":"Gunicorn Threads","text":"<p>default <code>2</code> - options <code>1-X</code></p> <p>Set the number of gunicorn threads to start when starting using <code>boot.sh</code> (all container installations). The default is likely appropriate for most installations. See Gunicorn docs for recommended settings.</p> <pre><code>GUNICORN_THREADS=2\n</code></pre>"},{"location":"system/configuration/#gunicorn-timeout","title":"Gunicorn Timeout","text":"<p>default <code>30</code> - options <code>1-X</code></p> <p>Set the timeout in seconds of gunicorn when starting using <code>boot.sh</code> (all container installations). The default is likely appropriate for most installations. However, if you are using a LLM which high response times gunicornmight time out during the wait until the LLM finished, in such cases you might want to increase the timeout. See Gunicorn docs for default settings.</p> <pre><code>GUNICORN_TIMEOUT=30\n</code></pre>"},{"location":"system/configuration/#gunicorn-media","title":"Gunicorn Media","text":"<p>default <code>0</code> - options <code>0</code>, <code>1</code></p> <p>Serve media files directly using gunicorn. Basically everyone recommends not doing this. Please use any of the examples provided that include an additional nxginx container to handle media file serving. If you know what you are doing turn this on (<code>1</code>) to serve media files using djangos serve() method.</p> <pre><code>GUNICORN_MEDIA=0\n</code></pre>"},{"location":"system/configuration/#csrf-trusted-origins","title":"CSRF Trusted Origins","text":"<p>default <code>[]</code> - options: [list,of,trusted,origins]</p> <p>Allows setting origins to allow for unsafe requests. See Django docs</p> <pre><code>CSRF_TRUSTED_ORIGINS = []\n</code></pre>"},{"location":"system/configuration/#cors-origins","title":"Cors origins","text":"<p>default <code>False</code> - options: <code>False</code>, <code>True</code></p> <p>By default, cross-origin resource sharing is disabled. Enabling this will allow access to your resources from other domains. Please read the docs carefully before enabling this.</p> <pre><code>CORS_ALLOW_ALL_ORIGINS = True\n</code></pre>"},{"location":"system/configuration/#session-cookies","title":"Session Cookies","text":"<p>Django session cookie settings. Can be changed to allow a single django application to authenticate several applications when running under the same database.</p> <pre><code>SESSION_COOKIE_DOMAIN=.example.com\nSESSION_COOKIE_NAME=sessionid # use this only to not interfere with non unified django applications under the same top level domain\n</code></pre>"},{"location":"system/configuration/#features","title":"Features","text":"<p>Some features can be enabled/disabled on a server level because they might change the user experience significantly, they might be unstable/beta or they have performance/security implications.</p>"},{"location":"system/configuration/#captcha","title":"Captcha","text":"<p>If you allow signing up to your instance you might want to use a captcha to prevent spam. Tandoor supports HCAPTCHA which is supposed to be a privacy-friendly captcha provider. See HCAPTCHA website for more information and to acquire your sitekey and secret.</p> <pre><code>HCAPTCHA_SITEKEY=\nHCAPTCHA_SECRET=\n</code></pre>"},{"location":"system/configuration/#metrics","title":"Metrics","text":"<p>Enable serving of prometheus metrics under the <code>/metrics</code> path</p> <p>Danger</p> <p>The view is not secured (as per the prometheus default way) so make sure to secure it through your web server.</p> <pre><code>ENABLE_METRICS=0\n</code></pre>"},{"location":"system/configuration/#tree-sorting","title":"Tree Sorting","text":"<p>default <code>0</code> - options <code>0</code>, <code>1</code></p> <p>By default SORT_TREE_BY_NAME is disabled this will store all Keywords and Food in the order they are created. Enabling this setting makes saving new keywords and foods very slow, which doesn't matter in most usecases. However, when doing large imports of recipes that will create new objects, can increase total run time by 10-15x Keywords and Food can be manually sorted by name in Admin This value can also be temporarily changed in Admin, it will revert the next time the application is started</p> <p>Info</p> <p>Disabling tree sorting is a temporary fix, in the future we might find a better implementation to allow tree sorting without the large performance impacts.</p> <pre><code>SORT_TREE_BY_NAME=0\n</code></pre>"},{"location":"system/configuration/#pdf-export","title":"PDF Export","text":"<p>default <code>0</code> - options <code>0</code>, <code>1</code></p> <p>Exporting PDF's is a community contributed feature to export recipes as PDF files. This requires the server to download a chromium binary and is generally implemented only rudimentary and somewhat slow depending on your server device.</p> <p>See Export feature docs for additional information.</p> <pre><code>ENABLE_PDF_EXPORT=1\n</code></pre>"},{"location":"system/configuration/#legal-urls","title":"Legal URLS","text":"<p>Depending on your jurisdiction you might need to provide any of the following URLs for your instance.</p> <pre><code>TERMS_URL=\nPRIVACY_URL=\nIMPRINT_URL=\n</code></pre>"},{"location":"system/configuration/#rate-limits","title":"Rate Limits","text":"<p>There are some rate limits that can be configured.</p> <ul> <li>RATELIMIT_URL_IMPORT_REQUESTS: limit the number of external URL import requests. Useful to prevent your server from being abused for malicious requests.</li> </ul>"},{"location":"system/configuration/#authentication","title":"Authentication","text":"<p>All configurable variables regarding authentication. Please also visit the dedicated docs page for more information.</p>"},{"location":"system/configuration/#default-permissions","title":"Default Permissions","text":"<p>Configures if a newly created user (from social auth or public signup) should automatically join into the given space and default group.</p> <p>This setting is targeted at private, single space instances that typically have a custom authentication system managing access to the data.</p> <p>Danger</p> <p>With public signup enabled this will give everyone access to the data in the given space</p> <p>Warning</p> <p>This feature might be deprecated in favor of a space join and public viewing system in the future</p> <p>default <code>0</code> (disabled) - options <code>0</code>, <code>1-X</code> (space id)</p> <p>When enabled will join user into space and apply group configured in <code>SOCIAL_DEFAULT_GROUP</code>.</p> <pre><code>SOCIAL_DEFAULT_ACCESS = 1\n</code></pre> <p>default <code>guest</code> - options <code>guest</code>, <code>user</code>, <code>admin</code></p> <pre><code>SOCIAL_DEFAULT_GROUP=guest\n</code></pre>"},{"location":"system/configuration/#enable-signup","title":"Enable Signup","text":"<p>default <code>0</code> - options <code>0</code>, <code>1</code></p> <p>Allow everyone to create local accounts on your application instance (without an invite link) You might want to setup HCAPTCHA to prevent bots from creating accounts/spam.</p> <p>Info</p> <p>Social accounts will always be able to sign up, if providers are configured</p> <pre><code>ENABLE_SIGNUP=0\n</code></pre>"},{"location":"system/configuration/#social-auth","title":"Social Auth","text":"<p>Allows you to set up external OAuth providers.</p> <pre><code>SOCIAL_PROVIDERS = allauth.socialaccount.providers.github, allauth.socialaccount.providers.nextcloud,\n</code></pre> <p>default <code>0</code> - options <code>0</code>, <code>1</code></p> <p>If you enable Social Auth, you can also disable the display of the regular login form by setting: <pre><code>HIDE_LOGIN_FORM=1\n</code></pre></p> <p>If you chose to enable this, the login page will only display the button to login with the configured social providers.</p> <p>To force the display of the login form (so you can login with a local admin account), you can add <code>form=1</code> as a parameter to the login URL - for example: <pre><code>http://localhost/accounts/login/?form=1\n</code></pre></p>"},{"location":"system/configuration/#remote-user-auth","title":"Remote User Auth","text":"<p>default <code>0</code> - options <code>0</code>, <code>1</code></p> <p>Allow authentication via the REMOTE-USER header (can be used for e.g. authelia).</p> <p>Danger</p> <p>Leave off if you don't know what you are doing! Enabling this without proper configuration will enable anybody to login with any username!</p> <pre><code>REMOTE_USER_AUTH=0\n</code></pre>"},{"location":"system/configuration/#ldap","title":"LDAP","text":"<p>LDAP based authentication is disabled by default. You can enable it by setting <code>LDAP_AUTH</code> to <code>1</code> and configuring the other settings accordingly. Please remove/comment settings you do not need for your setup.</p> <pre><code>LDAP_AUTH=\nAUTH_LDAP_SERVER_URI=\nAUTH_LDAP_BIND_DN=\nAUTH_LDAP_BIND_PASSWORD=\nAUTH_LDAP_USER_SEARCH_BASE_DN=\nAUTH_LDAP_TLS_CACERTFILE=\nAUTH_LDAP_START_TLS=\n</code></pre> <p>Instead of passing the LDAP password directly through the environment variable <code>AUTH_LDAP_BIND_PASSWORD</code>, you can set the password in a file and set the environment variable <code>AUTH_LDAP_BIND_PASSWORD_FILE</code> to the path of the file containing the ldap secret.</p> <pre><code>AUTH_LDAP_BIND_PASSWORD_FILE=/run/secrets/ldap_password.txt\n</code></pre>"},{"location":"system/configuration/#external-services","title":"External Services","text":""},{"location":"system/configuration/#email","title":"Email","text":"<p>Email Settings, see Django docs for additional information. Required for email confirmation and password reset (automatically activates if host is set).</p> <pre><code>EMAIL_HOST=\nEMAIL_PORT=\nEMAIL_HOST_USER=\nEMAIL_HOST_PASSWORD=\nEMAIL_USE_TLS=0\nEMAIL_USE_SSL=0\n# email sender address (default 'webmaster@localhost')\nDEFAULT_FROM_EMAIL=\n</code></pre> <p>Instead of passing the email password directly through the environment variable <code>EMAIL_HOST_PASSWORD</code>, you can set the password in a file and set the environment variable <code>EMAIL_HOST_PASSWORD_FILE</code> to the path of the file containing the ldap secret.</p> <pre><code>EMAIL_HOST_PASSWORD_FILE=/run/secrets/email_password.txt\n</code></pre> <p>Optional settings (only copy the ones you need)</p> <pre><code># prefix used for account related emails (default \"[Tandoor Recipes] \")\nACCOUNT_EMAIL_SUBJECT_PREFIX=\n</code></pre>"},{"location":"system/configuration/#s3-object-storage","title":"S3 Object storage","text":"<p>If you want to store your users media files using an external storage provider supporting the S3 API's (Like S3, MinIO, ...) configure the following settings accordingly. As long as <code>S3_ACCESS_KEY</code> is not set, all object storage related settings are disabled.</p> <p>See also Django Storages Docs for additional information.</p> <p>Info</p> <p>Settings are only named S3 but apply to all compatible object storage providers.</p> <p>Required settings</p> <pre><code>S3_ACCESS_KEY=\nS3_SECRET_ACCESS_KEY=\nS3_BUCKET_NAME=\n</code></pre> <p>Alternatively you can point to a file containing the S3_SECRET_ACCESS_KEY value. If using containers make sure the file is persistent and available inside the container.</p> <pre><code>S3_SECRET_ACCESS_KEY_FILE=/path/to/file.txt\n</code></pre> <p>Optional settings (only copy the ones you need)</p> <pre><code>S3_REGION_NAME= # default none, set your region might be required\nS3_QUERYSTRING_AUTH=1 # default true, set to 0 to serve media from a public bucket without signed urls\nS3_QUERYSTRING_EXPIRE=3600 # number of seconds querystring are valid for\nS3_ENDPOINT_URL= # when using a custom endpoint like minio\nS3_CUSTOM_DOMAIN= # when using a CDN/proxy to S3 (see https://github.com/TandoorRecipes/recipes/issues/1943)\n</code></pre>"},{"location":"system/configuration/#ai-integration","title":"AI Integration","text":"<p>Most AI features are configured through the AI Provider settings in the Tandoor web interface. Some defaults can be set for new spaces on your instance.</p> <p>Enables AI features for spaces by default <pre><code>SPACE_AI_ENABLED=1\n</code></pre></p> <p>Sets the monthly default credit limit for AI usage <pre><code>SPACE_AI_CREDITS_MONTHLY=100\n</code></pre></p> <p>Ratelimit for AI API <pre><code>AI_RATELIMIT=60/hour\n</code></pre></p>"},{"location":"system/configuration/#fdc-api","title":"FDC Api","text":"<p>The FDC Api is used to automatically load nutrition information from the FDC Nutrition Database. The default <code>DEMO_KEY</code> is limited to 30 requests / hour or 50 requests / day. If you want to do many requests to the FDC API you need to get a (free) API key here.</p> <pre><code>FDC_API_KEY=DEMO_KEY\n</code></pre>"},{"location":"system/configuration/#connectors","title":"Connectors","text":"<ul> <li><code>DISABLE_EXTERNAL_CONNECTORS</code> is a global switch to disable External Connectors entirely.</li> <li><code>EXTERNAL_CONNECTORS_QUEUE_SIZE</code> is the amount of changes that are kept in memory if the worker cannot keep up.</li> </ul> <p>(External) Connectors are used to sync the status from Tandoor to other services. More info can be found here.</p> <pre><code>DISABLE_EXTERNAL_CONNECTORS=0  # Default 0 (false), set to 1 (true) to disable connectors\nEXTERNAL_CONNECTORS_QUEUE_SIZE=100  # Defaults to 100, set to any number &gt;1\n</code></pre>"},{"location":"system/configuration/#debuggingdevelopment-settings","title":"Debugging/Development settings","text":"<p>Warning</p> <p>These settings should not be left on in production as they might provide additional attack surfaces and information to adversaries.</p>"},{"location":"system/configuration/#debug","title":"Debug","text":"<p>default <code>0</code> - options: <code>0</code>, <code>1</code></p> <p>Info</p> <p>Please enable this before posting logs anywhere to ask for help.</p> <p>Setting to <code>1</code> enables several django debug features and additional logs (see docs).</p> <pre><code>DEBUG=0\n</code></pre>"},{"location":"system/configuration/#debug-toolbar","title":"Debug Toolbar","text":"<p>default <code>0</code> - options: <code>0</code>, <code>1</code></p> <p>Set to <code>1</code> to enable django debug toolbar middleware. Toolbar only shows if <code>DEBUG=1</code> is set and the requesting IP is in <code>INTERNAL_IPS</code>. See Django Debug Toolbar Docs.</p> <pre><code>DEBUG_TOOLBAR=0\n</code></pre>"},{"location":"system/configuration/#sql-debug","title":"SQL Debug","text":"<p>default <code>0</code> - options: <code>0</code>, <code>1</code></p> <p>Set to <code>1</code> to enable additional query output on the search page.</p> <pre><code>SQL_DEBUG=0\n</code></pre>"},{"location":"system/configuration/#application-log-level","title":"Application Log Level","text":"<p>default <code>WARNING</code> - options: see Django Docs</p> <p>Increase or decrease the logging done by application. Please set to <code>DEBUG</code> when making a bug report.</p> <pre><code> LOG_LEVEL=\"DEBUG\"\n</code></pre>"},{"location":"system/configuration/#gunicorn-log-level","title":"Gunicorn Log Level","text":"<p>default <code>info</code> - options: see Gunicorn Docs</p> <p>Increase or decrease the logging done by gunicorn (the python wsgi application).</p> <pre><code> GUNICORN_LOG_LEVEL=\"debug\"\n</code></pre>"},{"location":"system/configuration/#default-user-preferences","title":"Default User Preferences","text":"<p>Having default user preferences is nice so that users signing up to your instance already have the settings you deem appropriate.</p>"},{"location":"system/configuration/#fractions","title":"Fractions","text":"<p>default <code>0</code> - options: <code>0</code>,<code>1</code></p> <p>The default value for the user preference 'fractions' (showing amounts as decimals or fractions).</p> <pre><code>FRACTION_PREF_DEFAULT=0\n</code></pre>"},{"location":"system/configuration/#comments","title":"Comments","text":"<p>default <code>1</code> - options: <code>0</code>,<code>1</code></p> <p>The default value for the user preference 'comments' (enable/disable commenting system)</p> <pre><code>COMMENT_PREF_DEFAULT=1\n</code></pre>"},{"location":"system/configuration/#sticky-navigation","title":"Sticky Navigation","text":"<p>default <code>1</code> - options: <code>0</code>,<code>1</code></p> <p>The default value for the user preference 'sticky navigation' (always show navbar on top or hide when scrolling)</p> <pre><code>STICKY_NAV_PREF_DEFAULT=1\n</code></pre>"},{"location":"system/configuration/#max-owned-spaces","title":"Max owned spaces","text":"<p>default <code>100</code> - options: <code>0-X</code></p> <p>The default for the number of spaces a user can own. By setting to 0 space creation for users will be disabled. Superusers can always bypass this limit.</p> <pre><code>MAX_OWNED_SPACES_PREF_DEFAULT=100\n</code></pre>"},{"location":"system/configuration/#cosmetic-preferences","title":"Cosmetic / Preferences","text":""},{"location":"system/configuration/#timezone","title":"Timezone","text":"<p>default <code>Europe/Berlin</code> - options: see timezone DB</p> <p>Default timezone to use for database connections (see Django docs). Usually everything is converted to the users timezone so this setting doesn't really need to be correct.</p> <pre><code>TZ=Europe/Berlin\n</code></pre>"},{"location":"system/configuration/#default-theme","title":"Default Theme","text":"<p>default <code>0</code> - options <code>1-X</code> (space ID)</p> <p>Tandoors appearance can be changed on a user and space level but unauthenticated users always see the tandoor default style. With this setting you can specify the ID of a space of which the appearance settings should be applied if a user is not logged in.</p> <pre><code>UNAUTHENTICATED_THEME_FROM_SPACE=\n</code></pre>"},{"location":"system/configuration/#force-theme","title":"Force Theme","text":"<p>default <code>0</code> - options <code>1-X</code> (space ID)</p> <p>Similar to the Default theme but forces the theme upon all users (authenticated/unauthenticated) and all spaces</p> <pre><code>FORCE_THEME_FROM_SPACE=\n</code></pre>"},{"location":"system/configuration/#rate-limiting-performance","title":"Rate Limiting / Performance","text":""},{"location":"system/configuration/#shopping-auto-sync","title":"Shopping auto sync","text":"<p>default <code>5</code> - options: <code>1-XXX</code></p> <p>Users can set an amount of time after which the shopping list is automatically refreshed. This is the minimum interval users can set. Setting this to a low value will allow users to automatically refresh very frequently which might cause high load on the server. (Technically they can obviously refresh as often as they want with their own scripts)</p> <pre><code>SHOPPING_MIN_AUTOSYNC_INTERVAL=5\n</code></pre>"},{"location":"system/configuration/#api-url-import-throttle","title":"API Url Import throttle","text":"<p>default <code>60/hour</code> - options: <code>x/hour</code>, <code>x/day</code>, <code>x/minute</code>, <code>x/second</code></p> <p>Limits how many recipes a user can import per hour. A rate limit is recommended to prevent users from abusing your server for (DDoS) relay attacks and to prevent external service providers from blocking your server for too many request.</p> <pre><code>DRF_THROTTLE_RECIPE_URL_IMPORT=60/hour\n</code></pre>"},{"location":"system/configuration/#default-space-limits","title":"Default Space Limits","text":"<p>You might want to limit how many resources a user might create. The following settings apply automatically to newly created spaces. These defaults can be changed in the admin view after a space has been created.</p> <p>If unset, all settings default to unlimited/enabled</p> <pre><code>SPACE_DEFAULT_MAX_RECIPES=0 # 0=unlimited recipes\nSPACE_DEFAULT_MAX_USERS=0 # 0=unlimited users per space\nSPACE_DEFAULT_MAX_FILES=0 # Maximum file storage for space in MB. 0 for unlimited, -1 to disable file upload.\nSPACE_DEFAULT_ALLOW_SHARING=1 # Allow users to share recipes with public links\n</code></pre>"},{"location":"system/configuration/#export-file-caching","title":"Export file caching","text":"<p>default <code>600</code> - options <code>1-X</code></p> <p>Recipe exports are cached for a certain time (in seconds) by default, adjust time if needed <pre><code>EXPORT_FILE_CACHE_DURATION=600\n</code></pre></p>"},{"location":"system/migration_sqlite-postgres/","title":"How to migrate from sqlite3 database to postgresql","text":"<p>This migration was written while using the unraid template (docker) for TandoorRecipes, version 1.3.0. While some commands are unraid specific, it should in general work for any setup.</p> <ol> <li> <p>Make a backup of your <code>/mnt/user/appdata/recipes</code> dir.</p> </li> <li> <p>Without changing any settings, get a shell into the TandoorRecipes docker through the Web-UI or by running <code>docker exec -it TandoorRecipes /bin/sh</code> <pre><code>cd /opt/recipes\n./venv/bin/python manage.py export -a &gt; /data/dump.json\n</code></pre></p> </li> <li> <p>Create a Postgresql database (With a new user &amp; database for recipes)</p> </li> </ol> <p>I used the <code>postgresql14</code> template.</p> <pre><code>psql -U postgres\npostgres=# create database tandoor;\npostgres=# create user tandoor with encrypted password 'yoursupersecretpassworddontusethisone';\npostgres=# grant all privileges on database tandoor to tandoor;\n</code></pre> <ol> <li> <p>Now its time to change some enviourment variables in TandoorRecipes template: <pre><code>DB_ENGINE=django.db.backends.postgresql  # Database Engine, previous value: `django.db.backends.sqlite3`\nPOSTGRES_HOST=&lt;Your unraid host ip&gt;  # PostgreSQL Host\nPOSTGRES_PORT=5432  # PostgreSQL Host\nPOSTGRES_USER=tandoor  # PostgreSQL User\nPOSTGRES_PASSWORD=yoursupersecretpassworddyoudidntcopy  # PostgreSQL Password\nPOSTGRES_DB=tandoor  # Database, previous value: `/data/recipes.db`\n</code></pre></p> </li> <li> <p>Save it, and start the container once.</p> </li> </ol> <p>It will perform all database migrations once for the postgresql database.</p> <ol> <li> <p>Get a shell into the docker through the WEB-UI or by running <code>docker exec -it TandoorRecipes /bin/sh</code> <pre><code>cd /opt/recipes\n./venv/bin/python manage.py import /data/dump.json\n</code></pre></p> </li> <li> <p>Enjoy your new fuzzy search options and SLIGHTLY performance increase!</p> </li> </ol>"},{"location":"system/permissions/","title":"Permission System","text":"<p>WIP</p> <p>This application was developed for private use in a trusted environment. Due to popular demand a basic permission system has been added.  It does its job protecting the most critical parts of the application, but it is not yet recommended to  give accounts to completely untrusted users. Work is done to improve the permission system, but it's not yet fully done and tested.</p>"},{"location":"system/permissions/#permission-levels","title":"Permission levels","text":"<p>The following table roughly defines the capabilities of each role</p> Group Capabilities logged in user Can do almost nothing without a group. guest - Search and view recipes- write comments - change user settings (e.g. language, theme, password) user Can do basically everything except for what admins can do admin - Create, edit and delete external storage- Create, edit and delete synced paths django superuser Ignores all permission checks and can access admin interface"},{"location":"system/permissions/#creating-user-accounts","title":"Creating User accounts","text":"<p>Warning</p> <p>Users without groups cannot do anything. Make sure to assign them a group!</p> <p>You can either create new users through the admin interface or by sending them invite links.</p> <p>Invite links can be generated on the System page. If you specify a username during the creation of the link  the person using it won't be able to change that name.</p>"},{"location":"system/permissions/#managing-permissions","title":"Managing Permissions","text":"<p>Management of permissions can currently only be achieved through the django admin interface.</p> <p>Warning</p> <p>Please do not rename the groups as this breaks the permission system.</p>"},{"location":"system/updating/","title":"Updating","text":"<p>The Updating process depends on your chosen method of installation</p> <p>While intermediate updates can be skipped when updating please make sure to read the release notes in case some special action is required to update.</p>"},{"location":"system/updating/#docker","title":"Docker","text":"<p>For all setups using Docker the updating process look something like this</p> <ol> <li>Before updating it is recommended to create a backup!</li> <li>Stop the container using <code>docker compose down</code></li> <li>Pull the latest image using <code>docker compose pull</code></li> <li>Start the container again using <code>docker compose up -d</code></li> </ol>"},{"location":"system/updating/#manual","title":"Manual","text":"<p>For all setups using a manual installation updates usually involve downloading the latest source code from GitHub. After that make sure to run:</p> <ol> <li><code>pip install -r requirements.txt</code></li> <li><code>manage.py collectstatic</code></li> <li><code>manage.py migrate</code></li> <li><code>cd ./vue</code></li> <li><code>yarn install</code></li> <li><code>yarn build</code></li> </ol> <p>To install latest libraries, apply all new migrations and collect new static files.</p>"},{"location":"system/updating/#postgresql","title":"PostgreSQL","text":"<p>Postgres does not automatically upgrade database files when you change versions and requires manual intervention. One option is to manually backup/restore the database.</p> <p>A full list of options to upgrade a database provide in the official PostgreSQL documentation.</p> <ol> <li>Collect information about your environment.</li> </ol> <pre><code>grep -E 'POSTGRES|DATABASE' ~/.docker/compose/.env\ndocker ps -a --format 'table {{.ID}}\\t{{.Names}}\\t{{.Image}}\\t{{.Status}}' | awk 'NR == 1 || /postgres/ || /recipes/'\n</code></pre> <ol> <li>Export the tandoor database</li> </ol> <pre><code>docker exec -t {{database_container}} pg_dumpall -U {{djangouser}} &gt; ~/tandoor.sql\n</code></pre> <ol> <li> <p>Stop the tandoor application <pre><code>docker compose down\n</code></pre></p> </li> <li> <p>Rename the tandoor volume</p> </li> </ol> <pre><code>mv ./postgresql ./postgresql.old\n</code></pre> <ol> <li>Update image tag on postgres container in the docker-compose.yaml</li> </ol> <pre><code>db_recipes:\n  restart: always\n  image: postgres:16-alpine\n  volumes:\n    - ./postgresql:/var/lib/postgresql/data\n  env_file:\n    - ./.env\n</code></pre> <ol> <li>Pull and rebuild database container</li> </ol> <pre><code>docker compose pull &amp;&amp; docker compose up -d db_recipes\n</code></pre> <ol> <li>Import the database export</li> </ol> <pre><code>cat ~/tandoor.sql | docker exec -i {{database_container}} psql postgres -U {{djangouser}}\n</code></pre> <ol> <li>Install postgres extensions <pre><code>docker exec -it {{database_container}} psql postgres -U {{djangouser}}\n</code></pre>   then <pre><code>CREATE EXTENSION IF NOT EXISTS unaccent;\nCREATE EXTENSION IF NOT EXISTS pg_trgm;\n</code></pre></li> </ol> <p>If anything fails, go back to the old postgres version and data directory and try again.</p> <p>There are many articles and tools online that might provide a good starting point to help you upgrade 1, 2, 3.</p>"}]}